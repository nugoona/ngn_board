# File: services/data_service.py
import os   
import sys
import datetime
import json
import gzip
import io
import re
from flask import Blueprint, request, jsonify, session, Response
from google.cloud import bigquery
from google.cloud import storage
import time
from concurrent.futures import ThreadPoolExecutor
import requests
from urllib.parse import quote, unquote

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€ (company_mapping ëª¨ë“ˆ ì„í¬íŠ¸ìš©)
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
tools_path = os.path.join(project_root, "tools")
if tools_path not in sys.path:
    sys.path.insert(0, tools_path)

# ìì‚¬ëª° ë§¤í•‘ ì„í¬íŠ¸
try:
    from config.company_mapping import get_company_korean_name, get_company_brands, COMPANY_MAPPING
    COMPANY_MAPPING_AVAILABLE = True
except (ImportError, ModuleNotFoundError) as e:
    print(f"[WARN] company_mapping ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")
    COMPANY_MAPPING_AVAILABLE = False
    def get_company_korean_name(name): return None
    def get_company_brands(name): return []
    COMPANY_MAPPING = {}

# ìºì‹œ ìœ í‹¸ë¦¬í‹° ì„í¬íŠ¸
from ..utils.cache_utils import get_cache_stats, invalidate_cache_by_pattern

# ğŸ“¦ ì„œë¹„ìŠ¤ í•¨ìˆ˜ ì„í¬íŠ¸ (ê¸°ëŠ¥ë³„ ì •ë¦¬)
from ..services.cafe24_service import (
    get_cafe24_sales_data,
    get_cafe24_product_sales,
)
from ..services.catalog_sidebar_service import create_or_update_product_set
from ..services.ga4_source_summary import get_ga4_source_summary
from ..services.meta_ads_insight import get_meta_account_list_filtered
from ..services.meta_ads_service import get_meta_ads_data
from ..services.performance_summary_new import get_performance_summary_new
from ..services.platform_sales_summary import get_monthly_platform_sales
from ..services.Fetch_Adset_Summary import get_meta_ads_adset_summary_by_type
from ..services.viewitem_summary import get_viewitem_summary
from ..services.monthly_net_sales_visitors import get_monthly_net_sales_visitors
from ..services.trend_29cm_service import (
    get_rising_star,
    get_new_entry,
    get_rank_drop,
    get_current_week_info,
    get_available_tabs,
    load_trend_snapshot_from_gcs,
    save_trend_snapshot_to_gcs,
    get_all_tabs_data_from_bigquery
)
from ..services.trend_ably_service import (
    get_rising_star as get_ably_rising_star,
    get_new_entry as get_ably_new_entry,
    get_rank_drop as get_ably_rank_drop,
    get_current_week_info as get_ably_current_week_info,
    get_available_tabs as get_ably_available_tabs,
    load_trend_snapshot_from_gcs as load_ably_trend_snapshot_from_gcs,
    save_trend_snapshot_to_gcs as save_ably_trend_snapshot_to_gcs,
    get_all_tabs_data_from_bigquery as get_ably_all_tabs_data_from_bq
)
from ..services.compare_29cm_service import (
    get_competitor_keywords,
    get_competitor_brands,
    get_own_brand_id,
    fetch_product_reviews,
    load_search_results_from_gcs,
)



data_blueprint = Blueprint("data", __name__, url_prefix="/dashboard")


def filter_ai_report_by_company(analysis_report: str, company_name: str) -> str:
    """
    AI ë¦¬í¬íŠ¸ì—ì„œ í˜„ì¬ ì—…ì²´ì— ë§ê²Œ Section 1ì˜ ìì‚¬ëª° ë¸Œëœë“œëª…ì„ ë™ì ìœ¼ë¡œ ë³€ê²½
    
    Args:
        analysis_report: ì›ë³¸ AI ë¦¬í¬íŠ¸ (ë§ˆí¬ë‹¤ìš´ í˜•ì‹)
        company_name: í˜„ì¬ ë¡œê·¸ì¸í•œ ì—…ì²´ëª… (ì˜ˆ: "piscess")
    
    Returns:
        í•„í„°ë§ëœ AI ë¦¬í¬íŠ¸ (Section 1ì˜ ìì‚¬ëª° ë¸Œëœë“œëª…ì´ í˜„ì¬ ì—…ì²´ì— ë§ê²Œ ë³€ê²½ë¨)
    """
    if not analysis_report or not company_name or not COMPANY_MAPPING_AVAILABLE:
        return analysis_report
    
    # demo ê³„ì •ì¸ ê²½ìš° piscessë¡œ ë§¤í•‘ (ì¸ì‚¬ì´íŠ¸ ë¦¬í¬íŠ¸ í‘œì‹œë¥¼ ìœ„í•´)
    filter_company_name = "piscess" if company_name.lower() == "demo" else company_name
    
    company_ko = get_company_korean_name(filter_company_name)
    if not company_ko:
        # ë§¤í•‘ë˜ì§€ ì•Šì€ ì—…ì²´ì¸ ê²½ìš°, Section 1ì—ì„œ ìì‚¬ëª° ì„¹ì…˜ ì œê±° ë˜ëŠ” ê¸°ë³¸ ë©”ì‹œì§€ë¡œ ë³€ê²½
        # Section 1ì˜ ìì‚¬ëª° ë¶€ë¶„ì„ "ìì‚¬ëª° ìƒí’ˆì´ í¬í•¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"ë¡œ ë³€ê²½
        section1_pattern = r'##\s*Section\s*1[^#]*?(?=##|$)'
        section1_match = re.search(section1_pattern, analysis_report, flags=re.IGNORECASE | re.DOTALL)
        if section1_match:
            section1_text = section1_match.group(0)
            # ìì‚¬ëª° ê´€ë ¨ ë‚´ìš©ì„ ì œê±°í•˜ê³  ê¸°ë³¸ ë©”ì‹œì§€ë¡œ êµì²´
            updated_section1 = re.sub(
                r'ìì‚¬ëª°\([^)]+\)[^#]*',
                'ìì‚¬ëª° ì„±ê³¼ ë¶„ì„\n\nê¸ˆì£¼ ë­í‚¹ ë°ì´í„°ì— ìì‚¬ëª° ìƒí’ˆì´ í¬í•¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.',
                section1_text,
                flags=re.DOTALL
            )
            analysis_report = analysis_report.replace(section1_text, updated_section1)
        return analysis_report.strip()
    
    # Section 1ì˜ ìì‚¬ëª° ë¸Œëœë“œëª…ì„ í˜„ì¬ ì—…ì²´ì˜ í•œê¸€ëª…ìœ¼ë¡œ ë³€ê²½
    # íŒ¨í„´: "## Section 1. ìì‚¬ëª°({ë¸Œëœë“œëª…}) ì„±ê³¼ ë¶„ì„"
    section1_pattern = r'(##\s*Section\s*1[^#]*?(?=##|$))'
    section1_match = re.search(section1_pattern, analysis_report, flags=re.IGNORECASE | re.DOTALL)
    
    if section1_match:
        section1_text = section1_match.group(1)
        
        # ê¸°ì¡´ ë¸Œëœë“œëª… íŒ¨í„´ ì°¾ê¸° ë° êµì²´
        # íŒ¨í„´ 1: "ìì‚¬ëª°({ë¸Œëœë“œëª…})" ë˜ëŠ” "ìì‚¬ëª° ({ë¸Œëœë“œëª…})"
        updated_section1 = re.sub(
            r'ìì‚¬ëª°\s*\([^)]+\)',
            f'ìì‚¬ëª°({company_ko})',
            section1_text,
            flags=re.IGNORECASE
        )
        
        # íŒ¨í„´ 2: Section 1 í…ìŠ¤íŠ¸ ë‚´ì˜ ëª¨ë“  ë¸Œëœë“œëª… ì¸ìŠ¤í„´ìŠ¤ êµì²´
        # ì¼ë°˜ì ì¸ ë¸Œëœë“œëª… íŒ¨í„´ êµì²´ (ë”°ì˜´í‘œ ì•ˆì˜ ë¸Œëœë“œëª… í¬í•¨)
        brand_patterns = [
            r"'ì¸ì›¨ì–´ë²„í„°'",
            r'"ì¸ì›¨ì–´ë²„í„°"',
            r'ì¸ì›¨ì–´ë²„í„°',
            r"'íŒŒì´ì‹œìŠ¤'",
            r'"íŒŒì´ì‹œìŠ¤"',
            r'íŒŒì´ì‹œìŠ¤',
            r"'Somewhere Butter'",
            r'"Somewhere Butter"',
            r'Somewhere Butter',
            r"'somewhere butter'",
            r"'PISCESS'",
            r'"PISCESS"',
            r'PISCESS',
            r"'piscess'",
        ]
        
        for pattern in brand_patterns:
            updated_section1 = re.sub(
                pattern,
                company_ko,
                updated_section1,
                flags=re.IGNORECASE
            )
        
        # íŒ¨í„´ 3: "{target_brand}" ë˜ëŠ” ë‹¤ë¥¸ ë³€ìˆ˜ëª… êµì²´
        updated_section1 = re.sub(
            r"\{target_brand\}|\{TARGET_BRAND\}|\{brand\}|\{BRAND\}",
            company_ko,
            updated_section1,
            flags=re.IGNORECASE
        )
        
        analysis_report = analysis_report.replace(section1_text, updated_section1)
    
    return analysis_report.strip()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ“Œ ìºì‹œ ê´€ë¦¬ ì—”ë“œí¬ì¸íŠ¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@data_blueprint.route("/cache/stats", methods=["GET"])
def cache_stats():
    """ìºì‹œ ìƒíƒœ ì •ë³´ ì¡°íšŒ"""
    try:
        stats = get_cache_stats()
        return jsonify({"status": "success", "cache_stats": stats}), 200
    except Exception as e:
        return jsonify({"status": "error", "message": str(e)}), 500

@data_blueprint.route("/cache/invalidate", methods=["POST"])
def cache_invalidate():
    """ìºì‹œ ë¬´íš¨í™” (íŒ¨í„´ ê¸°ë°˜)"""
    try:
        data = request.get_json() or {}
        pattern = data.get("pattern", "")
        
        if not pattern:
            return jsonify({"status": "error", "message": "pattern íŒŒë¼ë¯¸í„° í•„ìš”"}), 400
        
        deleted_count = invalidate_cache_by_pattern(pattern)
        return jsonify({
            "status": "success", 
            "message": f"{pattern} íŒ¨í„´ìœ¼ë¡œ {deleted_count}ê°œ ìºì‹œ ì‚­ì œë¨"
        }), 200
    except Exception as e:
        return jsonify({"status": "error", "message": str(e)}), 500

@data_blueprint.route("/cache/invalidate/ga4_source", methods=["POST"])
def cache_invalidate_ga4_source():
    """GA4 ì†ŒìŠ¤ ìš”ì•½ ìºì‹œ ë¬´íš¨í™” ì—”ë“œí¬ì¸íŠ¸"""
    try:
        from ..utils.cache_utils import invalidate_cache_by_pattern
        deleted_count = invalidate_cache_by_pattern("ga4_source_summary")
        
        return jsonify({
            "status": "success",
            "message": f"GA4 ì†ŒìŠ¤ ìš”ì•½ ìºì‹œ ë¬´íš¨í™” ì™„ë£Œ: {deleted_count}ê°œ í‚¤ ì‚­ì œ",
            "deleted_count": deleted_count
        })
    except Exception as e:
        return jsonify({
            "status": "error",
            "message": f"GA4 ì†ŒìŠ¤ ìš”ì•½ ìºì‹œ ë¬´íš¨í™” ì‹¤íŒ¨: {str(e)}"
        }), 500

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def get_start_end_dates(period, start_date=None, end_date=None):
    """ âœ… í•„í„°ë§ ê¸°ê°„ì„ ê²°ì •í•˜ëŠ” í•¨ìˆ˜ (KST ê¸°ì¤€ ì ìš©) """
    now_utc = datetime.datetime.utcnow()
    now_kst = now_utc + datetime.timedelta(hours=9)

    date_map = {
        "today": (now_kst.strftime("%Y-%m-%d"), now_kst.strftime("%Y-%m-%d")),
        "yesterday": (
            (now_kst - datetime.timedelta(days=1)).strftime("%Y-%m-%d"),
            (now_kst - datetime.timedelta(days=1)).strftime("%Y-%m-%d")
        ),
        "last7days": (
            (now_kst - datetime.timedelta(days=7)).strftime("%Y-%m-%d"),
            (now_kst - datetime.timedelta(days=1)).strftime("%Y-%m-%d")
        ),
        "current_month": (
            now_kst.replace(day=1).strftime("%Y-%m-%d"),
            now_kst.strftime("%Y-%m-%d")
        ),
        "last_month": (
            (now_kst.replace(day=1) - datetime.timedelta(days=1)).replace(day=1).strftime("%Y-%m-%d"),
            (now_kst.replace(day=1) - datetime.timedelta(days=1)).strftime("%Y-%m-%d")
        )
    }

    if start_date == "":
        start_date = None
    if end_date == "":
        end_date = None

    if period in date_map:
        start_date, end_date = date_map[period]

    # ğŸ”¥ 'ì§ì ‘ ì„ íƒ' ëª¨ë“œì—ì„œëŠ” ë‚ ì§œê°€ ë¹„ì–´ìˆìœ¼ë©´ ì˜¤ë¥˜ ë°œìƒ
    if period == "manual":
        if not start_date or not end_date:
            raise ValueError("ì§ì ‘ ì„ íƒ ëª¨ë“œì—ì„œëŠ” ì‹œì‘ì¼ê³¼ ì¢…ë£Œì¼ì´ ëª¨ë‘ í•„ìš”í•©ë‹ˆë‹¤.")
    
    # ğŸ”¥ ë¯¸ë¦¬ ì •ì˜ëœ ê¸°ê°„ì˜ ê²½ìš°ì—ë§Œ ê¸°ë³¸ê°’ ì„¤ì •
    if not start_date:
        start_date = now_kst.strftime("%Y-%m-%d")
    if not end_date:
        end_date = now_kst.strftime("%Y-%m-%d")

    print(f"[DEBUG] ë³€í™˜ëœ ë‚ ì§œ ê°’ - start_date: {start_date}, end_date: {end_date}")
    return start_date, end_date

@data_blueprint.route("/get_data", methods=["POST"])
def get_dashboard_data_route():
    t0 = time.time()
    try:
        data = request.get_json()
        user_id = session.get("user_id")
        raw_company_name = data.get("company_name", "all")

        # âœ… company_name ì²˜ë¦¬
        if raw_company_name == "all":
            company_name = ["demo"] if user_id == "demo" else [
                name for name in session.get("company_names", []) if name.lower() != "demo"
            ]
        elif isinstance(raw_company_name, list):
            company_name = ["demo"] if user_id == "demo" else [
                name.lower() for name in raw_company_name if name.lower() != "demo"
            ]
        else:
            name = str(raw_company_name).strip().lower()
            if name == "demo" and user_id != "demo":
                return jsonify({
                    "status": "success",
                    "message": "demo ì—…ì²´ ì ‘ê·¼ ë¶ˆê°€",
                    "cafe24_sales": [],
                    "cafe24_sales_total_count": 0
                }), 200
            company_name = name

        # âœ… ê³µí†µ íŒŒë¼ë¯¸í„° ì²˜ë¦¬
        period = str(data.get("period", "today")).strip()
        start_date = data.get("start_date")
        end_date = data.get("end_date")
        data_type = (data.get("data_type", "all") or "").strip().lower()
        data_type = data_type.replace("-", "_")  # kebab-case -> snake_case
        data_type = data_type.replace(" ", "_")  # spaces -> underscores
        date_type = str(data.get("date_type", "summary")).strip()
        date_sort = str(data.get("date_sort", "desc")).strip()
        sort_by = str(data.get("sort_by", "item_product_sales")).strip()

        # ì•ˆì „í•œ int ë³€í™˜
        try:
            page = int(data.get("page", 1)) if isinstance(data.get("page"), (int, str)) else 1
        except (ValueError, TypeError):
            page = 1
            
        try:
            limit = int(data.get("limit", 15)) if isinstance(data.get("limit"), (int, str)) else 15
        except (ValueError, TypeError):
            limit = 15
        offset = (page - 1) * limit

        # âœ… ê¸°ê°„ í•„í„° í•„ìš” ì—†ëŠ” í…Œì´ë¸” ì˜ˆì™¸ ì²˜ë¦¬
        if data_type not in ["monthly_net_sales_visitors", "platform_sales_monthly"]:
            # ğŸ”¥ periodê°€ ì—†ìœ¼ë©´ "manual"ë¡œ ì²˜ë¦¬ (ì§ì ‘ ì„ íƒ ëª¨ë“œ)
            if not period:
                period = "manual"
            start_date, end_date = get_start_end_dates(period, start_date, end_date)

        print(f"[DEBUG] ìš”ì²­ í•„í„° - company_name={company_name}, period={period}, "
              f"start_date={start_date}, end_date={end_date}, page={page}, limit={limit}, data_type={data_type}")
        print(f"[DEBUG] date_type={date_type}, date_sort={date_sort}, sort_by={sort_by}")
        print(f"[DEBUG] ì •ê·œí™”ëœ data_type: '{data_type}'")
        print(f"[DEBUG] performance_summary ì¡°ê±´ í™•ì¸: data_type in ['performance_summary', 'all'] = {data_type in ['performance_summary', 'all']}")

        response_data = {"status": "success"}
        timing_log = {}
        fetch_tasks = []
        results_map = {}
        with ThreadPoolExecutor() as executor:
            # Performance Summary
            if data_type in ["performance_summary", "all"]:
                def fetch_performance():
                    t1 = time.time()
                    performance_data = get_performance_summary_new(
                        company_name=company_name,
                        start_date=start_date,
                        end_date=end_date,
                        user_id=user_id
                    )
                    t2 = time.time()
                    timing_log["performance_summary"] = round(t2-t1, 3)
                    
                    # ğŸ”¥ ISO í˜•ì‹ìœ¼ë¡œ ë‚ ì§œ ë³€í™˜ (JavaScriptì—ì„œ íŒŒì‹± ê°€ëŠ¥)
                    latest_update = None
                    if performance_data:
                        for row in performance_data:
                            if row.get("updated_at"):
                                # datetime ê°ì²´ë¥¼ ISO í˜•ì‹ ë¬¸ìì—´ë¡œ ë³€í™˜
                                if hasattr(row["updated_at"], 'isoformat'):
                                    latest_update = row["updated_at"].isoformat()
                                else:
                                    latest_update = str(row["updated_at"])
                                break
                    
                    return ("performance_summary", performance_data[offset:offset + limit], len(performance_data), latest_update)
                fetch_tasks.append(executor.submit(fetch_performance))
            
            # Cafe24 Sales
            if data_type in ["cafe24_sales", "all"]:
                def fetch_cafe24_sales():
                    t1 = time.time()
                    result = get_cafe24_sales_data(
                        company_name, period, start_date, end_date,
                        date_type, date_sort, limit, page, user_id
                    )
                    t2 = time.time()
                    timing_log["cafe24_sales"] = round(t2-t1, 3)
                    return ("cafe24_sales", result["rows"], result["total_count"])
                fetch_tasks.append(executor.submit(fetch_cafe24_sales))
            
            # Cafe24 Product Sales
            if data_type in ["cafe24_product_sales", "all"]:
                def fetch_cafe24_product_sales():
                    t1 = time.time()
                    result = get_cafe24_product_sales(
                        company_name, period, start_date, end_date,
                        sort_by=sort_by, limit=limit, page=page, user_id=user_id
                    )
                    t2 = time.time()
                    timing_log["cafe24_product_sales"] = round(t2-t1, 3)
                    return ("cafe24_product_sales", result["rows"], result["total_count"])
                fetch_tasks.append(executor.submit(fetch_cafe24_product_sales))
            
            # ViewItem Summary
            if data_type in ["viewitem_summary", "all"]:
                def fetch_viewitem_summary():
                    t1 = time.time()
                    data_rows = get_viewitem_summary(company_name, start_date, end_date, limit=500)
                    t2 = time.time()
                    timing_log["viewitem_summary"] = round(t2-t1, 3)
                    return ("viewitem_summary", data_rows, len(data_rows))
                fetch_tasks.append(executor.submit(fetch_viewitem_summary))
            
            # GA4 Source Summary
            if data_type in ["ga4_source_summary", "all"]:
                def fetch_ga4_source_summary():
                    t1 = time.time()
                    try:
                        # ìºì‹œ ë¬´íš¨í™” íŒŒë¼ë¯¸í„° ì¶”ì¶œ
                        cache_buster = data.get('_cache_buster')
                        print(f"[DEBUG] GA4 Source Summary í˜¸ì¶œ - company: {company_name}, start: {start_date}, end: {end_date}")
                        print(f"[DEBUG] GA4 Source Summary íŒŒë¼ë¯¸í„° íƒ€ì… - company: {type(company_name)}, start: {type(start_date)}, end: {type(end_date)}")
                        print(f"[DEBUG] GA4 Source Summary ì „ì²´ data: {data}")
                        
                        if not start_date or not end_date:
                            print(f"[ERROR] GA4 Source Summary - start_date ë˜ëŠ” end_dateê°€ ì—†ìŠµë‹ˆë‹¤!")
                            return ("ga4_source_summary", [], 0)
                        
                        data_rows = get_ga4_source_summary(company_name, start_date, end_date, limit=100, _cache_buster=cache_buster)
                        t2 = time.time()
                        timing_log["ga4_source_summary"] = round(t2-t1, 3)
                        return ("ga4_source_summary", data_rows[offset:offset + limit], len(data_rows))
                    except Exception as e:
                        print(f"[ERROR] GA4 Source Summary ì˜¤ë¥˜: {type(e).__name__}: {str(e)}")
                        return ("ga4_source_summary", [], 0)
                fetch_tasks.append(executor.submit(fetch_ga4_source_summary))
            
            # Monthly Net Sales & Visitors Chart
            if data_type == "monthly_net_sales_visitors":
                def fetch_monthly_net_sales_visitors():
                    t1 = time.time()
                    data_rows = get_monthly_net_sales_visitors(company_name)
                    t2 = time.time()
                    timing_log["monthly_net_sales_visitors"] = round(t2-t1, 3)
                    return ("monthly_net_sales_visitors", data_rows, len(data_rows))
                fetch_tasks.append(executor.submit(fetch_monthly_net_sales_visitors))
            
            # Product Sales Ratio
            if data_type == "product_sales_ratio":
                def fetch_product_sales_ratio():
                    t1 = time.time()
                    from ..services.product_sales_ratio import get_product_sales_ratio
                    # â¬‡ï¸ ì„œë¹„ìŠ¤ í•¨ìˆ˜ëŠ” ë¦¬ìŠ¤íŠ¸ íŒŒë¼ë¯¸í„°ë¥¼ ê¸°ëŒ€í•˜ë¯€ë¡œ ë¬¸ìì—´ì´ë©´ ë¦¬ìŠ¤íŠ¸ë¡œ ë˜í•‘
                    _company_names = company_name if isinstance(company_name, list) else [company_name]
                    data_rows = get_product_sales_ratio(_company_names, start_date, end_date, limit=50, user_id=user_id)
                    t2 = time.time()
                    timing_log["product_sales_ratio"] = round(t2-t1, 3)
                    return ("product_sales_ratio", data_rows)
                fetch_tasks.append(executor.submit(fetch_product_sales_ratio))
            
            # Platform Sales Summary
            if data_type == "platform_sales_summary":
                def fetch_platform_sales_summary():
                    t1 = time.time()
                    from ..services.platform_sales_summary import get_platform_sales_by_day
                    # â¬‡ï¸ ì„œë¹„ìŠ¤ í•¨ìˆ˜ëŠ” ë¦¬ìŠ¤íŠ¸ íŒŒë¼ë¯¸í„°ë¥¼ ê¸°ëŒ€í•˜ë¯€ë¡œ ë¬¸ìì—´ì´ë©´ ë¦¬ìŠ¤íŠ¸ë¡œ ë˜í•‘
                    _company_names = company_name if isinstance(company_name, list) else [company_name]

                    data_rows = get_platform_sales_by_day(
                        company_names=_company_names,
                        start_date=start_date,
                        end_date=end_date,
                        date_type=date_type,
                        date_sort=date_sort
                    )
                    t2 = time.time()
                    timing_log["platform_sales_summary"] = round(t2-t1, 3)
                    return ("platform_sales_summary", data_rows, len(data_rows))
                fetch_tasks.append(executor.submit(fetch_platform_sales_summary))
            
            # Platform Sales Ratio (íŒŒì´ì°¨íŠ¸ìš©)
            if data_type == "platform_sales_ratio":
                def fetch_platform_sales_ratio():
                    t1 = time.time()
                    from ..services.platform_sales_summary import get_platform_sales_ratio
                    _company_names = company_name if isinstance(company_name, list) else [company_name]

                    data_rows = get_platform_sales_ratio(
                        company_names=_company_names,
                        start_date=start_date,
                        end_date=end_date
                    )
                    t2 = time.time()
                    timing_log["platform_sales_ratio"] = round(t2-t1, 3)
                    return ("platform_sales_ratio", data_rows)
                fetch_tasks.append(executor.submit(fetch_platform_sales_ratio))
            
            # Platform Sales Monthly
            if data_type == "platform_sales_monthly":
                def fetch_monthly_platform_sales():
                    t1 = time.time()
                    from ..services.platform_sales_summary import get_monthly_platform_sales
                    _company_names = company_name if isinstance(company_name, list) else [company_name]
                    data_rows = get_monthly_platform_sales(_company_names)
                    t2 = time.time()
                    timing_log["platform_sales_monthly"] = round(t2-t1, 3)
                    return ("platform_sales_monthly", data_rows, len(data_rows))
                fetch_tasks.append(executor.submit(fetch_monthly_platform_sales))

        # Collect results
        for future in fetch_tasks:
            result = future.result()
            if result[0] == "performance_summary":
                response_data["performance_summary"] = result[1]
                response_data["performance_summary_total_count"] = result[2]
                response_data["latest_update"] = result[3]
            elif result[0] == "cafe24_sales":
                response_data["cafe24_sales"] = result[1]
                response_data["cafe24_sales_total_count"] = result[2]
            elif result[0] == "cafe24_product_sales":
                response_data["cafe24_product_sales"] = result[1]
                response_data["cafe24_product_sales_total_count"] = result[2]
            elif result[0] == "viewitem_summary":
                response_data["viewitem_summary"] = result[1]
                response_data["viewitem_summary_total_count"] = result[2]
            elif result[0] == "ga4_source_summary":
                response_data["ga4_source_summary"] = result[1]
                response_data["ga4_source_summary_total_count"] = result[2]
            elif result[0] == "monthly_net_sales_visitors":
                response_data["monthly_net_sales_visitors"] = result[1]
                response_data["monthly_net_sales_visitors_total_count"] = result[2]
            elif result[0] == "product_sales_ratio":
                response_data["product_sales_ratio"] = result[1]
            elif result[0] == "platform_sales_summary":
                response_data["platform_sales_summary"] = result[1]
                response_data["platform_sales_summary_total_count"] = result[2]
            elif result[0] == "platform_sales_ratio":
                response_data["platform_sales_ratio"] = result[1]
            elif result[0] == "platform_sales_monthly":
                response_data["platform_sales_monthly"] = result[1]
                response_data["platform_sales_monthly_total_count"] = result[2]

        # Meta ê´‘ê³  ê´€ë ¨ ë°ì´í„° ìš”ì²­ ì²˜ë¦¬
        if data_type == "meta_ads_insight_table":
            t1 = time.time()
            from ..services.meta_ads_insight import get_meta_ads_insight_table

            level = data.get("level", "account")
            account_id = data.get("account_id")
            campaign_id = data.get("campaign_id")
            adset_id = data.get("adset_id")
            date_type = data.get("date_type", "summary")
            # í˜ì´ì§€ë„¤ì´ì…˜ íŒŒë¼ë¯¸í„° (ì›¹ UIì— ì˜í–¥ ì—†ë„ë¡ ê¸°ë³¸ê°’ ìœ ì§€)
            limit = data.get("limit", None)
            page = data.get("page", 1)

            rows = get_meta_ads_insight_table(
                level=level,
                company_name=company_name,
                start_date=start_date,
                end_date=end_date,
                account_id=account_id,
                campaign_id=campaign_id,
                adset_id=adset_id,
                date_type=date_type,
                limit=limit,
                page=page
            )
            t2 = time.time()
            timing_log["meta_ads_insight_table"] = round(t2-t1, 3)
            
            # í˜ì´ì§€ë„¤ì´ì…˜ëœ ê²°ê³¼ ì²˜ë¦¬
            if isinstance(rows, dict) and "rows" in rows:
                # í˜ì´ì§€ë„¤ì´ì…˜ëœ ê²°ê³¼ (ì „ì²´ ê°œìˆ˜ í¬í•¨)
                response_data["meta_ads_insight_table"] = rows["rows"]
                response_data["meta_ads_insight_table_total_count"] = rows["total_count"]
            else:
                # ê¸°ì¡´ í˜•ì‹ (í˜ì´ì§€ë„¤ì´ì…˜ ì—†ìŒ)
                response_data["meta_ads_insight_table"] = rows

            # âœ… Meta Ads ìˆ˜ì§‘ì‹œê°„ ì‚¬ìš© (meta_ads_ad_level í…Œì´ë¸”ì—ì„œ ì¡°íšŒ)
            try:
                from google.cloud import bigquery as bq_client
                client = bq_client.Client()
                meta_query = """
                    SELECT MAX(updated_at) AS updated_at
                    FROM `winged-precept-443218-v8.ngn_dataset.meta_ads_ad_level`
                    WHERE date >= DATE_SUB(CURRENT_DATE(), INTERVAL 7 DAY)
                """
                result = client.query(meta_query).result()
                for row in result:
                    if row.updated_at:
                        response_data["updated_at"] = row.updated_at.isoformat() if hasattr(row.updated_at, 'isoformat') else str(row.updated_at)
                        break
            except Exception as e:
                print(f"[WARN] Meta Ads updated_at ì¡°íšŒ ì‹¤íŒ¨: {e}")

        # Meta Ads ê³„ì • ëª©ë¡ ìš”ì²­ ì²˜ë¦¬
        if data_type == "meta_account_list":
            if user_id == "demo":
                session["company_names"] = ["demo"]

            from ..services.meta_ads_insight import get_meta_account_list_filtered
            rows = get_meta_account_list_filtered(company_name)
            response_data["meta_accounts"] = rows

        # Meta Ads ìº í˜ì¸ ëª©í‘œë³„ ì„±ê³¼ ìš”ì•½
        if data_type == "meta_ads_adset_summary_by_type":
            account_id = data.get("account_id")
            period = data.get("period")
            start_date = data.get("start_date")
            end_date = data.get("end_date")

            type_summary, total_spend_sum = get_meta_ads_adset_summary_by_type(
                account_id=account_id,
                period=period,
                start_date=start_date,
                end_date=end_date
            )

            response_data["data"] = {
                "type_summary": type_summary,
                "total_spend_sum": total_spend_sum
            }

        # Meta Ads ê´‘ê³  ë¯¸ë¦¬ë³´ê¸° - ë‹¨ì¼ (ìºì‹œ ì œê±° ë²„ì „)
        if data_type == "meta_ads_preview_list":
            from ..services.meta_ads_preview import get_meta_ads_preview_list
            import logging
            handler_logger = logging.getLogger(__name__)

            account_id = data.get("account_id")
            
            # âœ… [NO_CACHE] ìºì‹œ ì™„ì „ ì œê±° - í•­ìƒ ì§ì ‘ í˜¸ì¶œ
            handler_logger.warning(f"[META_API][NO_CACHE] live preview - cache bypassed, account_id={account_id}")
            handler_logger.warning(f"[META_API][ENTER] get_meta_ads_preview_list account_id={account_id}")
            
            start_time = time.time()
            ad_list = get_meta_ads_preview_list(account_id)
            processing_time = time.time() - start_time
            
            handler_logger.warning(f"[META_API][RESULT] ê²°ê³¼: {len(ad_list) if ad_list else 0}ê°œ, {processing_time:.2f}ì´ˆ")
            
            response_data["meta_ads_preview_list"] = ad_list
            response_data["cached"] = False
            response_data["processing_time"] = round(processing_time, 2)

        # Meta Ads ê´‘ê³  ë¯¸ë¦¬ë³´ê¸° - ì½œë ‰ì…˜/ìŠ¬ë¼ì´ë“œë“œ
        if data_type == "slide_collection_ads":
            from ..services.meta_ads_slide_collection import get_slide_collection_ads

            account_id = data.get("account_id")
            ad_list = get_slide_collection_ads(account_id)

            response_data["slide_collection_ads"] = ad_list

        # catalog_sidebar
        if data_type == "catalog_sidebar":
            from ..services.catalog_sidebar_service import get_catalog_sidebar_data

            account_id = data.get("account_id")
            if not account_id:
                return jsonify({"status": "error", "message": "account_id ëˆ„ë½"}), 400

            result, error = get_catalog_sidebar_data(account_id)
            if error:
                return jsonify({"status": "error", "message": error}), 404

            response_data["catalog_sidebar"] = result

        # catalog_manual  â”€ ìì‚¬ëª° URL ìˆ˜ì§‘
        if data_type == "catalog_manual":
            from ..services.catalog_sidebar_service import get_manual_product_list

            category_url = data.get("category_url")
            if not category_url:
                return jsonify({"status": "error", "message": "category_url ëˆ„ë½"}), 400

            result, error = get_manual_product_list(category_url)
            if error:
                return jsonify({"status": "error", "message": error}), 404

            response_data["products"] = result

        # catalog_manual_search  â”€ ìˆ˜ë™ ì„¸íŠ¸ í‚¤ì›Œë“œ ê²€ìƒ‰
        if data_type == "catalog_manual_search":
            from ..services.catalog_sidebar_service import search_products_for_manual_set

            account_id = data.get("account_id")
            keyword = (data.get("keyword") or "").strip()
            search_type = data.get("search_type")   # 'product_name' | 'product_no'

            # â”€â”€ íŒŒë¼ë¯¸í„° ê²€ì¦ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            if not account_id:
                return jsonify({"status": "error", "message": "account_id ëˆ„ë½"}), 400
            if not keyword:
                return jsonify({"status": "error", "message": "keyword ëˆ„ë½"}), 400
            if search_type not in ("product_name", "product_no"):
                return jsonify({"status": "error", "message": "search_type ëˆ„ë½ ë˜ëŠ” ì˜ëª»ë¨"}), 400

            # â”€â”€ ì„œë¹„ìŠ¤ í˜¸ì¶œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            result, error = search_products_for_manual_set(
                account_id=account_id,
                keyword=keyword,
                search_type=search_type
            )
            if error:
                return jsonify({"status": "error", "message": error}), 404

            response_data["results"] = result

        t_end = time.time()
        print("[TIMING_LOG] /dashboard/get_data timing:", timing_log, "total:", round(t_end-t0, 3), "s")
        return jsonify(response_data), 200

    except TypeError as te:
        print(f"[ERROR] ìš”ì²­ ë°ì´í„° íƒ€ì… ì˜¤ë¥˜: {te}")
        return jsonify({"status": "error", "message": f"ì˜ëª»ëœ ìš”ì²­ í˜•ì‹: {str(te)}"}), 400

    except Exception as e:
        print(f"[ERROR] ë°ì´í„° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return jsonify({"status": "error", "message": f"ë°ì´í„° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"}), 500


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ“Œ ì¹´íƒˆë¡œê·¸ ìƒí’ˆì„¸íŠ¸ ìƒì„± / ì—…ë°ì´íŠ¸
#     POST  /dashboard/catalog_set
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@data_blueprint.route("/catalog_set", methods=["POST"])
def catalog_set_route():
    try:
        data = request.get_json(silent=True) or {}

        catalog_id   = str(data.get("catalog_id", "")).strip()
        set_name     = str(data.get("set_name", "")).strip()
        retailer_ids = [str(r).strip() for r in data.get("retailer_ids", [])]

        # â”€â”€â”€ â‘  í•„ìˆ˜ íŒŒë¼ë¯¸í„° í™•ì¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if not (catalog_id and set_name and retailer_ids):
            return jsonify({
                "status": "error",
                "message": "catalog_id / set_name / retailer_ids ëˆ„ë½"
            }), 400

        # â”€â”€â”€ â‘¡ ì‹œìŠ¤í…œ-í† í° ì¡´ì¬ ì—¬ë¶€ë§Œ í™•ì¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if not os.getenv("META_SYSTEM_TOKEN"):
            return jsonify({
                "status": "error",
                "message": "META_SYSTEM_TOKEN ì´ í™˜ê²½ë³€ìˆ˜ì— ì—†ìŠµë‹ˆë‹¤."
            }), 500

        # â”€â”€â”€ â‘¢ ì„¸íŠ¸ ìƒì„±/ì—…ë°ì´íŠ¸ í˜¸ì¶œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        result, err = create_or_update_product_set(
            catalog_id   = catalog_id,
            set_name     = set_name,
            retailer_ids = retailer_ids
        )

        if err:
            return jsonify({"status": "error", "message": err}), 500

        return jsonify({"status": "success", **result}), 200

    except Exception as e:
        return jsonify({"status": "error", "message": str(e)}), 500


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ“Œ ì´ë¯¸ì§€ í”„ë¡ì‹œ ì—”ë“œí¬ì¸íŠ¸ (CORS ë¬¸ì œ í•´ê²°)
#     GET  /dashboard/proxy_image?url=<encoded_image_url>
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@data_blueprint.route("/test", methods=["GET"])
def test():
    return "Hello World"


@data_blueprint.route("/monthly_report", methods=["POST"])
def get_monthly_report():
    """ì›”ê°„ ë¦¬í¬íŠ¸ ìŠ¤ëƒ…ìƒ· ë°ì´í„° ì¡°íšŒ (GCS ë²„í‚·ì—ì„œ)"""
    try:
        data = request.get_json()
        company_name = data.get("company_name")
        year = int(data.get("year"))
        month = int(data.get("month"))
        
        if not company_name or company_name == "all":
            return jsonify({"status": "error", "message": "ì—…ì²´ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”"}), 400
        
        # GCS ë²„í‚·ì—ì„œ ìŠ¤ëƒ…ìƒ· íŒŒì¼ ì½ê¸°
        PROJECT_ID = os.environ.get("GOOGLE_CLOUD_PROJECT", "winged-precept-443218-v8")
        GCS_BUCKET = os.environ.get("GCS_BUCKET", "winged-precept-443218-v8.appspot.com")
        
        # ê²½ë¡œ í˜•ì‹: ai-reports/monthly/{company}/{YYYY-MM}/snapshot.json[.gz] (ì‹¤ì œ ì €ì¥ ê²½ë¡œ)
        month_str = f"{year}-{month:02d}"
        
        # ì—¬ëŸ¬ ê²½ë¡œ ì‹œë„ (ì••ì¶• íŒŒì¼ ìš°ì„ , ê·¸ ë‹¤ìŒ ì••ì¶• ì—†ëŠ” íŒŒì¼)
        blob_paths = [
            f"ai-reports/monthly/{company_name}/{month_str}/snapshot.json.gz",  # ì••ì¶• íŒŒì¼ (ì›ë³¸)
            f"ai-reports/monthly/{company_name.lower()}/{month_str}/snapshot.json.gz",  # ì••ì¶• íŒŒì¼ (ì†Œë¬¸ì)
            f"ai-reports/monthly/{company_name}/{month_str}/snapshot.json",  # ì••ì¶• ì—†ëŠ” íŒŒì¼ (ì›ë³¸, í•˜ìœ„ í˜¸í™˜)
            f"ai-reports/monthly/{company_name.lower()}/{month_str}/snapshot.json",  # ì••ì¶• ì—†ëŠ” íŒŒì¼ (ì†Œë¬¸ì)
            f"ai-reports/{company_name}/{month_str}.json",  # ëŒ€ì²´ ê²½ë¡œ (ì›ë³¸)
            f"ai-reports/{company_name.lower()}/{month_str}.json"  # ëŒ€ì²´ ê²½ë¡œ (ì†Œë¬¸ì)
        ]
        
        try:
            client = storage.Client(project=PROJECT_ID)
            bucket = client.bucket(GCS_BUCKET)
            
            # ì—¬ëŸ¬ ê²½ë¡œ ì‹œë„
            blob = None
            found_path = None
            for blob_path in blob_paths:
                test_blob = bucket.blob(blob_path)
                if test_blob.exists():
                    blob = test_blob
                    found_path = blob_path
                    break
            
            if not blob:
                return jsonify({
                    "status": "error",
                    "message": f"{year}ë…„ {month}ì›” ë¦¬í¬íŠ¸ê°€ ì•„ì§ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
                }), 404
            
            # í•˜ì´ë¸Œë¦¬ë“œ ì½ê¸° ë¡œì§: Gzip ì••ì¶• ì—¬ë¶€ì™€ ê´€ê³„ì—†ì´ ë°”ì´íŠ¸ë¡œ ë‹¤ìš´ë¡œë“œ í›„ ìë™ íŒë³„
            snapshot_bytes = blob.download_as_bytes()
            
            # Gzip ì••ì¶• í•´ì œ ì‹œë„ (ì„±ê³µí•˜ë©´ ì••ì¶•ëœ íŒŒì¼, ì‹¤íŒ¨í•˜ë©´ ì••ì¶•ë˜ì§€ ì•Šì€ íŒŒì¼)
            try:
                # Python ë²„ì „ í˜¸í™˜ì„±ì„ ìœ„í•´ gzip.GzipFile ì‚¬ìš© (max_length íŒŒë¼ë¯¸í„° ë¬¸ì œ íšŒí”¼)
                with gzip.GzipFile(fileobj=io.BytesIO(snapshot_bytes)) as gz_file:
                    snapshot_json_str = gz_file.read().decode('utf-8')
                print(f"âœ… GCSì—ì„œ ìŠ¤ëƒ…ìƒ·ì„ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤: {found_path} (Gzip ì••ì¶• í•´ì œë¨)", file=sys.stderr)
            except (gzip.BadGzipFile, OSError, Exception) as e:
                # Gzip ì••ì¶• í•´ì œ ì‹¤íŒ¨ â†’ ì••ì¶•ë˜ì§€ ì•Šì€ JSON íŒŒì¼ë¡œ ì²˜ë¦¬ (í•˜ìœ„ í˜¸í™˜)
                snapshot_json_str = snapshot_bytes.decode('utf-8')
                print(f"âœ… GCSì—ì„œ ìŠ¤ëƒ…ìƒ·ì„ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤: {found_path} (ì••ì¶• ì—†ìŒ, í•˜ìœ„ í˜¸í™˜)", file=sys.stderr)
            
            snapshot_data = json.loads(snapshot_json_str)
            
            return jsonify({
                "status": "success",
                "data": snapshot_data
            }), 200
            
        except Exception as e:
            return jsonify({
                "status": "error",
                "message": f"ìŠ¤ëƒ…ìƒ· íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            }), 500
            
    except Exception as e:
        return jsonify({"status": "error", "message": str(e)}), 500

@data_blueprint.route("/monthly_report/check_new", methods=["POST"])
def check_new_monthly_report():
    """GCS íŒŒì¼ ìˆ˜ì • ì‹œê°„ë§Œ í™•ì¸ (íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì•ˆ í•¨, ë¹„ìš© ìµœì†Œí™”)"""
    try:
        data = request.get_json()
        company_name = data.get("company_name")
        year = int(data.get("year"))
        month = int(data.get("month"))
        
        if not company_name or company_name == "all":
            return jsonify({"status": "error", "message": "ì—…ì²´ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”"}), 400
        
        # GCS ë²„í‚·ì—ì„œ ìŠ¤ëƒ…ìƒ· íŒŒì¼ ë©”íƒ€ë°ì´í„°ë§Œ í™•ì¸ (íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì•ˆ í•¨)
        PROJECT_ID = os.environ.get("GOOGLE_CLOUD_PROJECT", "winged-precept-443218-v8")
        GCS_BUCKET = os.environ.get("GCS_BUCKET", "winged-precept-443218-v8.appspot.com")
        
        month_str = f"{year}-{month:02d}"
        
        # ì—¬ëŸ¬ ê²½ë¡œ ì‹œë„
        blob_paths = [
            f"ai-reports/monthly/{company_name}/{month_str}/snapshot.json.gz",
            f"ai-reports/monthly/{company_name.lower()}/{month_str}/snapshot.json.gz",
            f"ai-reports/monthly/{company_name}/{month_str}/snapshot.json",
            f"ai-reports/monthly/{company_name.lower()}/{month_str}/snapshot.json",
        ]
        
        try:
            client = storage.Client(project=PROJECT_ID)
            bucket = client.bucket(GCS_BUCKET)
            
            # ì—¬ëŸ¬ ê²½ë¡œ ì‹œë„ (ë©”íƒ€ë°ì´í„°ë§Œ í™•ì¸, íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì•ˆ í•¨)
            blob = None
            for blob_path in blob_paths:
                test_blob = bucket.blob(blob_path)
                if test_blob.exists():
                    blob = test_blob
                    # ë©”íƒ€ë°ì´í„°ë§Œ ê°€ì ¸ì˜¤ê¸° (íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì•ˆ í•¨)
                    blob.reload()
                    break
            
            if not blob:
                return jsonify({
                    "status": "error",
                    "message": f"{year}ë…„ {month}ì›” ë¦¬í¬íŠ¸ê°€ ì•„ì§ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
                }), 404
            
            # íŒŒì¼ ìˆ˜ì • ì‹œê°„ë§Œ ë°˜í™˜ (ISO í˜•ì‹)
            return jsonify({
                "status": "success",
                "snapshot_updated": blob.updated.isoformat() if blob.updated else None,
                "snapshot_created": blob.time_created.isoformat() if blob.time_created else None
            }), 200
            
        except Exception as e:
            return jsonify({
                "status": "error",
                "message": f"ìŠ¤ëƒ…ìƒ· íŒŒì¼ í™•ì¸ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            }), 500
            
    except Exception as e:
        return jsonify({"status": "error", "message": str(e)}), 500

@data_blueprint.route("/proxy_image", methods=["GET"])
def proxy_image():
    """
    ì™¸ë¶€ ì´ë¯¸ì§€ URLì„ í”„ë¡ì‹œí•˜ì—¬ CORS ë° Mixed Content ë¬¸ì œë¥¼ í•´ê²°í•©ë‹ˆë‹¤.
    Meta APIì—ì„œ ê°€ì ¸ì˜¨ ì´ë¯¸ì§€ URLì„ ì„œë²„ì—ì„œ ê°€ì ¸ì™€ì„œ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    print(f"[PROXY] proxy_image í˜¸ì¶œë¨ - args: {request.args}")
    try:
        # URL íŒŒë¼ë¯¸í„°ì—ì„œ ì´ë¯¸ì§€ URL ê°€ì ¸ì˜¤ê¸°
        image_url = request.args.get("url")
        
        if not image_url:
            return jsonify({"status": "error", "message": "url íŒŒë¼ë¯¸í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤"}), 400
        
        # URL ë””ì½”ë”©
        try:
            image_url = unquote(image_url)
        except Exception:
            pass  # ì´ë¯¸ ë””ì½”ë”©ëœ ê²½ìš° ê·¸ëŒ€ë¡œ ì‚¬ìš©
        
        # ë³´ì•ˆ: í—ˆìš©ëœ ë„ë©”ì¸ë§Œ í”„ë¡ì‹œ (Meta/Facebook ì´ë¯¸ì§€)
        allowed_domains = [
            "fbcdn.net",
            "facebook.com",
            "scontent",
            "cdninstagram.com",
            "instagram.com"
        ]
        
        if not any(domain in image_url.lower() for domain in allowed_domains):
            # ë¡œì»¬ íŒŒì¼ ê²½ë¡œì¸ ê²½ìš° í—ˆìš© (ì˜ˆ: /static/demo_ads/...)
            if not image_url.startswith("/static/"):
                return jsonify({"status": "error", "message": "í—ˆìš©ë˜ì§€ ì•Šì€ ë„ë©”ì¸ì…ë‹ˆë‹¤"}), 403
        
        # ë¡œì»¬ íŒŒì¼ì¸ ê²½ìš° ì§ì ‘ ë°˜í™˜
        if image_url.startswith("/static/"):
            from flask import send_from_directory
            import os
            static_folder = os.path.join(os.path.dirname(__file__), "..", "static")
            file_path = image_url.replace("/static/", "")
            return send_from_directory(static_folder, file_path)
        
        # ì™¸ë¶€ ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸°
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
        }
        
        response = requests.get(image_url, headers=headers, timeout=10, stream=True)
        response.raise_for_status()
        
        # Content-Type í™•ì¸
        content_type = response.headers.get("Content-Type", "image/jpeg")
        
        # ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ìŠ¤íŠ¸ë¦¼ìœ¼ë¡œ ë°˜í™˜
        def generate():
            for chunk in response.iter_content(chunk_size=8192):
                if chunk:
                    yield chunk
        
        return Response(
            generate(),
            mimetype=content_type,
            headers={
                "Cache-Control": "public, max-age=3600",  # 1ì‹œê°„ ìºì‹œ
                "Access-Control-Allow-Origin": "*",  # CORS í—ˆìš©
            }
        )
        
    except requests.exceptions.RequestException as e:
        print(f"[ERROR] ì´ë¯¸ì§€ í”„ë¡ì‹œ ì‹¤íŒ¨: {image_url}, ì˜¤ë¥˜: {str(e)}")
        return jsonify({"status": "error", "message": f"ì´ë¯¸ì§€ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}"}), 500
    except Exception as e:
        print(f"[ERROR] ì´ë¯¸ì§€ í”„ë¡ì‹œ ì˜¤ë¥˜: {str(e)}")
        return jsonify({"status": "error", "message": f"í”„ë¡ì‹œ ì˜¤ë¥˜: {str(e)}"}), 500


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ“Œ Batch Dashboard Data API (Single Request)
#     POST  /dashboard/get_batch_dashboard_data
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@data_blueprint.route("/get_batch_dashboard_data", methods=["POST"])
def get_batch_dashboard_data_route():
    """
    ëŒ€ì‹œë³´ë“œ ì´ˆê¸° ë¡œë”©ì„ ìœ„í•œ í†µí•© API
    ëª¨ë“  ìœ„ì ¯ ë°ì´í„°ë¥¼ í•œ ë²ˆì˜ ìš”ì²­ìœ¼ë¡œ ë³‘ë ¬ ì²˜ë¦¬í•˜ì—¬ ë°˜í™˜
    """
    t0 = time.time()
    try:
        data = request.get_json()
        user_id = session.get("user_id")
        raw_company_name = data.get("company_name", "all")

        # âœ… company_name ì²˜ë¦¬ (ê¸°ì¡´ ë¡œì§ê³¼ ë™ì¼)
        if raw_company_name == "all":
            company_name = ["demo"] if user_id == "demo" else [
                name for name in session.get("company_names", []) if name.lower() != "demo"
            ]
        elif isinstance(raw_company_name, list):
            company_name = ["demo"] if user_id == "demo" else [
                name.lower() for name in raw_company_name if name.lower() != "demo"
            ]
        else:
            name = str(raw_company_name).strip().lower()
            if name == "demo" and user_id != "demo":
                return jsonify({
                    "status": "success",
                    "message": "demo ì—…ì²´ ì ‘ê·¼ ë¶ˆê°€",
                    "performance_summary": [],
                    "cafe24_sales": [],
                    "cafe24_product_sales": [],
                    "ga4_source_summary": [],
                    "viewitem_summary": [],
                    "monthly_net_sales_visitors": [],
                    "platform_sales_summary": [],
                    "platform_sales_ratio": [],
                    "product_sales_ratio": []
                }), 200
            company_name = name

        # âœ… ê³µí†µ íŒŒë¼ë¯¸í„° ì²˜ë¦¬
        period = str(data.get("period", "today")).strip()
        start_date = data.get("start_date")
        end_date = data.get("end_date")
        
        # âœ… ì¶”ê°€ íŒŒë¼ë¯¸í„° (ê¸°ë³¸ê°’ ì ìš©)
        date_type = str(data.get("date_type", "summary")).strip()
        date_sort = str(data.get("date_sort", "desc")).strip()
        sort_by = str(data.get("sort_by", "sales")).strip()
        platform_date_type = str(data.get("platform_date_type", "summary")).strip()
        platform_date_sort = str(data.get("platform_date_sort", "desc")).strip()

        # âœ… ê¸°ê°„ í•„í„° ì²˜ë¦¬
        if period and period not in ["monthly_net_sales_visitors", "platform_sales_monthly"]:
            if not period:
                period = "manual"
            try:
                start_date, end_date = get_start_end_dates(period, start_date, end_date)
            except ValueError as ve:
                return jsonify({"status": "error", "message": str(ve)}), 400

        print(f"[BATCH_API] ìš”ì²­ - company_name={company_name}, period={period}, "
              f"start_date={start_date}, end_date={end_date}")

        # âœ… ì‘ë‹µ ë°ì´í„° ì´ˆê¸°í™”
        response_data = {
            "status": "success",
            "performance_summary": [],
            "performance_summary_total_count": 0,
            "latest_update": None,
            "cafe24_sales": [],
            "cafe24_sales_total_count": 0,
            "cafe24_product_sales": [],
            "cafe24_product_sales_total_count": 0,
            "ga4_source_summary": [],
            "ga4_source_summary_total_count": 0,
            "viewitem_summary": [],
            "viewitem_summary_total_count": 0,
            "monthly_net_sales_visitors": [],
            "monthly_net_sales_visitors_total_count": 0,
            "platform_sales_summary": [],
            "platform_sales_summary_total_count": 0,
            "platform_sales_ratio": [],
            "product_sales_ratio": []
        }
        
        timing_log = {}
        fetch_tasks = []

        # âœ… ThreadPoolExecutorë¡œ ë³‘ë ¬ ì²˜ë¦¬
        with ThreadPoolExecutor() as executor:
            # 1. Performance Summary
            def fetch_performance():
                try:
                    t1 = time.time()
                    performance_data = get_performance_summary_new(
                        company_name=company_name,
                        start_date=start_date,
                        end_date=end_date,
                        user_id=user_id
                    )
                    t2 = time.time()
                    timing_log["performance_summary"] = round(t2-t1, 3)
                    
                    latest_update = None
                    if performance_data:
                        for row in performance_data:
                            if row.get("updated_at"):
                                if hasattr(row["updated_at"], 'isoformat'):
                                    latest_update = row["updated_at"].isoformat()
                                else:
                                    latest_update = str(row["updated_at"])
                                break
                    
                    return ("performance_summary", performance_data[:100], len(performance_data), latest_update)
                except Exception as e:
                    print(f"[ERROR] Performance Summary ì˜¤ë¥˜: {type(e).__name__}: {str(e)}")
                    return ("performance_summary", [], 0, None)
            
            fetch_tasks.append(executor.submit(fetch_performance))
            
            # 2. Cafe24 Sales
            def fetch_cafe24_sales():
                try:
                    t1 = time.time()
                    result = get_cafe24_sales_data(
                        company_name, period, start_date, end_date,
                        date_type, date_sort, limit=30, page=1, user_id=user_id
                    )
                    t2 = time.time()
                    timing_log["cafe24_sales"] = round(t2-t1, 3)
                    return ("cafe24_sales", result.get("rows", []), result.get("total_count", 0))
                except Exception as e:
                    print(f"[ERROR] Cafe24 Sales ì˜¤ë¥˜: {type(e).__name__}: {str(e)}")
                    return ("cafe24_sales", [], 0)
            
            fetch_tasks.append(executor.submit(fetch_cafe24_sales))
            
            # 3. Cafe24 Product Sales
            def fetch_cafe24_product_sales():
                try:
                    t1 = time.time()
                    result = get_cafe24_product_sales(
                        company_name, period, start_date, end_date,
                        sort_by=sort_by, limit=13, page=1, user_id=user_id
                    )
                    t2 = time.time()
                    timing_log["cafe24_product_sales"] = round(t2-t1, 3)
                    return ("cafe24_product_sales", result.get("rows", []), result.get("total_count", 0))
                except Exception as e:
                    print(f"[ERROR] Cafe24 Product Sales ì˜¤ë¥˜: {type(e).__name__}: {str(e)}")
                    return ("cafe24_product_sales", [], 0)
            
            fetch_tasks.append(executor.submit(fetch_cafe24_product_sales))
            
            # 4. GA4 Source Summary
            def fetch_ga4_source_summary():
                try:
                    t1 = time.time()
                    if not start_date or not end_date:
                        print(f"[ERROR] GA4 Source Summary - start_date ë˜ëŠ” end_dateê°€ ì—†ìŠµë‹ˆë‹¤!")
                        return ("ga4_source_summary", [], 0)
                    
                    cache_buster = data.get('_cache_buster')
                    data_rows = get_ga4_source_summary(company_name, start_date, end_date, limit=100, _cache_buster=cache_buster)
                    t2 = time.time()
                    timing_log["ga4_source_summary"] = round(t2-t1, 3)
                    return ("ga4_source_summary", data_rows[:100], len(data_rows))
                except Exception as e:
                    print(f"[ERROR] GA4 Source Summary ì˜¤ë¥˜: {type(e).__name__}: {str(e)}")
                    return ("ga4_source_summary", [], 0)
            
            fetch_tasks.append(executor.submit(fetch_ga4_source_summary))
            
            # 5. ViewItem Summary
            def fetch_viewitem_summary():
                try:
                    t1 = time.time()
                    if not start_date or not end_date:
                        print(f"[ERROR] ViewItem Summary - start_date ë˜ëŠ” end_dateê°€ ì—†ìŠµë‹ˆë‹¤!")
                        return ("viewitem_summary", [], 0)
                    
                    data_rows = get_viewitem_summary(company_name, start_date, end_date, limit=500)
                    t2 = time.time()
                    timing_log["viewitem_summary"] = round(t2-t1, 3)
                    return ("viewitem_summary", data_rows, len(data_rows))
                except Exception as e:
                    print(f"[ERROR] ViewItem Summary ì˜¤ë¥˜: {type(e).__name__}: {str(e)}")
                    return ("viewitem_summary", [], 0)
            
            fetch_tasks.append(executor.submit(fetch_viewitem_summary))
            
            # 6. Monthly Net Sales & Visitors
            def fetch_monthly_net_sales_visitors():
                try:
                    t1 = time.time()
                    data_rows = get_monthly_net_sales_visitors(company_name)
                    t2 = time.time()
                    timing_log["monthly_net_sales_visitors"] = round(t2-t1, 3)
                    return ("monthly_net_sales_visitors", data_rows, len(data_rows))
                except Exception as e:
                    print(f"[ERROR] Monthly Net Sales Visitors ì˜¤ë¥˜: {type(e).__name__}: {str(e)}")
                    return ("monthly_net_sales_visitors", [], 0)
            
            fetch_tasks.append(executor.submit(fetch_monthly_net_sales_visitors))
            
            # 7. Platform Sales Summary
            def fetch_platform_sales_summary():
                try:
                    t1 = time.time()
                    from ..services.platform_sales_summary import get_platform_sales_by_day
                    _company_names = company_name if isinstance(company_name, list) else [company_name]
                    
                    if not start_date or not end_date:
                        print(f"[ERROR] Platform Sales Summary - start_date ë˜ëŠ” end_dateê°€ ì—†ìŠµë‹ˆë‹¤!")
                        return ("platform_sales_summary", [], 0)
                    
                    data_rows = get_platform_sales_by_day(
                        company_names=_company_names,
                        start_date=start_date,
                        end_date=end_date,
                        date_type=platform_date_type,
                        date_sort=platform_date_sort
                    )
                    t2 = time.time()
                    timing_log["platform_sales_summary"] = round(t2-t1, 3)
                    return ("platform_sales_summary", data_rows, len(data_rows))
                except Exception as e:
                    print(f"[ERROR] Platform Sales Summary ì˜¤ë¥˜: {type(e).__name__}: {str(e)}")
                    return ("platform_sales_summary", [], 0)
            
            fetch_tasks.append(executor.submit(fetch_platform_sales_summary))
            
            # 8. Platform Sales Ratio
            def fetch_platform_sales_ratio():
                try:
                    t1 = time.time()
                    from ..services.platform_sales_summary import get_platform_sales_ratio
                    _company_names = company_name if isinstance(company_name, list) else [company_name]
                    
                    if not start_date or not end_date:
                        print(f"[ERROR] Platform Sales Ratio - start_date ë˜ëŠ” end_dateê°€ ì—†ìŠµë‹ˆë‹¤!")
                        return ("platform_sales_ratio", [])
                    
                    data_rows = get_platform_sales_ratio(
                        company_names=_company_names,
                        start_date=start_date,
                        end_date=end_date
                    )
                    t2 = time.time()
                    timing_log["platform_sales_ratio"] = round(t2-t1, 3)
                    return ("platform_sales_ratio", data_rows)
                except Exception as e:
                    print(f"[ERROR] Platform Sales Ratio ì˜¤ë¥˜: {type(e).__name__}: {str(e)}")
                    return ("platform_sales_ratio", [])
            
            fetch_tasks.append(executor.submit(fetch_platform_sales_ratio))
            
            # 9. Product Sales Ratio
            def fetch_product_sales_ratio():
                try:
                    t1 = time.time()
                    from ..services.product_sales_ratio import get_product_sales_ratio
                    _company_names = company_name if isinstance(company_name, list) else [company_name]
                    
                    if not start_date or not end_date:
                        print(f"[ERROR] Product Sales Ratio - start_date ë˜ëŠ” end_dateê°€ ì—†ìŠµë‹ˆë‹¤!")
                        return ("product_sales_ratio", [])
                    
                    data_rows = get_product_sales_ratio(
                        _company_names, start_date, end_date, limit=50, user_id=user_id
                    )
                    t2 = time.time()
                    timing_log["product_sales_ratio"] = round(t2-t1, 3)
                    return ("product_sales_ratio", data_rows)
                except Exception as e:
                    print(f"[ERROR] Product Sales Ratio ì˜¤ë¥˜: {type(e).__name__}: {str(e)}")
                    return ("product_sales_ratio", [])
            
            fetch_tasks.append(executor.submit(fetch_product_sales_ratio))

        # âœ… ê²°ê³¼ ìˆ˜ì§‘
        for future in fetch_tasks:
            try:
                result = future.result()
                if result[0] == "performance_summary":
                    response_data["performance_summary"] = result[1]
                    response_data["performance_summary_total_count"] = result[2]
                    response_data["latest_update"] = result[3]
                elif result[0] == "cafe24_sales":
                    response_data["cafe24_sales"] = result[1]
                    response_data["cafe24_sales_total_count"] = result[2]
                elif result[0] == "cafe24_product_sales":
                    response_data["cafe24_product_sales"] = result[1]
                    response_data["cafe24_product_sales_total_count"] = result[2]
                elif result[0] == "ga4_source_summary":
                    response_data["ga4_source_summary"] = result[1]
                    response_data["ga4_source_summary_total_count"] = result[2]
                elif result[0] == "viewitem_summary":
                    response_data["viewitem_summary"] = result[1]
                    response_data["viewitem_summary_total_count"] = result[2]
                elif result[0] == "monthly_net_sales_visitors":
                    response_data["monthly_net_sales_visitors"] = result[1]
                    response_data["monthly_net_sales_visitors_total_count"] = result[2]
                elif result[0] == "platform_sales_summary":
                    response_data["platform_sales_summary"] = result[1]
                    response_data["platform_sales_summary_total_count"] = result[2]
                elif result[0] == "platform_sales_ratio":
                    response_data["platform_sales_ratio"] = result[1]
                elif result[0] == "product_sales_ratio":
                    response_data["product_sales_ratio"] = result[1]
            except Exception as e:
                print(f"[ERROR] Future ê²°ê³¼ ì²˜ë¦¬ ì˜¤ë¥˜: {type(e).__name__}: {str(e)}")
                # ê°œë³„ ì‹¤íŒ¨ëŠ” ë¬´ì‹œí•˜ê³  ê³„ì† ì§„í–‰

        t_end = time.time()
        print("[BATCH_API] /dashboard/get_batch_dashboard_data timing:", timing_log, "total:", round(t_end-t0, 3), "s")
        return jsonify(response_data), 200

    except TypeError as te:
        print(f"[ERROR] Batch API ìš”ì²­ ë°ì´í„° íƒ€ì… ì˜¤ë¥˜: {te}")
        return jsonify({"status": "error", "message": f"ì˜ëª»ëœ ìš”ì²­ í˜•ì‹: {str(te)}"}), 400

    except Exception as e:
        print(f"[ERROR] Batch API ë°ì´í„° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return jsonify({"status": "error", "message": f"ë°ì´í„° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"}), 500


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ“Œ 29CM íŠ¸ë Œë“œ API
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@data_blueprint.route("/trend", methods=["POST"])
def get_trend_data():
    """29CM íŠ¸ë Œë“œ ë°ì´í„° ì¡°íšŒ (ìŠ¤ëƒ…ìƒ· ìš°ì„ , ì—†ìœ¼ë©´ BigQuery ì¡°íšŒ)"""
    try:
        data = request.get_json() or {}
        tab_names = data.get("tab_names")  # ë¦¬ìŠ¤íŠ¸ë¡œ ë°›ì•„ì„œ ì—¬ëŸ¬ íƒ­ í•œ ë²ˆì— ì²˜ë¦¬
        tab_name = data.get("tab_name")  # ë‹¨ì¼ íƒ­ (í•˜ìœ„ í˜¸í™˜)
        trend_type = data.get("trend_type", "all")  # "rising", "new_entry", "rank_drop", "all"
        company_name = data.get("company_name")  # í˜„ì¬ ë¡œê·¸ì¸í•œ ì—…ì²´ëª… (ìì‚¬ëª° í•„í„°ë§ìš©)
        
        # ì£¼ì°¨ ì •ë³´ ì¡°íšŒ (ìŠ¤ëƒ…ìƒ· ê²½ë¡œ ìƒì„±ì„ ìœ„í•´)
        current_week = get_current_week_info()
        if not current_week:
            return jsonify({"status": "error", "message": "ì£¼ì°¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}), 404
        
        # ìŠ¤ëƒ…ìƒ·ì—ì„œ ë¡œë“œ ì‹œë„ (ìš°ì„ ìˆœìœ„ 1: GCS ë²„í‚·)
        # âœ… ì—…ì²´ëª… í´ë” êµ¬ì¡° ì‚¬ìš©
        snapshot_data = load_trend_snapshot_from_gcs(current_week, company_name) if company_name else None
        
        if snapshot_data:
            # ìŠ¤ëƒ…ìƒ· ë°ì´í„° ì‚¬ìš© (GCS ë²„í‚·ì—ì„œ ë¡œë“œ ì„±ê³µ)
            print(f"[INFO] âœ… GCS ìŠ¤ëƒ…ìƒ·ì—ì„œ íŠ¸ë Œë“œ ë°ì´í„° ë¡œë“œ ì„±ê³µ: {current_week}")
            
            if tab_names and isinstance(tab_names, list):
                # ì—¬ëŸ¬ íƒ­ ì²˜ë¦¬
                # AI ë¦¬í¬íŠ¸ í•„í„°ë§ (í˜„ì¬ ì—…ì²´ì— í•´ë‹¹í•˜ëŠ” ìì‚¬ëª° ì„¹ì…˜ë§Œ í¬í•¨)
                insights = snapshot_data.get("insights", {})
                
                # âœ… ë¦¬í¬íŠ¸ê°€ ìˆìœ¼ë©´ ë¬´ì¡°ê±´ í‘œì‹œ (Section 1ë§Œ í•„í„°ë§)
                # ë¸Œëœë“œ ì²´í¬ì™€ ê´€ê³„ì—†ì´ ë¦¬í¬íŠ¸ëŠ” í•­ìƒ ë°˜í™˜
                if company_name and insights.get("analysis_report"):
                    # ë¦¬í¬íŠ¸ê°€ ìˆìœ¼ë©´ Section 1ë§Œ í•„í„°ë§í•˜ê³  í•­ìƒ ë°˜í™˜
                    analysis_report = insights.get("analysis_report", "")
                    filtered_report = filter_ai_report_by_company(
                        analysis_report,
                        company_name.lower() if isinstance(company_name, str) else company_name
                    )
                    insights = insights.copy()
                    insights["analysis_report"] = filtered_report
                elif company_name:
                    # company_nameì´ ìˆì§€ë§Œ insightsì— analysis_reportê°€ ì—†ëŠ” ê²½ìš°
                    # insights ìì²´ê°€ ì—†ìœ¼ë©´ ë¹ˆ ê°ì²´ ìœ ì§€
                    if not insights:
                        insights = {}
                
                result = {
                    "status": "success",
                    "current_week": snapshot_data.get("current_week", current_week),
                    "tabs_data": {},
                    "insights": insights  # í•„í„°ë§ëœ AI ë¶„ì„ ë¦¬í¬íŠ¸ í¬í•¨
                }
                
                for tab in tab_names:
                    tab_data = snapshot_data.get("tabs_data", {}).get(tab, {})
                    if trend_type == "all":
                        result["tabs_data"][tab] = tab_data
                    else:
                        filtered_data = {}
                        if trend_type == "rising" and "rising_star" in tab_data:
                            filtered_data["rising_star"] = tab_data["rising_star"]
                        if trend_type == "new_entry" and "new_entry" in tab_data:
                            filtered_data["new_entry"] = tab_data["new_entry"]
                        if trend_type == "rank_drop" and "rank_drop" in tab_data:
                            filtered_data["rank_drop"] = tab_data["rank_drop"]
                        result["tabs_data"][tab] = filtered_data
                
                return jsonify(result), 200
            else:
                # ë‹¨ì¼ íƒ­ ì²˜ë¦¬ (í•˜ìœ„ í˜¸í™˜)
                tab_name = tab_name or "ì „ì²´"
                tab_data = snapshot_data.get("tabs_data", {}).get(tab_name, {})
                
                # AI ë¦¬í¬íŠ¸ í•„í„°ë§ (í˜„ì¬ ì—…ì²´ì— í•´ë‹¹í•˜ëŠ” ìì‚¬ëª° ì„¹ì…˜ë§Œ í¬í•¨)
                insights = snapshot_data.get("insights", {})
                
                # âœ… ì—…ì²´ë³„ë¡œ insightsê°€ ì—†ìœ¼ë©´ ë¹ˆ ê°ì²´ ë°˜í™˜ (ë²„í‚·ì´ ì—†ëŠ” ì—…ì²´)
                # insightsì˜ analysis_reportë¥¼ í™•ì¸í•˜ì—¬ í˜„ì¬ ì—…ì²´ì˜ ë¸Œëœë“œê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
                if company_name and insights.get("analysis_report"):
                    # í˜„ì¬ ì—…ì²´ì˜ ë¸Œëœë“œëª… ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
                    company_ko = get_company_korean_name(company_name.lower())
                    company_brands = []
                    if company_ko and COMPANY_MAPPING_AVAILABLE:
                        company_info = COMPANY_MAPPING.get(company_name.lower(), {})
                        company_brands = company_info.get("brands", [])
                    
                    # insights ë¦¬í¬íŠ¸ì— í˜„ì¬ ì—…ì²´ì˜ ë¸Œëœë“œê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
                    analysis_report = insights.get("analysis_report", "")
                    has_company_brand = False
                    if company_ko and analysis_report:
                        # ë¦¬í¬íŠ¸ì— í˜„ì¬ ì—…ì²´ì˜ ë¸Œëœë“œëª…ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
                        for brand in company_brands:
                            if brand in analysis_report:
                                has_company_brand = True
                                break
                        # í•œê¸€ëª…ë„ í™•ì¸
                        if company_ko in analysis_report:
                            has_company_brand = True
                    
                    if has_company_brand:
                        # í˜„ì¬ ì—…ì²´ì˜ ë¸Œëœë“œê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ í•„í„°ë§
                        filtered_report = filter_ai_report_by_company(
                            analysis_report,
                            company_name.lower() if isinstance(company_name, str) else company_name
                        )
                        insights = insights.copy()
                        insights["analysis_report"] = filtered_report
                    else:
                        # í˜„ì¬ ì—…ì²´ì˜ ë¸Œëœë“œê°€ í¬í•¨ë˜ì–´ ìˆì§€ ì•Šìœ¼ë©´ ë¹ˆ ê°ì²´ ë°˜í™˜
                        insights = {}
                elif company_name:
                    # í•´ë‹¹ ì—…ì²´ì˜ insightsê°€ ì—†ìœ¼ë©´ ë¹ˆ ê°ì²´ë¡œ ì„¤ì •
                    insights = {}
                elif company_name:
                    # í•´ë‹¹ ì—…ì²´ì˜ insightsê°€ ì—†ìœ¼ë©´ ë¹ˆ ê°ì²´ë¡œ ì„¤ì •
                    insights = {}
                
                result = {
                    "status": "success",
                    "tab_name": tab_name,
                    "current_week": snapshot_data.get("current_week", current_week),
                    "insights": insights  # í•„í„°ë§ëœ AI ë¶„ì„ ë¦¬í¬íŠ¸ í¬í•¨
                }
                
                if trend_type == "all":
                    result["rising_star"] = tab_data.get("rising_star", [])
                    result["new_entry"] = tab_data.get("new_entry", [])
                    result["rank_drop"] = tab_data.get("rank_drop", [])
                else:
                    if trend_type == "rising" or trend_type == "all":
                        result["rising_star"] = tab_data.get("rising_star", [])
                    if trend_type == "new_entry" or trend_type == "all":
                        result["new_entry"] = tab_data.get("new_entry", [])
                    if trend_type == "rank_drop" or trend_type == "all":
                        result["rank_drop"] = tab_data.get("rank_drop", [])
                
                return jsonify(result), 200
        else:
            # ìŠ¤ëƒ…ìƒ·ì´ ì—†ìœ¼ë©´ BigQueryì—ì„œ ì¡°íšŒ (Fallback)
            print(f"[WARN] âš ï¸ GCS ìŠ¤ëƒ…ìƒ· ì—†ìŒ, BigQueryì—ì„œ ì§ì ‘ ì¡°íšŒ (ë¹„ìš© ë°œìƒ): {current_week}")
            
            if tab_names and isinstance(tab_names, list):
                # ì—¬ëŸ¬ íƒ­ ë°ì´í„°ë¥¼ í•œ ë²ˆì— ë°˜í™˜
                result = {
                    "status": "success",
                    "tabs_data": {},
                    "current_week": current_week
                }
                
                # ê° íƒ­ë³„ ë°ì´í„° ì¡°íšŒ
                for tab in tab_names:
                    tab_data = {}
                    if trend_type == "rising" or trend_type == "all":
                        tab_data["rising_star"] = get_rising_star(tab)
                    if trend_type == "new_entry" or trend_type == "all":
                        tab_data["new_entry"] = get_new_entry(tab)
                    if trend_type == "rank_drop" or trend_type == "all":
                        tab_data["rank_drop"] = get_rank_drop(tab)
                    result["tabs_data"][tab] = tab_data
                
                return jsonify(result), 200
            else:
                # ë‹¨ì¼ íƒ­ ì²˜ë¦¬ (í•˜ìœ„ í˜¸í™˜)
                tab_name = tab_name or "ì „ì²´"
                result = {
                    "status": "success",
                    "tab_name": tab_name,
                    "current_week": current_week
                }
                
                # íŠ¸ë Œë“œ íƒ€ì…ë³„ ë°ì´í„° ì¡°íšŒ
                if trend_type == "rising" or trend_type == "all":
                    result["rising_star"] = get_rising_star(tab_name)
                
                if trend_type == "new_entry" or trend_type == "all":
                    result["new_entry"] = get_new_entry(tab_name)
                
                if trend_type == "rank_drop" or trend_type == "all":
                    result["rank_drop"] = get_rank_drop(tab_name)
                
                return jsonify(result), 200
        
    except Exception as e:
        print(f"[ERROR] get_trend_data ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({"status": "error", "message": str(e)}), 500


@data_blueprint.route("/trend/snapshot/create", methods=["POST"])
def create_trend_snapshot():
    """íŠ¸ë Œë“œ ìŠ¤ëƒ…ìƒ· ìƒì„± (ìˆ˜ë™ ì‹¤í–‰ìš©, ìŠ¤ì¼€ì¤„ ì¶”ê°€ ì˜ˆì •)"""
    try:
        data = request.get_json() or {}
        tab_names = data.get("tab_names", [])
        
        if not tab_names:
            # ê¸°ë³¸ íƒ­ ëª©ë¡ ì¡°íšŒ
            tab_names = get_available_tabs()
        
        # ì£¼ì°¨ ì •ë³´ ì¡°íšŒ
        current_week = get_current_week_info()
        if not current_week:
            return jsonify({"status": "error", "message": "ì£¼ì°¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}), 404
        
        # ëª¨ë“  íƒ­ ë°ì´í„° ì¡°íšŒ (ìºì‹œ ë¬´ì‹œí•˜ê³  ì§ì ‘ ì¡°íšŒ)
        print(f"[INFO] ìŠ¤ëƒ…ìƒ· ìƒì„± ì‹œì‘: {current_week}")
        tabs_data = get_all_tabs_data_from_bigquery(tab_names)
        
        # GCSì— ì €ì¥
        success = save_trend_snapshot_to_gcs(current_week, tabs_data, current_week)
        
        if success:
            return jsonify({
                "status": "success",
                "message": f"ìŠ¤ëƒ…ìƒ· ìƒì„± ì™„ë£Œ: {current_week}",
                "run_id": current_week,
                "tabs_count": len(tab_names)
            }), 200
        else:
            return jsonify({"status": "error", "message": "ìŠ¤ëƒ…ìƒ· ì €ì¥ ì‹¤íŒ¨"}), 500
        
    except Exception as e:
        print(f"[ERROR] create_trend_snapshot ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({"status": "error", "message": str(e)}), 500


@data_blueprint.route("/get_meta_token", methods=["POST"])
def get_meta_token():
    """Meta API ì•¡ì„¸ìŠ¤ í† í° ë°˜í™˜ (í´ë¼ì´ì–¸íŠ¸ì—ì„œ ì§ì ‘ API í˜¸ì¶œìš©)

    í† í° ì¡°íšŒ ìš°ì„ ìˆœìœ„:
    1. í™˜ê²½ ë³€ìˆ˜ META_SYSTEM_USER_TOKEN (ë§ˆì¼€íŒ… ëŒ€í–‰ì‚¬ ë§ˆìŠ¤í„° ê¶Œí•œ)
    2. í™˜ê²½ ë³€ìˆ˜ META_LONG_TOKEN (ê¸°ì¡´ ë°©ì‹)
    3. ì„¸ì…˜ì—ì„œ meta_token
    """
    try:
        # ê°œë°œ í™˜ê²½ ì²´í¬ (FLASK_ENV=development ì‹œ ì¸ì¦ ìŠ¤í‚µ)
        is_dev = os.getenv("FLASK_ENV") == "development"

        # 1ìˆœìœ„: í™˜ê²½ ë³€ìˆ˜ META_SYSTEM_USER_TOKEN (ë§ˆì¼€íŒ… ëŒ€í–‰ì‚¬ ë§ˆìŠ¤í„° ê¶Œí•œ)
        access_token = os.getenv("META_SYSTEM_USER_TOKEN")
        if access_token:
            print(f"[INFO] META_SYSTEM_USER_TOKEN í™˜ê²½ ë³€ìˆ˜ì—ì„œ í† í° ë°œê²¬")
            print(f"[INFO] í† í° ë°˜í™˜ ì„±ê³µ: {access_token[:10]}...")
            return jsonify({
                "status": "success",
                "access_token": access_token
            }), 200

        # 2ìˆœìœ„: ê¸°ì¡´ load_access_token (META_LONG_TOKEN)
        from ..services.meta_demo_service import load_access_token
        access_token = load_access_token()
        if access_token:
            print(f"[INFO] META_LONG_TOKEN í™˜ê²½ ë³€ìˆ˜ì—ì„œ í† í° ë°œê²¬")
            print(f"[INFO] í† í° ë°˜í™˜ ì„±ê³µ: {access_token[:10]}...")
            return jsonify({
                "status": "success",
                "access_token": access_token
            }), 200

        # 3ìˆœìœ„: ì„¸ì…˜ì—ì„œ í† í° í™•ì¸
        access_token = session.get("meta_token")
        if access_token:
            print(f"[INFO] ì„¸ì…˜ì—ì„œ í† í° ë°œê²¬")
            print(f"[INFO] í† í° ë°˜í™˜ ì„±ê³µ: {access_token[:10]}...")
            return jsonify({
                "status": "success",
                "access_token": access_token
            }), 200

        # í† í° ì—†ìŒ
        print("[ERROR] Meta ì•¡ì„¸ìŠ¤ í† í°ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (ëª¨ë“  ì†ŒìŠ¤ í™•ì¸ ì™„ë£Œ)")
        return jsonify({"status": "error", "message": "Meta ì•¡ì„¸ìŠ¤ í† í°ì´ ì—†ìŠµë‹ˆë‹¤"}), 401

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({"status": "error", "message": str(e)}), 500


@data_blueprint.route("/generate_ad_preview", methods=["POST"])
def generate_ad_preview():
    """Meta APIë¥¼ ì‚¬ìš©í•˜ì—¬ ê´‘ê³  ë¯¸ë¦¬ë³´ê¸° ìƒì„±

    ìš”ì²­ íŒŒë¼ë¯¸í„°:
    - account_id: ê´‘ê³  ê³„ì • ID
    - ad_format: INSTAGRAM_STANDARD, INSTAGRAM_REELS, MOBILE_FEED_STANDARD
    - media_type: image ë˜ëŠ” video
    - image_hash: ì´ë¯¸ì§€ í•´ì‹œ (ì´ë¯¸ì§€ìš©)
    - video_id: ë¹„ë””ì˜¤ ID (ë™ì˜ìƒìš©)
    - link: ì›¹ì‚¬ì´íŠ¸ URL
    - message: Primary Text
    - name: Headline
    - description: Description
    - cta_type: Call to Action íƒ€ì…
    - is_carousel: ìŠ¬ë¼ì´ë“œ ì—¬ë¶€ (ì„ íƒ)
    - cards: ìŠ¬ë¼ì´ë“œ ì¹´ë“œ ë°°ì—´ (ì„ íƒ)
    """
    import requests
    import json

    print("[PREVIEW] ===== ê´‘ê³  ë¯¸ë¦¬ë³´ê¸° ìƒì„± ì‹œì‘ =====")

    try:
        data = request.get_json()
        print(f"[PREVIEW] ìš”ì²­ ë°ì´í„°: {json.dumps(data, indent=2, ensure_ascii=False)}")

        # í•„ìˆ˜ íŒŒë¼ë¯¸í„° í™•ì¸
        account_id = data.get('account_id')
        ad_format = data.get('ad_format', 'INSTAGRAM_STANDARD')
        media_type = data.get('media_type', 'image')

        if not account_id:
            print("[PREVIEW] ERROR: account_id ëˆ„ë½")
            return jsonify({"status": "error", "message": "account_idê°€ í•„ìš”í•©ë‹ˆë‹¤"}), 400

        # ì•¡ì„¸ìŠ¤ í† í° ê°€ì ¸ì˜¤ê¸°
        access_token = os.getenv("META_SYSTEM_USER_TOKEN") or os.getenv("META_LONG_TOKEN")
        if not access_token:
            print("[PREVIEW] ERROR: ì•¡ì„¸ìŠ¤ í† í° ì—†ìŒ")
            return jsonify({"status": "error", "message": "Meta ì•¡ì„¸ìŠ¤ í† í°ì´ ì—†ìŠµë‹ˆë‹¤"}), 401

        print(f"[PREVIEW] í† í° í™•ì¸: {access_token[:15]}...")

        # BigQueryì—ì„œ page_id, instagram_user_id ì¡°íšŒ
        bq_client = bigquery.Client()
        mapping_query = """
            SELECT page_id, instagram_user_id
            FROM `ngn_dataset.meta_account_mapping`
            WHERE account_id = @account_id
            LIMIT 1
        """
        job_config = bigquery.QueryJobConfig(
            query_parameters=[
                bigquery.ScalarQueryParameter("account_id", "STRING", account_id)
            ]
        )
        mapping_result = bq_client.query(mapping_query, job_config=job_config).result()
        mapping_row = None
        for row in mapping_result:
            mapping_row = row
            break

        page_id = None
        instagram_user_id = None

        if mapping_row:
            # ê°’ trim ë° ìœ íš¨ì„± ê²€ì‚¬
            page_id = str(mapping_row.page_id).strip() if mapping_row.page_id else None
            instagram_user_id = str(mapping_row.instagram_user_id).strip() if mapping_row.instagram_user_id else None
            print(f"[PREVIEW] BigQueryì—ì„œ ì¡°íšŒ - page_id: '{page_id}', instagram_user_id: '{instagram_user_id}'")
        else:
            print(f"[PREVIEW] BigQueryì— account_id={account_id} ë§¤í•‘ ì—†ìŒ, Meta APIë¡œ í´ë°±")
            # í´ë°±: Meta APIì—ì„œ Page ID ì¡°íšŒ
            pages_url = "https://graph.facebook.com/v24.0/me/accounts"
            pages_response = requests.get(pages_url, params={
                "access_token": access_token,
                "fields": "id,name"
            }, timeout=10)
            pages_data = pages_response.json()
            print(f"[PREVIEW] Pages ì‘ë‹µ: {json.dumps(pages_data, indent=2)}")

            if 'data' in pages_data and len(pages_data['data']) > 0:
                page_id = pages_data['data'][0]['id']

        if not page_id:
            print("[PREVIEW] ERROR: page_idë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            return jsonify({"status": "error", "message": "ì—°ê²°ëœ Facebook í˜ì´ì§€ê°€ ì—†ìŠµë‹ˆë‹¤"}), 400

        # Facebook Pageì—ì„œ ì—°ê²°ëœ Instagram Business Account ì¡°íšŒ (í•­ìƒ ìµœì‹  ì •ë³´)
        try:
            ig_url = f"https://graph.facebook.com/v24.0/{page_id}"
            ig_response = requests.get(ig_url, params={
                "access_token": access_token,
                "fields": "instagram_business_account"
            }, timeout=10)
            ig_data = ig_response.json()
            print(f"[PREVIEW] Page Instagram ì—°ê²° ì¡°íšŒ: {json.dumps(ig_data, indent=2)}")

            if 'instagram_business_account' in ig_data:
                fetched_ig_id = ig_data['instagram_business_account'].get('id')
                if fetched_ig_id:
                    instagram_user_id = fetched_ig_id
                    print(f"[PREVIEW] Pageì—ì„œ Instagram ID ê°€ì ¸ì˜´: {instagram_user_id}")
        except Exception as e:
            print(f"[PREVIEW] Instagram ê³„ì • ì¡°íšŒ ì‹¤íŒ¨: {e}")

        print(f"[PREVIEW] ì‚¬ìš©í•  Page ID: {page_id}, Instagram User ID: {instagram_user_id}")

        # creative_spec êµ¬ì„±
        link = data.get('link', 'https://example.com')
        message = data.get('message', '')
        headline = data.get('name', '')
        description = data.get('description', '')
        cta_type = data.get('cta_type', 'SHOP_NOW')
        image_hash = data.get('image_hash')
        video_id = data.get('video_id')
        is_carousel = data.get('is_carousel', False)
        cards = data.get('cards', [])

        creative_spec = {
            "object_story_spec": {
                "page_id": page_id
            }
        }

        # Instagram í¬ë§·ì¸ ê²½ìš° instagram_user_id ì¶”ê°€ (Meta API v24.0 ê·œê²©)
        is_instagram_format = ad_format in ['INSTAGRAM_STANDARD', 'INSTAGRAM_REELS', 'INSTAGRAM_STORY']
        if is_instagram_format and instagram_user_id:
            creative_spec["object_story_spec"]["instagram_user_id"] = instagram_user_id
            print(f"[PREVIEW] Instagram í¬ë§· - instagram_user_id ì¶”ê°€: {instagram_user_id}")

        if is_carousel and len(cards) > 1:
            # ìŠ¬ë¼ì´ë“œ (Carousel) ê´‘ê³ 
            print(f"[PREVIEW] ìŠ¬ë¼ì´ë“œ ê´‘ê³  ìƒì„±: {len(cards)}ê°œ ì¹´ë“œ")
            child_attachments = []
            for i, card in enumerate(cards):
                attachment = {
                    "link": card.get('link', link),
                    "name": card.get('name', headline),
                    "description": card.get('description', description),
                    "call_to_action": {"type": cta_type}
                }
                # video_idë¥¼ ë¨¼ì € í™•ì¸ (ë™ì˜ìƒ ìš°ì„ )
                if card.get('video_id'):
                    attachment["video_id"] = card['video_id']
                elif card.get('image_hash'):
                    attachment["image_hash"] = card['image_hash']
                child_attachments.append(attachment)
                print(f"[PREVIEW] ì¹´ë“œ {i+1}: {attachment}")

            creative_spec["object_story_spec"]["link_data"] = {
                "link": link,
                "message": message,
                "child_attachments": child_attachments,
                "multi_share_optimized": True
            }
        else:
            # ë‹¨ì¼ ì´ë¯¸ì§€/ë™ì˜ìƒ ê´‘ê³ 
            if media_type == 'video' and video_id:
                print(f"[PREVIEW] ë‹¨ì¼ ë™ì˜ìƒ ê´‘ê³ : video_id={video_id}")

                # ë™ì˜ìƒ ì¸ë„¤ì¼ URL ê°€ì ¸ì˜¤ê¸° (Meta API í•„ìˆ˜ ìš”êµ¬ì‚¬í•­)
                thumbnail_url = None
                try:
                    thumb_response = requests.get(
                        f"https://graph.facebook.com/v24.0/{video_id}",
                        params={
                            "access_token": access_token,
                            "fields": "thumbnails"
                        },
                        timeout=10
                    )
                    thumb_data = thumb_response.json()
                    print(f"[PREVIEW] ì¸ë„¤ì¼ ì‘ë‹µ: {json.dumps(thumb_data, indent=2)}")

                    if 'thumbnails' in thumb_data and 'data' in thumb_data['thumbnails']:
                        thumbnails = thumb_data['thumbnails']['data']
                        if thumbnails:
                            thumbnail_url = thumbnails[0].get('uri')
                            print(f"[PREVIEW] ì¸ë„¤ì¼ URL: {thumbnail_url}")
                except Exception as e:
                    print(f"[PREVIEW] ì¸ë„¤ì¼ ì¡°íšŒ ì‹¤íŒ¨: {e}")

                video_data = {
                    "video_id": video_id,
                    "message": message,
                    "title": headline,
                    "link_description": description,
                    "call_to_action": {
                        "type": cta_type,
                        "value": {"link": link}
                    }
                }

                # ì¸ë„¤ì¼ URL ì¶”ê°€ (í•„ìˆ˜)
                if thumbnail_url:
                    video_data["image_url"] = thumbnail_url
                else:
                    # í´ë°±: íˆ¬ëª… 1x1 í”½ì…€ ë˜ëŠ” ê¸°ë³¸ ì´ë¯¸ì§€
                    video_data["image_url"] = "https://via.placeholder.com/1080x1920/000000/000000?text=+"
                    print("[PREVIEW] ì¸ë„¤ì¼ ì—†ìŒ, í”Œë ˆì´ìŠ¤í™€ë” ì‚¬ìš©")

                creative_spec["object_story_spec"]["video_data"] = video_data
            elif image_hash:
                print(f"[PREVIEW] ë‹¨ì¼ ì´ë¯¸ì§€ ê´‘ê³ : image_hash={image_hash}")
                creative_spec["object_story_spec"]["link_data"] = {
                    "image_hash": image_hash,
                    "link": link,
                    "message": message,
                    "name": headline,
                    "description": description,
                    "call_to_action": {"type": cta_type}
                }
            else:
                print("[PREVIEW] ERROR: image_hash ë˜ëŠ” video_id í•„ìš”")
                return jsonify({"status": "error", "message": "ì´ë¯¸ì§€ í•´ì‹œ ë˜ëŠ” ë¹„ë””ì˜¤ IDê°€ í•„ìš”í•©ë‹ˆë‹¤"}), 400

        print(f"[PREVIEW] creative_spec: {json.dumps(creative_spec, indent=2)}")

        # Meta API í˜¸ì¶œ (GET ë°©ì‹ + ì¬ì‹œë„ ë¡œì§)
        from requests.adapters import HTTPAdapter
        from urllib3.util.retry import Retry

        ad_account_id = f"act_{account_id}"
        preview_url = f"https://graph.facebook.com/v24.0/{ad_account_id}/generatepreviews"

        # GET íŒŒë¼ë¯¸í„° êµ¬ì„± (JSON ì••ì¶•ìœ¼ë¡œ URL ê¸¸ì´ ìµœì†Œí™”)
        api_params = {
            "access_token": access_token,
            "creative": json.dumps(creative_spec, separators=(',', ':')),  # ê³µë°± ì œê±°
            "ad_format": ad_format
        }

        print(f"[PREVIEW] API í˜¸ì¶œ (GET): {preview_url}")
        print(f"[PREVIEW] ad_format: {ad_format}")

        # ì¬ì‹œë„ ì „ëµ ì„¤ì • (ìµœëŒ€ 3íšŒ, backoff factor ì ìš©)
        retry_strategy = Retry(
            total=3,
            backoff_factor=1,
            status_forcelist=[429, 500, 502, 503, 504],
            allowed_methods=["GET"]
        )
        adapter = HTTPAdapter(max_retries=retry_strategy)
        session = requests.Session()
        session.mount("https://", adapter)

        response = session.get(preview_url, params=api_params, timeout=30)
        result = response.json()

        print(f"[PREVIEW] API ì‘ë‹µ ìƒíƒœ: {response.status_code}")
        print(f"[PREVIEW] API ì‘ë‹µ: {json.dumps(result, indent=2)}")

        if 'error' in result:
            error_msg = result['error'].get('message', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')
            error_code = result['error'].get('code', '')
            print(f"[PREVIEW] ERROR: {error_code} - {error_msg}")
            return jsonify({
                "status": "error",
                "message": f"Meta API ì˜¤ë¥˜: {error_msg}",
                "error_code": error_code
            }), 400

        if 'data' in result and len(result['data']) > 0:
            preview_html = result['data'][0].get('body', '')
            print(f"[PREVIEW] ë¯¸ë¦¬ë³´ê¸° HTML ê¸¸ì´: {len(preview_html)}")
            print("[PREVIEW] ===== ë¯¸ë¦¬ë³´ê¸° ìƒì„± ì„±ê³µ =====")
            return jsonify({
                "status": "success",
                "preview_html": preview_html
            }), 200
        else:
            print("[PREVIEW] ERROR: ë¯¸ë¦¬ë³´ê¸° ë°ì´í„° ì—†ìŒ")
            return jsonify({
                "status": "error",
                "message": "ë¯¸ë¦¬ë³´ê¸° ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤"
            }), 400

    except requests.exceptions.Timeout:
        print("[PREVIEW] ERROR: API ìš”ì²­ íƒ€ì„ì•„ì›ƒ")
        return jsonify({"status": "error", "message": "Meta API ìš”ì²­ ì‹œê°„ ì´ˆê³¼"}), 504
    except requests.exceptions.RequestException as e:
        print(f"[PREVIEW] ERROR: ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ - {e}")
        return jsonify({"status": "error", "message": f"ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜: {str(e)}"}), 500
    except Exception as e:
        import traceback
        traceback.print_exc()
        print(f"[PREVIEW] ERROR: ì˜ˆì™¸ ë°œìƒ - {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


@data_blueprint.route("/trend/tabs", methods=["GET"])
def get_trend_tabs():
    """ì‚¬ìš© ê°€ëŠ¥í•œ íƒ­ ëª©ë¡ ì¡°íšŒ"""
    try:
        tabs = get_available_tabs()
        return jsonify({"status": "success", "tabs": tabs}), 200
    except Exception as e:
        print(f"[ERROR] get_trend_tabs ì‹¤íŒ¨: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ“Œ Ably íŠ¸ë Œë“œ API
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@data_blueprint.route("/trend/ably", methods=["POST"])
def get_ably_trend_data():
    """Ably íŠ¸ë Œë“œ ë°ì´í„° ì¡°íšŒ (ìŠ¤ëƒ…ìƒ· ìš°ì„ , ì—†ìœ¼ë©´ BigQuery ì¡°íšŒ)"""
    try:
        data = request.get_json() or {}
        tab_names = data.get("tab_names")  # ë¦¬ìŠ¤íŠ¸ë¡œ ë°›ì•„ì„œ ì—¬ëŸ¬ íƒ­ í•œ ë²ˆì— ì²˜ë¦¬
        tab_name = data.get("tab_name")  # ë‹¨ì¼ íƒ­ (í•˜ìœ„ í˜¸í™˜)
        trend_type = data.get("trend_type", "all")  # "rising", "new_entry", "rank_drop", "all"
        company_name = data.get("company_name")  # í˜„ì¬ ë¡œê·¸ì¸í•œ ì—…ì²´ëª… (ìì‚¬ëª° í•„í„°ë§ìš©)
        
        # ì£¼ì°¨ ì •ë³´ ì¡°íšŒ (ìŠ¤ëƒ…ìƒ· ê²½ë¡œ ìƒì„±ì„ ìœ„í•´)
        current_week = get_ably_current_week_info()
        if not current_week:
            return jsonify({"status": "error", "message": "ì£¼ì°¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}), 404
        
        # ìŠ¤ëƒ…ìƒ·ì—ì„œ ë¡œë“œ ì‹œë„ (ìš°ì„ ìˆœìœ„ 1: GCS ë²„í‚·)
        # âœ… ì—…ì²´ëª… í´ë” êµ¬ì¡° ì‚¬ìš©
        snapshot_data = load_ably_trend_snapshot_from_gcs(current_week, company_name) if company_name else None
        
        if snapshot_data:
            # ìŠ¤ëƒ…ìƒ· ë°ì´í„° ì‚¬ìš© (GCS ë²„í‚·ì—ì„œ ë¡œë“œ ì„±ê³µ)
            print(f"[INFO] âœ… GCS ìŠ¤ëƒ…ìƒ·ì—ì„œ Ably íŠ¸ë Œë“œ ë°ì´í„° ë¡œë“œ ì„±ê³µ: {current_week}")
            
            if tab_names and isinstance(tab_names, list):
                # ì—¬ëŸ¬ íƒ­ ì²˜ë¦¬
                # AI ë¦¬í¬íŠ¸ í•„í„°ë§ (í˜„ì¬ ì—…ì²´ì— í•´ë‹¹í•˜ëŠ” ìì‚¬ëª° ì„¹ì…˜ë§Œ í¬í•¨)
                insights = snapshot_data.get("insights", {})
                
                # âœ… ë¦¬í¬íŠ¸ê°€ ìˆìœ¼ë©´ ë¬´ì¡°ê±´ í‘œì‹œ (Section 1ë§Œ í•„í„°ë§)
                # ë¸Œëœë“œ ì²´í¬ì™€ ê´€ê³„ì—†ì´ ë¦¬í¬íŠ¸ëŠ” í•­ìƒ ë°˜í™˜
                if company_name and insights.get("analysis_report"):
                    # ë¦¬í¬íŠ¸ê°€ ìˆìœ¼ë©´ Section 1ë§Œ í•„í„°ë§í•˜ê³  í•­ìƒ ë°˜í™˜
                    analysis_report = insights.get("analysis_report", "")
                    filtered_report = filter_ai_report_by_company(
                        analysis_report,
                        company_name.lower() if isinstance(company_name, str) else company_name
                    )
                    insights = insights.copy()
                    insights["analysis_report"] = filtered_report
                elif company_name:
                    # company_nameì´ ìˆì§€ë§Œ insightsì— analysis_reportê°€ ì—†ëŠ” ê²½ìš°
                    # insights ìì²´ê°€ ì—†ìœ¼ë©´ ë¹ˆ ê°ì²´ ìœ ì§€
                    if not insights:
                        insights = {}
                
                result = {
                    "status": "success",
                    "current_week": snapshot_data.get("current_week", current_week),
                    "tabs_data": {},
                    "insights": insights  # í•„í„°ë§ëœ AI ë¶„ì„ ë¦¬í¬íŠ¸ í¬í•¨
                }
                
                for tab in tab_names:
                    tab_data = snapshot_data.get("tabs_data", {}).get(tab, {})
                    if trend_type == "all":
                        result["tabs_data"][tab] = tab_data
                    else:
                        filtered_data = {}
                        if trend_type == "rising" and "rising_star" in tab_data:
                            filtered_data["rising_star"] = tab_data["rising_star"]
                        if trend_type == "new_entry" and "new_entry" in tab_data:
                            filtered_data["new_entry"] = tab_data["new_entry"]
                        if trend_type == "rank_drop" and "rank_drop" in tab_data:
                            filtered_data["rank_drop"] = tab_data["rank_drop"]
                        result["tabs_data"][tab] = filtered_data
                
                return jsonify(result), 200
            else:
                # ë‹¨ì¼ íƒ­ ì²˜ë¦¬ (í•˜ìœ„ í˜¸í™˜)
                tab_name = tab_name or "ìƒì˜"
                tab_data = snapshot_data.get("tabs_data", {}).get(tab_name, {})
                
                # AI ë¦¬í¬íŠ¸ í•„í„°ë§ (í˜„ì¬ ì—…ì²´ì— í•´ë‹¹í•˜ëŠ” ìì‚¬ëª° ì„¹ì…˜ë§Œ í¬í•¨)
                insights = snapshot_data.get("insights", {})
                
                # âœ… ì—…ì²´ë³„ë¡œ insightsê°€ ì—†ìœ¼ë©´ ë¹ˆ ê°ì²´ ë°˜í™˜ (ë²„í‚·ì´ ì—†ëŠ” ì—…ì²´)
                # insightsì˜ analysis_reportë¥¼ í™•ì¸í•˜ì—¬ í˜„ì¬ ì—…ì²´ì˜ ë¸Œëœë“œê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
                if company_name and insights.get("analysis_report"):
                    # í˜„ì¬ ì—…ì²´ì˜ ë¸Œëœë“œëª… ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
                    company_ko = get_company_korean_name(company_name.lower())
                    company_brands = []
                    if company_ko and COMPANY_MAPPING_AVAILABLE:
                        company_info = COMPANY_MAPPING.get(company_name.lower(), {})
                        company_brands = company_info.get("brands", [])
                    
                    # insights ë¦¬í¬íŠ¸ì— í˜„ì¬ ì—…ì²´ì˜ ë¸Œëœë“œê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
                    analysis_report = insights.get("analysis_report", "")
                    has_company_brand = False
                    if company_ko and analysis_report:
                        # ë¦¬í¬íŠ¸ì— í˜„ì¬ ì—…ì²´ì˜ ë¸Œëœë“œëª…ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
                        for brand in company_brands:
                            if brand in analysis_report:
                                has_company_brand = True
                                break
                        # í•œê¸€ëª…ë„ í™•ì¸
                        if company_ko in analysis_report:
                            has_company_brand = True
                    
                    if has_company_brand:
                        # í˜„ì¬ ì—…ì²´ì˜ ë¸Œëœë“œê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ í•„í„°ë§
                        filtered_report = filter_ai_report_by_company(
                            analysis_report,
                            company_name.lower() if isinstance(company_name, str) else company_name
                        )
                        insights = insights.copy()
                        insights["analysis_report"] = filtered_report
                    else:
                        # í˜„ì¬ ì—…ì²´ì˜ ë¸Œëœë“œê°€ í¬í•¨ë˜ì–´ ìˆì§€ ì•Šìœ¼ë©´ ë¹ˆ ê°ì²´ ë°˜í™˜
                        insights = {}
                elif company_name:
                    # í•´ë‹¹ ì—…ì²´ì˜ insightsê°€ ì—†ìœ¼ë©´ ë¹ˆ ê°ì²´ë¡œ ì„¤ì •
                    insights = {}
                
                result = {
                    "status": "success",
                    "tab_name": tab_name,
                    "current_week": snapshot_data.get("current_week", current_week),
                    "insights": insights  # í•„í„°ë§ëœ AI ë¶„ì„ ë¦¬í¬íŠ¸ í¬í•¨
                }
                
                if trend_type == "all":
                    result["rising_star"] = tab_data.get("rising_star", [])
                    result["new_entry"] = tab_data.get("new_entry", [])
                    result["rank_drop"] = tab_data.get("rank_drop", [])
                else:
                    if trend_type == "rising" or trend_type == "all":
                        result["rising_star"] = tab_data.get("rising_star", [])
                    if trend_type == "new_entry" or trend_type == "all":
                        result["new_entry"] = tab_data.get("new_entry", [])
                    if trend_type == "rank_drop" or trend_type == "all":
                        result["rank_drop"] = tab_data.get("rank_drop", [])
                
                return jsonify(result), 200
        else:
            # ìŠ¤ëƒ…ìƒ·ì´ ì—†ìœ¼ë©´ BigQueryì—ì„œ ì¡°íšŒ (Fallback)
            print(f"[WARN] âš ï¸ GCS ìŠ¤ëƒ…ìƒ· ì—†ìŒ, BigQueryì—ì„œ ì§ì ‘ ì¡°íšŒ (ë¹„ìš© ë°œìƒ): {current_week}")
            
            if tab_names and isinstance(tab_names, list):
                # ì—¬ëŸ¬ íƒ­ ë°ì´í„°ë¥¼ í•œ ë²ˆì— ë°˜í™˜
                result = {
                    "status": "success",
                    "tabs_data": {},
                    "current_week": current_week
                }
                
                # ê° íƒ­ë³„ ë°ì´í„° ì¡°íšŒ
                for tab in tab_names:
                    tab_data = {}
                    if trend_type == "rising" or trend_type == "all":
                        tab_data["rising_star"] = get_ably_rising_star(tab)
                    if trend_type == "new_entry" or trend_type == "all":
                        tab_data["new_entry"] = get_ably_new_entry(tab)
                    if trend_type == "rank_drop" or trend_type == "all":
                        tab_data["rank_drop"] = get_ably_rank_drop(tab)
                    result["tabs_data"][tab] = tab_data
                
                return jsonify(result), 200
            else:
                # ë‹¨ì¼ íƒ­ ì²˜ë¦¬ (í•˜ìœ„ í˜¸í™˜)
                tab_name = tab_name or "ìƒì˜"
                result = {
                    "status": "success",
                    "tab_name": tab_name,
                    "current_week": current_week
                }
                
                # íŠ¸ë Œë“œ íƒ€ì…ë³„ ë°ì´í„° ì¡°íšŒ
                if trend_type == "rising" or trend_type == "all":
                    result["rising_star"] = get_ably_rising_star(tab_name)
                
                if trend_type == "new_entry" or trend_type == "all":
                    result["new_entry"] = get_ably_new_entry(tab_name)
                
                if trend_type == "rank_drop" or trend_type == "all":
                    result["rank_drop"] = get_ably_rank_drop(tab_name)
                
                return jsonify(result), 200
        
    except Exception as e:
        print(f"[ERROR] get_ably_trend_data ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({"status": "error", "message": str(e)}), 500


@data_blueprint.route("/trend/ably/snapshot/create", methods=["POST"])
def create_ably_trend_snapshot():
    """Ably íŠ¸ë Œë“œ ìŠ¤ëƒ…ìƒ· ìƒì„± (ìˆ˜ë™ ì‹¤í–‰ìš©, ìŠ¤ì¼€ì¤„ ì¶”ê°€ ì˜ˆì •)"""
    try:
        data = request.get_json() or {}
        tab_names = data.get("tab_names", [])
        
        if not tab_names:
            # ê¸°ë³¸ íƒ­ ëª©ë¡ ì¡°íšŒ
            tab_names = get_ably_available_tabs()
        
        # ì£¼ì°¨ ì •ë³´ ì¡°íšŒ
        current_week = get_ably_current_week_info()
        if not current_week:
            return jsonify({"status": "error", "message": "ì£¼ì°¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}), 404
        
        # ëª¨ë“  íƒ­ ë°ì´í„° ì¡°íšŒ (ìºì‹œ ë¬´ì‹œí•˜ê³  ì§ì ‘ ì¡°íšŒ)
        print(f"[INFO] Ably ìŠ¤ëƒ…ìƒ· ìƒì„± ì‹œì‘: {current_week}")
        tabs_data = get_ably_all_tabs_data_from_bigquery(tab_names)
        
        # GCSì— ì €ì¥ (AI ë¶„ì„ ë¦¬í¬íŠ¸ í¬í•¨)
        success = save_ably_trend_snapshot_to_gcs(current_week, tabs_data, current_week, enable_ai_analysis=True)
        
        if success:
            return jsonify({
                "status": "success",
                "message": f"Ably ìŠ¤ëƒ…ìƒ· ìƒì„± ì™„ë£Œ: {current_week}",
                "run_id": current_week,
                "tabs_count": len(tab_names)
            }), 200
        else:
            return jsonify({"status": "error", "message": "ìŠ¤ëƒ…ìƒ· ì €ì¥ ì‹¤íŒ¨"}), 500
        
    except Exception as e:
        print(f"[ERROR] create_ably_trend_snapshot ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({"status": "error", "message": str(e)}), 500


@data_blueprint.route("/trend/ably/tabs", methods=["GET"])
def get_ably_trend_tabs():
    """ì‚¬ìš© ê°€ëŠ¥í•œ Ably íƒ­ ëª©ë¡ ì¡°íšŒ"""
    try:
        tabs = get_ably_available_tabs()
        return jsonify({"status": "success", "tabs": tabs}), 200
    except Exception as e:
        print(f"[ERROR] get_ably_trend_tabs ì‹¤íŒ¨: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ“Œ 29CM ê²½ìŸì‚¬ ë¹„êµ í˜ì´ì§€ API
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@data_blueprint.route("/compare/29cm/brands", methods=["GET"])
def get_compare_brands():
    """ê²½ìŸì‚¬ ë¸Œëœë“œ ëª©ë¡ ì¡°íšŒ (brandId ê¸°ë°˜)"""
    try:
        company_name = request.args.get("company_name")
        if not company_name:
            return jsonify({"status": "error", "message": "company_name íŒŒë¼ë¯¸í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400

        # ìì‚¬ëª° ë¸Œëœë“œ ID
        own_brand_id = get_own_brand_id(company_name)

        # ê²½ìŸì‚¬ ë¸Œëœë“œ ëª©ë¡
        competitor_brands = get_competitor_brands(company_name)

        return jsonify({
            "status": "success",
            "own_brand_id": own_brand_id,
            "brands": competitor_brands
        }), 200
    except Exception as e:
        print(f"[ERROR] get_compare_brands ì‹¤íŒ¨: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


@data_blueprint.route("/compare/29cm/keywords", methods=["GET"])
def get_compare_keywords_legacy():
    """[DEPRECATED] /compare/29cm/brands ì‚¬ìš© ê¶Œì¥"""
    try:
        company_name = request.args.get("company_name")
        if not company_name:
            return jsonify({"status": "error", "message": "company_name íŒŒë¼ë¯¸í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400

        keywords = get_competitor_keywords(company_name)
        return jsonify({
            "status": "success",
            "keywords": keywords
        }), 200
    except Exception as e:
        print(f"[ERROR] get_compare_keywords ì‹¤íŒ¨: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


@data_blueprint.route("/compare/29cm/search", methods=["POST"])
def get_compare_search_results():
    """ê²½ìŸì‚¬ ê²€ìƒ‰ ê²°ê³¼ ì¡°íšŒ (brand_id ë˜ëŠ” search_keyword ì§€ì›)"""
    try:
        data = request.get_json() or {}
        company_name = data.get("company_name")
        brand_id = data.get("brand_id")  # ìƒˆë¡œìš´ brandId ê¸°ë°˜
        search_keyword = data.get("search_keyword")  # í•˜ìœ„ í˜¸í™˜ì„±
        run_id = data.get("run_id")
        get_run_id_only = data.get("get_run_id_only", False)

        if not company_name:
            return jsonify({"status": "error", "message": "company_nameì´ í•„ìš”í•©ë‹ˆë‹¤."}), 400

        # run_idë§Œ ì¡°íšŒí•˜ëŠ” ê²½ìš°
        if get_run_id_only:
            run_id = get_current_week_info()
            if not run_id:
                return jsonify({"status": "error", "message": "ì£¼ì°¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}), 404
            return jsonify({"status": "success", "run_id": run_id}), 200

        # run_idê°€ ì—†ìœ¼ë©´ ìµœì‹  ì£¼ì°¨ ì‚¬ìš©
        if not run_id:
            run_id = get_current_week_info()
            if not run_id:
                return jsonify({"status": "error", "message": "ì£¼ì°¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}), 404

        # brand_id ê¸°ë°˜ ì²˜ë¦¬ (ìš°ì„ )
        if brand_id is not None:
            # brand_idë¥¼ ë¬¸ìì—´ í‚¤ë¡œ ë³€í™˜ (GCS ìŠ¤ëƒ…ìƒ· í‚¤ í˜•ì‹)
            brand_key = str(brand_id)

            # ìì‚¬ëª° ë¸Œëœë“œì¸ ê²½ìš° (brand_id == 'own')
            if brand_id == 'own':
                own_brand_id = get_own_brand_id(company_name)
                if own_brand_id:
                    brand_key = str(own_brand_id)
                else:
                    return jsonify({"status": "error", "message": "ìì‚¬ëª° ë¸Œëœë“œ IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}), 404

            # GCS ìŠ¤ëƒ…ìƒ·ì—ì„œ ê²€ìƒ‰ ê²°ê³¼ ë¡œë“œ
            snapshot_data = load_search_results_from_gcs(
                company_name=company_name,
                run_id=run_id,
                search_keyword=brand_key
            )

            if snapshot_data is None:
                return jsonify({"status": "error", "message": "ìŠ¤ëƒ…ìƒ·ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}), 404

            search_results = snapshot_data.get("search_results", {})
            created_at = snapshot_data.get("created_at")

            return jsonify({
                "status": "success",
                "run_id": run_id,
                "brand_id": brand_id,
                "results": search_results.get(brand_key, []),
                "created_at": created_at
            }), 200

        # í•˜ìœ„ í˜¸í™˜ì„±: search_keyword ê¸°ë°˜ ì²˜ë¦¬
        if search_keyword == 'own':
            if COMPANY_MAPPING_AVAILABLE:
                brands = get_company_brands(company_name)
                if brands:
                    search_keyword = brands[0]
                else:
                    korean_name = get_company_korean_name(company_name)
                    if korean_name:
                        search_keyword = korean_name
                    else:
                        search_keyword = company_name
            else:
                brand_mapping = {'piscess': 'íŒŒì´ì‹œìŠ¤'}
                search_keyword = brand_mapping.get(company_name.lower(), company_name)

        # GCS ìŠ¤ëƒ…ìƒ·ì—ì„œ ê²€ìƒ‰ ê²°ê³¼ ë¡œë“œ
        snapshot_data = load_search_results_from_gcs(
            company_name=company_name,
            run_id=run_id,
            search_keyword=search_keyword if search_keyword else None
        )

        if snapshot_data is None:
            return jsonify({"status": "error", "message": "ìŠ¤ëƒ…ìƒ·ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}), 404

        search_results = snapshot_data.get("search_results", {})
        created_at = snapshot_data.get("created_at")

        if search_keyword:
            return jsonify({
                "status": "success",
                "run_id": run_id,
                "search_keyword": search_keyword,
                "results": search_results.get(search_keyword, []),
                "created_at": created_at
            }), 200
        else:
            return jsonify({
                "status": "success",
                "run_id": run_id,
                "results": search_results,
                "created_at": created_at
            }), 200

    except Exception as e:
        print(f"[ERROR] get_compare_search_results ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({"status": "error", "message": str(e)}), 500


@data_blueprint.route("/compare/29cm/reviews", methods=["GET"])
def get_compare_reviews():
    """ìƒí’ˆ ë¦¬ë·° ì¡°íšŒ"""
    try:
        item_id = request.args.get("item_id")
        if not item_id:
            return jsonify({"status": "error", "message": "item_id íŒŒë¼ë¯¸í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400
        
        try:
            item_id_int = int(item_id)
        except ValueError:
            return jsonify({"status": "error", "message": "item_idëŠ” ìˆ«ìì—¬ì•¼ í•©ë‹ˆë‹¤."}), 400
        
        reviews = fetch_product_reviews(item_id_int, limit=10)
        return jsonify({
            "status": "success",
            "item_id": item_id_int,
            "reviews": reviews
        }), 200
        
    except Exception as e:
        print(f"[ERROR] get_compare_reviews ì‹¤íŒ¨: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ“Œ Step 4: ê´‘ê³  ê´€ë¦¬ API (Ad Management)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@data_blueprint.route("/get_active_ads", methods=["GET"])
def get_active_ads():
    """
    Meta APIì—ì„œ í™œì„± ê´‘ê³  ëª©ë¡ ì¡°íšŒ
    - effective_status í•„í„°ë§ ì‚¬ìš© (ACTIVE ìƒíƒœ)
    - ì¡°íšŒ ìˆœì„œ: adset â†’ campaign â†’ account (í´ë°±)
    - ì¸ë„¤ì¼ URL í¬í•¨
    """
    try:
        account_id = request.args.get("account_id")
        if not account_id:
            return jsonify({"status": "success", "ads": [], "total": 0, "message": "account_idê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 200

        # Meta API ì•¡ì„¸ìŠ¤ í† í°
        access_token = os.environ.get("META_SYSTEM_USER_TOKEN")
        if not access_token:
            return jsonify({"status": "success", "ads": [], "total": 0, "message": "Meta API í† í° ì—†ìŒ"}), 200

        # account_id ì •ê·œí™” (act_ ì ‘ë‘ì‚¬ ì œê±°)
        clean_account_id = account_id.replace("act_", "")
        ad_account_id = f"act_{clean_account_id}"
        print(f"[STEP4] ìš”ì²­ account_id: {account_id}, ad_account_id: {ad_account_id}")

        # BigQueryì—ì„œ ìº í˜ì¸/ì„¸íŠ¸ ID ì¡°íšŒ
        mapping_row = None
        try:
            bq_client = bigquery.Client()
            mapping_query = """
                SELECT account_id, conv_campaign_id, conv_adset_id, traffic_campaign_id, traffic_adset_id
                FROM `ngn_dataset.meta_account_mapping`
                WHERE account_id = @account_id
                   OR account_id = @clean_account_id
                   OR account_id = @prefixed_account_id
                LIMIT 1
            """
            job_config = bigquery.QueryJobConfig(
                query_parameters=[
                    bigquery.ScalarQueryParameter("account_id", "STRING", account_id),
                    bigquery.ScalarQueryParameter("clean_account_id", "STRING", clean_account_id),
                    bigquery.ScalarQueryParameter("prefixed_account_id", "STRING", ad_account_id)
                ]
            )
            mapping_result = bq_client.query(mapping_query, job_config=job_config).result()
            for row in mapping_result:
                mapping_row = row
                print(f"[STEP4] BigQuery ë§¤í•‘: conv_campaign={row.conv_campaign_id}, conv_adset={row.conv_adset_id}")
                break
        except Exception as bq_err:
            print(f"[STEP4] BigQuery ì¡°íšŒ ì‹¤íŒ¨: {bq_err}")

        # ID ëª©ë¡ ìˆ˜ì§‘ (ìº í˜ì¸ ìœ í˜•ë³„ë¡œ êµ¬ë¶„)
        conv_adset_ids = set()
        traffic_adset_ids = set()
        conv_campaign_ids = set()
        traffic_campaign_ids = set()

        if mapping_row:
            if mapping_row.conv_adset_id and mapping_row.conv_adset_id.strip():
                conv_adset_ids.add(mapping_row.conv_adset_id.strip())
            if mapping_row.traffic_adset_id and mapping_row.traffic_adset_id.strip():
                traffic_adset_ids.add(mapping_row.traffic_adset_id.strip())
            if mapping_row.conv_campaign_id and mapping_row.conv_campaign_id.strip():
                conv_campaign_ids.add(mapping_row.conv_campaign_id.strip())
            if mapping_row.traffic_campaign_id and mapping_row.traffic_campaign_id.strip():
                traffic_campaign_ids.add(mapping_row.traffic_campaign_id.strip())

        # í†µí•© ë¦¬ìŠ¤íŠ¸ (ì¡°íšŒìš©)
        adset_ids = list(conv_adset_ids | traffic_adset_ids)
        campaign_ids = list(conv_campaign_ids | traffic_campaign_ids)

        print(f"[STEP4] adset_ids: {adset_ids}, campaign_ids: {campaign_ids}")

        # Meta API í•„ë“œ ì •ì˜ (ì¸ë„¤ì¼ + configured_status í¬í•¨)
        fields = "id,name,status,effective_status,configured_status,preview_shareable_link,creative{id,thumbnail_url,image_url},adcreatives{image_url,thumbnail_url}"

        # Meta APIëŠ” status/effective_status í•„í„°ë§ ì§€ì› ì•ˆí•¨
        # ì„œë²„ì—ì„œ ì§ì ‘ í•„í„°ë§: DELETED, ARCHIVED ì œì™¸

        all_ads = []

        # ìºì‹œ ìš°íšŒ í—¤ë”
        headers = {
            "Cache-Control": "no-cache, no-store, must-revalidate",
            "Pragma": "no-cache"
        }
        # íƒ€ì„ìŠ¤íƒ¬í”„ (ìºì‹œ ë¬´íš¨í™”)
        import time
        cache_buster = int(time.time() * 1000)

        # ê´‘ê³  ID â†’ ìº í˜ì¸ ìœ í˜• ë§¤í•‘
        ad_campaign_type = {}

        # 1ë‹¨ê³„: AdSet ê¸°ì¤€ ì¡°íšŒ
        if adset_ids:
            for adset_id in adset_ids:
                # ìº í˜ì¸ ìœ í˜• ê²°ì •
                if adset_id in conv_adset_ids:
                    campaign_type = "ì „í™˜"
                elif adset_id in traffic_adset_ids:
                    campaign_type = "ìœ ì…"
                else:
                    campaign_type = "-"

                try:
                    ads_url = f"https://graph.facebook.com/v24.0/{adset_id}/ads"
                    params = {
                        "access_token": access_token,
                        "fields": fields,
                        "limit": 100,
                        "_ts": cache_buster
                    }
                    print(f"[STEP4] AdSet {adset_id} ({campaign_type}) ì¡°íšŒ ì¤‘...")
                    response = requests.get(ads_url, params=params, headers=headers, timeout=30)
                    result = response.json()

                    if "error" not in result:
                        ads_data = result.get("data", [])
                        # ê° ê´‘ê³ ì— ìº í˜ì¸ ìœ í˜• íƒœê¹…
                        for ad in ads_data:
                            ad_campaign_type[ad.get("id")] = campaign_type
                        all_ads.extend(ads_data)
                        print(f"[STEP4] AdSet {adset_id}: {len(ads_data)}ê°œ ê´‘ê³ ")
                        for ad in ads_data:
                            print(f"  - ID: {ad.get('id')}, Name: {ad.get('name')}, Status: {ad.get('status')}")
                    else:
                        print(f"[STEP4] AdSet {adset_id} ì˜¤ë¥˜: {result.get('error', {}).get('message')}")
                except Exception as e:
                    print(f"[STEP4] AdSet {adset_id} ì˜ˆì™¸: {e}")

        # 2ë‹¨ê³„: AdSetì—ì„œ ëª» ì°¾ìœ¼ë©´ Campaign ê¸°ì¤€ ì¡°íšŒ (í´ë°±)
        if not all_ads and campaign_ids:
            print(f"[STEP4] AdSet ì¡°íšŒ ê²°ê³¼ ì—†ìŒ, Campaign í´ë°± ì‹œë„")
            for campaign_id in campaign_ids:
                # ìº í˜ì¸ ìœ í˜• ê²°ì •
                if campaign_id in conv_campaign_ids:
                    campaign_type = "ì „í™˜"
                elif campaign_id in traffic_campaign_ids:
                    campaign_type = "ìœ ì…"
                else:
                    campaign_type = "-"

                try:
                    ads_url = f"https://graph.facebook.com/v24.0/{campaign_id}/ads"
                    params = {
                        "access_token": access_token,
                        "fields": fields,
                        "limit": 100,
                        "_ts": cache_buster
                    }
                    print(f"[STEP4] Campaign {campaign_id} ({campaign_type}) ì¡°íšŒ ì¤‘...")
                    response = requests.get(ads_url, params=params, headers=headers, timeout=30)
                    result = response.json()

                    if "error" not in result:
                        ads_data = result.get("data", [])
                        # ê° ê´‘ê³ ì— ìº í˜ì¸ ìœ í˜• íƒœê¹…
                        for ad in ads_data:
                            ad_campaign_type[ad.get("id")] = campaign_type
                        all_ads.extend(ads_data)
                        print(f"[STEP4] Campaign {campaign_id}: {len(ads_data)}ê°œ ê´‘ê³ ")
                        for ad in ads_data:
                            print(f"  - ID: {ad.get('id')}, Name: {ad.get('name')}, Status: {ad.get('status')}")
                    else:
                        print(f"[STEP4] Campaign {campaign_id} ì˜¤ë¥˜: {result.get('error', {}).get('message')}")
                except Exception as e:
                    print(f"[STEP4] Campaign {campaign_id} ì˜ˆì™¸: {e}")

        # 3ë‹¨ê³„: ì•„ì§ë„ ì—†ìœ¼ë©´ Account ì „ì²´ ì¡°íšŒ (ìµœì¢… í´ë°±)
        if not all_ads:
            print(f"[STEP4] Campaign ì¡°íšŒ ê²°ê³¼ ì—†ìŒ, Account ì „ì²´ í´ë°±")
            try:
                ads_url = f"https://graph.facebook.com/v24.0/{ad_account_id}/ads"
                params = {
                    "access_token": access_token,
                    "fields": fields,
                    "limit": 100,
                    "_ts": cache_buster
                }
                print(f"[STEP4] Account {ad_account_id} ì „ì²´ ì¡°íšŒ ì¤‘...")
                response = requests.get(ads_url, params=params, headers=headers, timeout=30)
                result = response.json()

                if "error" not in result:
                    all_ads = result.get("data", [])
                    print(f"[STEP4] Account ì „ì²´: {len(all_ads)}ê°œ ê´‘ê³ ")
                else:
                    print(f"[STEP4] Account ì „ì²´ ì¡°íšŒ ì˜¤ë¥˜: {result.get('error', {}).get('message')}")
            except Exception as e:
                print(f"[STEP4] Account ì „ì²´ ì¡°íšŒ ì˜ˆì™¸: {e}")

        # ì¤‘ë³µ ì œê±° + DELETED/ARCHIVED í•„í„°ë§ (ì„œë²„ ì¸¡)
        seen_ids = set()
        unique_ads = []
        excluded_statuses = {'DELETED', 'ARCHIVED'}
        for ad in all_ads:
            ad_id = ad.get("id")
            ad_status = ad.get("status", "")
            # DELETED, ARCHIVED ì œì™¸
            if ad_status in excluded_statuses:
                continue
            if ad_id and ad_id not in seen_ids:
                seen_ids.add(ad_id)
                unique_ads.append(ad)

        print(f"[STEP4] ìµœì¢… ì¡°íšŒ ê²°ê³¼: {len(unique_ads)}ê°œ ê´‘ê³  (DELETED/ARCHIVED ì œì™¸)")
        for ad in unique_ads:
            print(f"  [ìµœì¢…] ID: {ad.get('id')}, Name: {ad.get('name')}")

        # ê´‘ê³  ë°ì´í„° ê°€ê³µ (ì¸ë„¤ì¼ ì¶”ì¶œ)
        processed_ads = []
        for ad in unique_ads:
            # ì¸ë„¤ì¼ URL ì¶”ì¶œ ìš°ì„ ìˆœìœ„: creative.thumbnail_url â†’ creative.image_url â†’ adcreatives[0].image_url
            thumbnail_url = ""
            creative = ad.get("creative", {})
            if creative:
                thumbnail_url = creative.get("thumbnail_url") or creative.get("image_url") or ""

            if not thumbnail_url:
                adcreatives = ad.get("adcreatives", {}).get("data", [])
                if adcreatives and len(adcreatives) > 0:
                    thumbnail_url = adcreatives[0].get("image_url") or adcreatives[0].get("thumbnail_url") or ""

            processed_ads.append({
                "id": ad.get("id"),
                "name": ad.get("name", "ì´ë¦„ ì—†ìŒ"),
                "status": ad.get("status"),
                "effective_status": ad.get("effective_status"),
                "configured_status": ad.get("configured_status"),  # ì‚¬ìš©ì ì„¤ì • ìƒíƒœ (ON/OFF ë°°ì§€ìš©)
                "campaign_type": ad_campaign_type.get(ad.get("id"), "-"),  # ì „í™˜/ìœ ì…
                "thumbnail_url": thumbnail_url,
                "preview_link": ad.get("preview_shareable_link", "")
            })

        return jsonify({
            "status": "success",
            "ads": processed_ads,
            "total": len(processed_ads)
        }), 200

    except requests.exceptions.Timeout:
        print("[STEP4] Meta API íƒ€ì„ì•„ì›ƒ")
        return jsonify({"status": "success", "ads": [], "total": 0, "message": "API íƒ€ì„ì•„ì›ƒ"}), 200
    except Exception as e:
        print(f"[ERROR] get_active_ads ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        # ì—ëŸ¬ ì‹œì—ë„ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜ (í”„ë¡ íŠ¸ì—”ë“œ ì—ëŸ¬ ë°©ì§€)
        return jsonify({"status": "success", "ads": [], "total": 0, "message": str(e)}), 200


@data_blueprint.route("/pause_ads", methods=["POST"])
def pause_ads():
    """ì„ íƒí•œ ê´‘ê³ ë“¤ì„ ì¼ì‹œì •ì§€(PAUSED) ìƒíƒœë¡œ ë³€ê²½"""
    try:
        data = request.get_json() or {}
        ad_ids = data.get("ad_ids", [])

        if not ad_ids:
            return jsonify({"status": "error", "message": "ad_idsê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400

        access_token = os.environ.get("META_SYSTEM_USER_TOKEN")
        if not access_token:
            return jsonify({"status": "error", "message": "Meta API í† í°ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}), 500

        print(f"[STEP4] ê´‘ê³  ì¼ì‹œì •ì§€ ìš”ì²­: {len(ad_ids)}ê°œ")

        success_count = 0
        failed_ids = []

        for ad_id in ad_ids:
            try:
                update_url = f"https://graph.facebook.com/v24.0/{ad_id}"
                response = requests.post(
                    update_url,
                    data={
                        "access_token": access_token,
                        "status": "PAUSED"
                    },
                    timeout=15
                )
                result = response.json()

                if result.get("success") or "id" in result:
                    success_count += 1
                    print(f"[STEP4] ê´‘ê³  {ad_id} ì¼ì‹œì •ì§€ ì„±ê³µ")
                else:
                    failed_ids.append(ad_id)
                    print(f"[STEP4] ê´‘ê³  {ad_id} ì¼ì‹œì •ì§€ ì‹¤íŒ¨: {result}")

            except Exception as e:
                failed_ids.append(ad_id)
                print(f"[STEP4] ê´‘ê³  {ad_id} ì¼ì‹œì •ì§€ ì˜¤ë¥˜: {e}")

        return jsonify({
            "status": "success" if success_count > 0 else "error",
            "message": f"{success_count}ê°œ ê´‘ê³  ì¼ì‹œì •ì§€ ì™„ë£Œ",
            "success_count": success_count,
            "failed_ids": failed_ids
        }), 200

    except Exception as e:
        print(f"[ERROR] pause_ads ì‹¤íŒ¨: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


@data_blueprint.route("/delete_ads", methods=["POST"])
def delete_ads():
    """ì„ íƒí•œ ê´‘ê³ ë“¤ì„ ì‚­ì œ (DELETED ìƒíƒœë¡œ ë³€ê²½)"""
    try:
        data = request.get_json() or {}
        ad_ids = data.get("ad_ids", [])

        if not ad_ids:
            return jsonify({"status": "error", "message": "ad_idsê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400

        access_token = os.environ.get("META_SYSTEM_USER_TOKEN")
        if not access_token:
            return jsonify({"status": "error", "message": "Meta API í† í°ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}), 500

        print(f"[STEP4] ê´‘ê³  ì‚­ì œ ìš”ì²­: {len(ad_ids)}ê°œ")

        success_count = 0
        failed_ids = []

        for ad_id in ad_ids:
            try:
                # Meta APIì—ì„œ ê´‘ê³  ì‚­ì œëŠ” DELETE ë©”ì„œë“œ ë˜ëŠ” status=DELETEDë¡œ ë³€ê²½
                delete_url = f"https://graph.facebook.com/v24.0/{ad_id}"
                response = requests.delete(
                    delete_url,
                    params={"access_token": access_token},
                    timeout=15
                )
                result = response.json()

                if result.get("success"):
                    success_count += 1
                    print(f"[STEP4] ê´‘ê³  {ad_id} ì‚­ì œ ì„±ê³µ")
                else:
                    failed_ids.append(ad_id)
                    print(f"[STEP4] ê´‘ê³  {ad_id} ì‚­ì œ ì‹¤íŒ¨: {result}")

            except Exception as e:
                failed_ids.append(ad_id)
                print(f"[STEP4] ê´‘ê³  {ad_id} ì‚­ì œ ì˜¤ë¥˜: {e}")

        return jsonify({
            "status": "success" if success_count > 0 else "error",
            "message": f"{success_count}ê°œ ê´‘ê³  ì‚­ì œ ì™„ë£Œ",
            "success_count": success_count,
            "failed_ids": failed_ids
        }), 200

    except Exception as e:
        print(f"[ERROR] delete_ads ì‹¤íŒ¨: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500