"""
ìŠ¤ëƒ…ìƒ· ë°ì´í„°ì˜ ì‹¤ì œ ë‚ ì§œ ë²”ìœ„ í™•ì¸ ìŠ¤í¬ë¦½íŠ¸
"""
import os
import sys
import json
import gzip
from datetime import date
from google.cloud import bigquery
from google.cloud import storage

PROJECT_ID = os.environ.get("GOOGLE_CLOUD_PROJECT", "winged-precept-443218-v8")
DATASET = "ngn_dataset"
GCS_BUCKET = os.environ.get("GCS_BUCKET", "winged-precept-443218-v8.appspot.com")

def check_bigquery_dates(company_name: str, year: int, month: int):
    """BigQuery í…Œì´ë¸”ì—ì„œ ì‹¤ì œ ë‚ ì§œ ë²”ìœ„ í™•ì¸"""
    client = bigquery.Client(project=PROJECT_ID)
    
    # 1. daily_cafe24_sales í…Œì´ë¸” í™•ì¸
    query = f"""
    SELECT 
        MIN(payment_date) AS min_date,
        MAX(payment_date) AS max_date,
        COUNT(DISTINCT payment_date) AS date_count
    FROM `{PROJECT_ID}.{DATASET}.daily_cafe24_sales`
    WHERE company_name = @company_name
      AND payment_date >= @start_date
      AND payment_date <= @end_date
    """
    
    start_date = date(year, month, 1).isoformat()
    if month == 12:
        end_date = date(year + 1, 1, 1)
    else:
        end_date = date(year, month + 1, 1)
    end_date = (end_date - date.resolution).isoformat()  # ì›”ë§
    
    rows = list(
        client.query(
            query,
            job_config=bigquery.QueryJobConfig(
                query_parameters=[
                    bigquery.ScalarQueryParameter("company_name", "STRING", company_name),
                    bigquery.ScalarQueryParameter("start_date", "DATE", start_date),
                    bigquery.ScalarQueryParameter("end_date", "DATE", end_date),
                ]
            ),
        ).result()
    )
    
    if rows:
        row = rows[0]
        print(f"ğŸ“Š BigQuery daily_cafe24_sales í…Œì´ë¸”:")
        print(f"   ìµœì†Œ ë‚ ì§œ: {row.min_date}")
        print(f"   ìµœëŒ€ ë‚ ì§œ: {row.max_date}")
        print(f"   ë‚ ì§œ ê°œìˆ˜: {row.date_count}")
        print(f"   ì˜ˆìƒ ë‚ ì§œ ê°œìˆ˜: 31ì¼")
        if row.max_date and row.max_date.isoformat() < end_date:
            print(f"   âš ï¸ ê²½ê³ : ì›”ë§({end_date})ê¹Œì§€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤!")
    
    # 2. ì¼ë³„ ë°ì´í„° ìƒì„¸ í™•ì¸ (ë§ˆì§€ë§‰ 5ì¼)
    query2 = f"""
    SELECT 
        payment_date,
        SUM(net_sales) AS net_sales,
        SUM(total_orders) AS total_orders
    FROM `{PROJECT_ID}.{DATASET}.daily_cafe24_sales`
    WHERE company_name = @company_name
      AND payment_date >= @start_date
      AND payment_date <= @end_date
    GROUP BY payment_date
    ORDER BY payment_date DESC
    LIMIT 5
    """
    
    rows2 = list(
        client.query(
            query2,
            job_config=bigquery.QueryJobConfig(
                query_parameters=[
                    bigquery.ScalarQueryParameter("company_name", "STRING", company_name),
                    bigquery.ScalarQueryParameter("start_date", "DATE", start_date),
                    bigquery.ScalarQueryParameter("end_date", "DATE", end_date),
                ]
            ),
        ).result()
    )
    
    print(f"\nğŸ“… ì¼ë³„ ë§¤ì¶œ ë°ì´í„° (ë§ˆì§€ë§‰ 5ì¼):")
    for row in rows2:
        print(f"   {row.payment_date}: ë§¤ì¶œ {row.net_sales:,.0f}ì›, ì£¼ë¬¸ {row.total_orders}ê±´")


def check_gcs_snapshot(company_name: str, year: int, month: int):
    """GCS ìŠ¤ëƒ…ìƒ· íŒŒì¼ì—ì„œ ì‹¤ì œ ë‚ ì§œ ë²”ìœ„ í™•ì¸"""
    storage_client = storage.Client(project=PROJECT_ID)
    bucket = storage_client.bucket(GCS_BUCKET)
    blob_path = f"ai-reports/monthly/{company_name}/{year}-{month:02d}/snapshot.json.gz"
    blob = bucket.blob(blob_path)
    
    if not blob.exists():
        print(f"âŒ GCS ìŠ¤ëƒ…ìƒ· íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {blob_path}")
        return
    
    # íŒŒì¼ ë‹¤ìš´ë¡œë“œ ë° íŒŒì‹±
    file_bytes = blob.download_as_bytes(raw_download=True)
    decompressed = gzip.decompress(file_bytes)
    snapshot = json.loads(decompressed.decode('utf-8'))
    
    # ìŠ¤ëƒ…ìƒ· ìƒì„± ì‹œê°„ í™•ì¸
    print(f"\nğŸ“¦ GCS ìŠ¤ëƒ…ìƒ· íŒŒì¼:")
    print(f"   ê²½ë¡œ: {blob_path}")
    print(f"   ìƒì„± ì‹œê°„: {blob.time_created}")
    print(f"   ìˆ˜ì • ì‹œê°„: {blob.updated}")
    
    # daily_this ë°ì´í„° í™•ì¸
    daily_this = snapshot.get("facts", {}).get("mall_sales", {}).get("daily_this", [])
    if daily_this:
        dates = [item.get("date") for item in daily_this if item.get("date")]
        if dates:
            dates.sort()
            print(f"\nğŸ“Š ìŠ¤ëƒ…ìƒ· ë‚´ daily_this ë°ì´í„°:")
            print(f"   ìµœì†Œ ë‚ ì§œ: {dates[0]}")
            print(f"   ìµœëŒ€ ë‚ ì§œ: {dates[-1]}")
            print(f"   ë‚ ì§œ ê°œìˆ˜: {len(dates)}")
            print(f"   ì˜ˆìƒ ë‚ ì§œ ê°œìˆ˜: 31ì¼")
            
            # ë§ˆì§€ë§‰ 5ì¼ í™•ì¸
            print(f"\nğŸ“… ìŠ¤ëƒ…ìƒ· ì¼ë³„ ë§¤ì¶œ ë°ì´í„° (ë§ˆì§€ë§‰ 5ì¼):")
            for item in sorted(daily_this, key=lambda x: x.get("date", ""), reverse=True)[:5]:
                print(f"   {item.get('date')}: ë§¤ì¶œ {item.get('net_sales', 0):,.0f}ì›, ì£¼ë¬¸ {item.get('total_orders', 0)}ê±´")
            
            # ì›”ë§ ë°ì´í„° í™•ì¸
            expected_end = f"{year}-{month:02d}-31"
            if dates[-1] < expected_end:
                print(f"\n   âš ï¸ ê²½ê³ : ì›”ë§({expected_end})ê¹Œì§€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤!")
                print(f"   ë§ˆì§€ë§‰ ë‚ ì§œ: {dates[-1]}")
    else:
        print(f"   âš ï¸ daily_this ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    company_name = "piscess"
    year = 2025
    month = 12
    
    print(f"ğŸ” ìŠ¤ëƒ…ìƒ· ë°ì´í„° ë‚ ì§œ ë²”ìœ„ í™•ì¸")
    print(f"   íšŒì‚¬: {company_name}")
    print(f"   ë…„ì›”: {year}-{month:02d}\n")
    
    # BigQuery í™•ì¸
    print("=" * 60)
    check_bigquery_dates(company_name, year, month)
    
    # GCS ìŠ¤ëƒ…ìƒ· í™•ì¸
    print("\n" + "=" * 60)
    check_gcs_snapshot(company_name, year, month)





