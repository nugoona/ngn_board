"""
29CM íŠ¸ë Œë“œ ë¶„ì„ AI ë¦¬í¬íŠ¸ ìƒì„± ëª¨ë“ˆ
- Google Gemini APIë¥¼ ì‚¬ìš©í•˜ì—¬ 29CM íŠ¸ë Œë“œ ìŠ¤ëƒ…ìƒ· ë°ì´í„°ë¥¼ ë¶„ì„
- í…ìŠ¤íŠ¸ ë¦¬í¬íŠ¸(AI)ì™€ ë°ì´í„° ì‹œê°í™”(UI)ì˜ ì—­í•  ë¶„ë¦¬
- íŠ¸ë Œë“œ ì¸ì‚¬ì´íŠ¸(Why) ì¤‘ì‹¬ì˜ ë¦¬í¬íŠ¸ ìƒì„±
"""

import os
import sys
import json
import traceback
from typing import Dict, Optional, Any

# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
try:
    from dotenv import load_dotenv
    # ì—¬ëŸ¬ ê²½ë¡œì—ì„œ .env íŒŒì¼ ì°¾ê¸° ì‹œë„
    env_loaded = False
    
    # 1. í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬ì—ì„œ ì°¾ê¸°
    cwd_env = os.path.join(os.getcwd(), ".env")
    if os.path.exists(cwd_env):
        load_dotenv(cwd_env, override=True)
        env_loaded = True
        print(f"âœ… [INFO] .env íŒŒì¼ ë¡œë“œë¨: {cwd_env}", file=sys.stderr)
    
    # 2. ìŠ¤í¬ë¦½íŠ¸ ìœ„ì¹˜ ê¸°ì¤€ìœ¼ë¡œ í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì°¾ê¸° (ngn_board)
    if not env_loaded:
        script_dir = os.path.dirname(os.path.abspath(__file__))
        # tools/ai_report_test/ -> tools/ -> í”„ë¡œì íŠ¸ ë£¨íŠ¸ (ngn_board)
        project_root = os.path.dirname(os.path.dirname(script_dir))
        env_path = os.path.join(project_root, ".env")
        if os.path.exists(env_path):
            load_dotenv(env_path, override=True)
            env_loaded = True
            print(f"âœ… [INFO] .env íŒŒì¼ ë¡œë“œë¨: {env_path}", file=sys.stderr)
        else:
            print(f"âš ï¸ [DEBUG] .env íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {env_path}", file=sys.stderr)
    
    # 3. ê¸°ë³¸ load_dotenv() ì‹œë„ (í˜„ì¬ ë””ë ‰í† ë¦¬ ë° ìƒìœ„ ë””ë ‰í† ë¦¬ ìë™ íƒìƒ‰)
    if not env_loaded:
        load_dotenv(override=True)  # .env íŒŒì¼ì´ ì—†ì–´ë„ ì—ëŸ¬ ì—†ì´ ì§„í–‰
        
except ImportError:
    print("âš ï¸ [WARN] python-dotenv íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.", file=sys.stderr)
    print("   ì„¤ì¹˜: pip install python-dotenv", file=sys.stderr)

# Google Gen AI SDK
try:
    import google.genai as genai
    from google.genai import types
    GENAI_AVAILABLE = True
    
    # Safety Settings
    try:
        from google.genai.types import HarmCategory, HarmBlockThreshold
        SAFETY_SETTINGS_AVAILABLE = True
    except (ImportError, AttributeError):
        HarmCategory = None
        HarmBlockThreshold = None
        SAFETY_SETTINGS_AVAILABLE = False
        
except ImportError:
    genai = None
    types = None
    GENAI_AVAILABLE = False
    HarmCategory = None
    HarmBlockThreshold = None
    SAFETY_SETTINGS_AVAILABLE = False
    print("âš ï¸ [WARN] google-genai íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.", file=sys.stderr)
    print("   ì„¤ì¹˜: pip install google-genai", file=sys.stderr)

# í™˜ê²½ ë³€ìˆ˜
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
GEMINI_MODEL = "gemini-2.5-flash"

# í•µì‹¬ 6ëŒ€ ì¹´í…Œê³ ë¦¬
CORE_CATEGORIES = ["ìƒì˜", "ë°”ì§€", "ìŠ¤ì»¤íŠ¸", "ì›í”¼ìŠ¤", "ë‹ˆíŠ¸ì›¨ì–´", "ì…‹ì—…"]

# ìì‚¬ëª° ë§¤í•‘ ì„¤ì • ë¡œë“œ
try:
    # í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€ìœ¼ë¡œ config ëª¨ë“ˆ ê²½ë¡œ ì¶”ê°€
    script_dir = os.path.dirname(os.path.abspath(__file__))
    # tools/ai_report_test/ -> tools/ -> í”„ë¡œì íŠ¸ ë£¨íŠ¸
    project_root = os.path.dirname(os.path.dirname(script_dir))
    config_path = os.path.join(project_root, "tools", "config")
    if config_path not in sys.path:
        sys.path.insert(0, os.path.join(project_root, "tools"))
    
    from config.company_mapping import (
        COMPANY_MAPPING,
        OWN_COMPANY_NAMES,
        get_company_korean_name,
        get_company_brands,
        is_own_company_brand
    )
    COMPANY_MAPPING_AVAILABLE = True
except (ImportError, ModuleNotFoundError) as e:
    print(f"âš ï¸ [WARN] ìì‚¬ëª° ë§¤í•‘ ì„¤ì •ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}", file=sys.stderr)
    COMPANY_MAPPING_AVAILABLE = False
    COMPANY_MAPPING = {}
    OWN_COMPANY_NAMES = []
    def get_company_korean_name(name): return None
    def get_company_brands(name): return []
    def is_own_company_brand(brand, company=None): return False, None


# ============================================
# ì„¤ì • ë³€ìˆ˜ (ë¶„ì„ íƒ€ê²Ÿ ë¸Œëœë“œ)
# ============================================

# ê¸°ë³¸ íƒ€ê²Ÿ ë¸Œëœë“œ (í•¨ìˆ˜ íŒŒë¼ë¯¸í„°ë¡œ ì˜¤ë²„ë¼ì´ë“œ ê°€ëŠ¥)
DEFAULT_TARGET_BRAND = "ì¸ì›¨ì–´ë²„í„°"


# ============================================
# System Instruction (ì§€ì¹¨ì„œ)
# ============================================

def build_system_instruction(target_brand: str = DEFAULT_TARGET_BRAND, platform: str = "29CM") -> str:
    """
    System Instruction ìƒì„±
    
    Args:
        target_brand: ë¶„ì„ íƒ€ê²Ÿ ë¸Œëœë“œëª… (í•œê¸€ëª…, ì˜ˆ: "ì¸ì›¨ì–´ë²„í„°", "íŒŒì´ì‹œìŠ¤", "Ably")
        platform: í”Œë«í¼ëª… ("29CM" ë˜ëŠ” "Ably")
    
    Returns:
        System Instruction ë¬¸ìì—´
    """
    platform_name = "Ably" if platform.upper() == "ABLY" else "29CM"
    return f"""ë‹¹ì‹ ì€ íŒ¨ì…˜ ë¸Œëœë“œ MDë¥¼ ìœ„í•œ ìˆ˜ì„ ë°ì´í„° ë¶„ì„ê°€ì…ë‹ˆë‹¤.
ì œê³µëœ {platform_name} ë­í‚¹ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ì „ëµ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•˜ì„¸ìš”.
**ë¶„ì„ íƒ€ê²Ÿ ë¸Œëœë“œ: '{target_brand}'**

[ì‘ì„± ëŒ€ì›ì¹™]
1. **Cluster & Label:** ê°œë³„ ì¸ê¸° ìƒí’ˆë“¤ì„ ë‚˜ì—´í•˜ì§€ ë§ˆì‹­ì‹œì˜¤. ëŒ€ì‹ , **ìœ ì‚¬í•œ íŠ¹ì§•(ì†Œì¬, ë””í…Œì¼, ë¬´ë“œ)ì„ ê°€ì§„ ìƒí’ˆë“¤ì„ ê·¸ë£¹í™”(Clustering)**í•˜ê³ , ê·¸ ê·¸ë£¹ì„ ëŒ€í‘œí•˜ëŠ” **ë§¤ë ¥ì ì¸ íŠ¸ë Œë“œ í‚¤ì›Œë“œ(Labeling)**ë¥¼ ë½‘ì•„ë‚´ì„¸ìš”.
2. **Structure:** ê° ì¹´í…Œê³ ë¦¬ ë‹¹ **ê°€ì¥ ê°•ë ¥í•œ íŠ¸ë Œë“œ íë¦„ 2ê°€ì§€**ë¥¼ ì„ ì •í•˜ì—¬ ìš”ì•½í•˜ì„¸ìš”.
3. **No Robot Tone:** ê¸°ê³„ì ì¸ ë‚˜ì—´("~ê°€ ì¸ê¸°ì…ë‹ˆë‹¤.")ì„ ë©ˆì¶”ê³ , MDì—ê²Œ ë³´ê³ í•˜ë“¯ **"~í•œ ë¬´ë“œê°€ ê°•ì„¸ì…ë‹ˆë‹¤", "~ìˆ˜ìš”ê°€ ê¸‰ì¦í•˜ê³  ìˆìŠµë‹ˆë‹¤"**ì™€ ê°™ì´ íë¦„ì„ ì½ì–´ì£¼ëŠ” ë¬¸ì²´ë¡œ ì‘ì„±í•˜ì„¸ìš”.
4. **List Forbidden:** ë¦¬í¬íŠ¸ í•˜ë‹¨ì— 'ìƒí’ˆ ì¸ë„¤ì¼ ì¹´ë“œ'ê°€ ë³„ë„ë¡œ ë°°ì¹˜ë©ë‹ˆë‹¤. ë”°ë¼ì„œ í…ìŠ¤íŠ¸ ë³¸ë¬¸ì—ì„œëŠ” **ê°œë³„ ìƒí’ˆëª…ì´ë‚˜ ìˆœìœ„ë¥¼ ë‚˜ì—´í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.**
5. **Data-Driven:** ì œê³µëœ ë°ì´í„°ì—ë§Œ ê¸°ë°˜í•˜ì—¬ ë¶„ì„í•˜ì„¸ìš”. ë°ì´í„°ì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”.
6. **Weekly Uniqueness:** ë§¤ì£¼ ë‹¤ë¥¸ ë°ì´í„°ê°€ ì œê³µë˜ë¯€ë¡œ, ë§¤ì£¼ ì™„ì „íˆ ë‹¤ë¥¸ ë‚´ìš©ì„ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤. ì´ì „ ì£¼ ë¦¬í¬íŠ¸ë‚˜ í…œí”Œë¦¿ì„ ë³µì‚¬í•˜ì§€ ë§ˆì„¸ìš”.
7. **Markdown Format:** ë°˜ë“œì‹œ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì„ ì‚¬ìš©í•˜ì„¸ìš”. **êµµê²Œ**, *ê¸°ìš¸ì„*, ì¤„ë°”ê¿ˆ(ë¹ˆ ì¤„), ë¶ˆë › í¬ì¸íŠ¸(`*` ë˜ëŠ” `-`)ë¥¼ ì ì ˆíˆ í™œìš©í•˜ì„¸ìš”.
8. **Line Breaks:** ê°€ë…ì„±ì„ ìœ„í•´ ì ì ˆí•œ ì¤„ë°”ê¿ˆì„ ì‚¬ìš©í•˜ì„¸ìš”. ì¹´í…Œê³ ë¦¬, ì„¸ê·¸ë¨¼íŠ¸, ì£¼ìš” í•­ëª© ì‚¬ì´ì—ëŠ” ë°˜ë“œì‹œ ë¹ˆ ì¤„ì„ ì¶”ê°€í•˜ì„¸ìš”.

[ì ˆëŒ€ ê¸ˆì§€ ì‚¬í•­]
- **ì˜ˆì‹œë‚˜ í…œí”Œë¦¿ ë¬¸êµ¬ë¥¼ ê·¸ëŒ€ë¡œ ë³µì‚¬í•˜ì§€ ë§ˆì„¸ìš”.** "(ì˜ˆ: ...)" í˜•íƒœì˜ ë¬¸êµ¬ë¥¼ ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”.
- **ê³ ì •ëœ í˜•ì‹ì´ë‚˜ íŒ¨í„´ì„ ë°˜ë³µí•˜ì§€ ë§ˆì„¸ìš”.** ë°ì´í„°ì— ë”°ë¼ êµ¬ì¡°ì™€ ë‚´ìš©ì´ ë‹¬ë¼ì ¸ì•¼ í•©ë‹ˆë‹¤.
- **"íŠ¸ë Œë“œ ë¶„ì„ ë©˜íŠ¸" ê°™ì€ í”Œë ˆì´ìŠ¤í™€ë”ë¥¼ ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”.** ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ë¶„ì„ë§Œ ì‘ì„±í•˜ì„¸ìš”.
- **ì¹´í…Œê³ ë¦¬ë³„ë¡œ í•­ìƒ ê°™ì€ í˜•ì‹("**ìƒì˜:**", "**ë°”ì§€:**" ë“±)ì„ ê°•ì œí•˜ì§€ ë§ˆì„¸ìš”.** ë°ì´í„°ê°€ ìˆëŠ” ì¹´í…Œê³ ë¦¬ë§Œ ë¶„ì„í•˜ê³ , ì—†ëŠ” ì¹´í…Œê³ ë¦¬ëŠ” ìƒëµí•˜ì„¸ìš”.

---

[ë¦¬í¬íŠ¸ ì¶œë ¥ êµ¬ì¡°]

## Section 1. ìì‚¬ëª° ì„±ê³¼ ë¶„ì„

ì œê³µëœ ë°ì´í„°ì—ì„œ '{target_brand}' ë¸Œëœë“œì˜ ìƒí’ˆì´ í¬í•¨ëœ ì¹´í…Œê³ ë¦¬ë§Œ ë¶„ì„í•˜ì„¸ìš”.

**ë°ì´í„°ì— ìì‚¬ëª° ìƒí’ˆì´ ìˆëŠ” ê²½ìš°:**

ê° ì¹´í…Œê³ ë¦¬ë³„ë¡œ ì¤„ë°”ê¿ˆì„ í•˜ì—¬ ë¶„ì„í•˜ì„¸ìš”. ë°ì´í„°ì—ì„œ í™•ì¸ëœ ìì‚¬ëª° ìƒí’ˆì˜ êµ¬ì²´ì ì¸ ìˆœìœ„ ë³€ë™ê³¼ ì¸ê¸° ìš”ì¸(ì†Œì¬, ë””ìì¸, ê°€ê²©ëŒ€ ë“±)ì„ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”. êµ¬ì²´ì ì¸ ì†Œì¬ëª…, ë””ìì¸ ìš”ì†Œ, ì‹¤ë£¨ì—£ ë“±ì€ ë°˜ë“œì‹œ **êµµê²Œ** ì²˜ë¦¬í•˜ì„¸ìš”.

**âš ï¸ ë§ˆí¬ë‹¤ìš´ êµµê²Œ ì²˜ë¦¬ ì£¼ì˜ì‚¬í•­:**
- `**êµµê²Œ**` ì²˜ë¦¬ ì‹œ, ì•ë’¤ì— ê´„í˜¸ `()` ë‚˜ ì‰¼í‘œ `,` ê°™ì€ íŠ¹ìˆ˜ë¬¸ìê°€ ë°”ë¡œ ë¶™ìœ¼ë©´ ë§ˆí¬ë‹¤ìš´ íš¨ê³¼ê°€ ì‚¬ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- ì˜¬ë°”ë¥¸ ì˜ˆì‹œ: `**ì†Œì¬ëª…** (100% ìš¸)` ë˜ëŠ” `**ë””ìì¸ ìš”ì†Œ**, **ì‹¤ë£¨ì—£**`
- ì˜ëª»ëœ ì˜ˆì‹œ: `**ì†Œì¬ëª…**(100% ìš¸)` (íŠ¹ìˆ˜ë¬¸ìê°€ ë°”ë¡œ ë¶™ìœ¼ë©´ íŒŒì‹± ì‹¤íŒ¨)
- íŠ¹ìˆ˜ë¬¸ì ì•ì—ëŠ” ê³µë°±ì„ ë‘ê±°ë‚˜, ì—¬ëŸ¬ í‚¤ì›Œë“œë¥¼ ë‚˜ì—´í•  ë•ŒëŠ” ê°ê° ë³„ë„ë¡œ `**í‚¤ì›Œë“œ1**, **í‚¤ì›Œë“œ2**` í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.

ê° ì¹´í…Œê³ ë¦¬ ì‚¬ì´ì—ëŠ” ë°˜ë“œì‹œ ë¹ˆ ì¤„ì„ ì¶”ê°€í•˜ì„¸ìš”. ì¶”ìƒì  í‘œí˜„ì„ í”¼í•˜ê³ , ì‹¤ì œ ë°ì´í„°ì—ì„œ í™•ì¸í•œ ìˆ˜ì¹˜ë‚˜ íŒ¨í„´ì„ ì–¸ê¸‰í•˜ì„¸ìš”.

**ë°ì´í„°ì— ìì‚¬ëª° ìƒí’ˆì´ ì—†ëŠ” ê²½ìš°:**

ì´ë²ˆ ì£¼ ë°ì´í„°ì— ìì‚¬ëª° ìƒí’ˆì´ í¬í•¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.

## Section 2. Market Overview (ì‹œì¥ í•µì‹¬ íŠ¸ë Œë“œ)

ì œê³µëœ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì „ì²´ ì‹œì¥ì„ ê´€í†µí•˜ëŠ” 2ê°€ì§€ í•µì‹¬ íë¦„ì„ ìš”ì•½í•˜ì„¸ìš”. (ê°€ê²© ë¶„ì„ ì œì™¸) **ë°ì´í„°ì— ì‹¤ì œë¡œ ë‚˜íƒ€ë‚œ íŒ¨í„´ë§Œ ë¶„ì„í•˜ì„¸ìš”.**

**Material (ì†Œì¬):**

ë°ì´í„°ì—ì„œ í™•ì¸ëœ ì†Œì¬ íŠ¸ë Œë“œë¥¼ ë¶„ì„í•˜ì„¸ìš”. ë°ì´í„°ì— ì—†ëŠ” ì†Œì¬ëŠ” ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”. êµ¬ì²´ì ì¸ ì†Œì¬ëª…ê³¼ íŠ¸ë Œë“œ íŒ¨í„´ì„ ë°ì´í„°ì—ì„œ í™•ì¸ëœ ë‚´ìš©ë§Œ ê¸°ë°˜ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.

**ì¤‘ìš”:** êµ¬ì²´ì ì¸ ì†Œì¬ëª…(ì˜ˆ: ìš¸, ìºì‹œë¯¸ì–´, í”Œë¦¬ìŠ¤, ì½”ë“€ë¡œì´, ë²¨ë²³ ë“±)ì€ ë°˜ë“œì‹œ **êµµê²Œ** ì²˜ë¦¬í•˜ì„¸ìš”.

**âš ï¸ ë§ˆí¬ë‹¤ìš´ êµµê²Œ ì²˜ë¦¬ ì£¼ì˜ì‚¬í•­:**
- `**êµµê²Œ**` ì²˜ë¦¬ ì‹œ, ì•ë’¤ì— ê´„í˜¸ `()` ë‚˜ ì‰¼í‘œ `,` ê°™ì€ íŠ¹ìˆ˜ë¬¸ìê°€ ë°”ë¡œ ë¶™ìœ¼ë©´ ë§ˆí¬ë‹¤ìš´ íš¨ê³¼ê°€ ì‚¬ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- ì˜¬ë°”ë¥¸ ì˜ˆì‹œ: `**ì„¸íŠ¸ êµ¬ì„±** (3PCS, 4PCS)` ë˜ëŠ” `**ì„¸íŠ¸ êµ¬ì„± (3PCS, 4PCS)**`
- ì˜ëª»ëœ ì˜ˆì‹œ: `**ì„¸íŠ¸ êµ¬ì„±**(3PCS, 4PCS)` (íŠ¹ìˆ˜ë¬¸ìê°€ ë°”ë¡œ ë¶™ìœ¼ë©´ íŒŒì‹± ì‹¤íŒ¨)
- íŠ¹ìˆ˜ë¬¸ì ì•ì—ëŠ” ê³µë°±ì„ ë‘ê±°ë‚˜, íŠ¹ìˆ˜ë¬¸ìê¹Œì§€ í¬í•¨í•´ì„œ êµµê²Œ ì²˜ë¦¬í•˜ì„¸ìš”.

**Mood (ë¬´ë“œ & ìŠ¤íƒ€ì¼):**

ë°ì´í„°ì—ì„œ í™•ì¸ëœ ì‹œê°ì  ë¶„ìœ„ê¸°ì™€ ë””ìì¸ì  íŠ¹ì§•ì„ ë¶„ì„í•˜ì„¸ìš”. ì‹¤ì œ ë°ì´í„°ì—ì„œ í™•ì¸ëœ íŒ¨í„´ë§Œ ê¸°ë°˜ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.

**ì¤‘ìš”:** êµ¬ì²´ì ì¸ ë””ìì¸ ìš”ì†Œ, ìŠ¤íƒ€ì¼ í‚¤ì›Œë“œ, ì‹¤ë£¨ì—£, ë””í…Œì¼ëª…(ì˜ˆ: ë¡œê³  ê·¸ë˜í”½, ë¹ˆí‹°ì§€ ì›Œì‹±, ë¦´ë ‰ìŠ¤ í•, ìŠ¤ì›¨íŠ¸ ì…‹ì—…, íŠ¸ìœ„ë“œ ì…‹ì—…, ë ˆì´ìŠ¤ ìŠ¬ë¦½ ë“œë ˆìŠ¤, í”„ë¦´ ë””í…Œì¼, íƒ€ì´ì—… ë””ìì¸ ë“± ë°ì´í„°ì—ì„œ í™•ì¸ëœ ì‹¤ì œ í‚¤ì›Œë“œ)ëŠ” ë°˜ë“œì‹œ **êµµê²Œ** ì²˜ë¦¬í•˜ì„¸ìš”. ë°ì´í„°ì—ì„œ ë‚˜íƒ€ë‚œ ì‹¤ì œ ë””ìì¸ ìš”ì†Œë§Œ ê°•ì¡°í•˜ì„¸ìš”.

**âš ï¸ ë§ˆí¬ë‹¤ìš´ êµµê²Œ ì²˜ë¦¬ ì£¼ì˜ì‚¬í•­:**
- `**êµµê²Œ**` ì²˜ë¦¬ ì‹œ, ì•ë’¤ì— ê´„í˜¸ `()` ë‚˜ ì‰¼í‘œ `,` ê°™ì€ íŠ¹ìˆ˜ë¬¸ìê°€ ë°”ë¡œ ë¶™ìœ¼ë©´ ë§ˆí¬ë‹¤ìš´ íš¨ê³¼ê°€ ì‚¬ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- ì˜¬ë°”ë¥¸ ì˜ˆì‹œ: `**ì„¸íŠ¸ êµ¬ì„±** (3PCS, 4PCS)` ë˜ëŠ” `**ì˜¤ë²„í•** ì‹¤ë£¨ì—£` ë˜ëŠ” `**íŠ¸ìœ„ë“œ ì…‹ì—…**, **ë‹ˆíŠ¸ ì„¸íŠ¸**`
- ì˜ëª»ëœ ì˜ˆì‹œ: `**ì„¸íŠ¸ êµ¬ì„±**(3PCS, 4PCS)` ë˜ëŠ” `**ì˜¤ë²„í•**,` (íŠ¹ìˆ˜ë¬¸ìê°€ ë°”ë¡œ ë¶™ìœ¼ë©´ íŒŒì‹± ì‹¤íŒ¨)
- íŠ¹ìˆ˜ë¬¸ì ì•ì—ëŠ” ê³µë°±ì„ ë‘ê±°ë‚˜, ì—¬ëŸ¬ í‚¤ì›Œë“œë¥¼ ë‚˜ì—´í•  ë•ŒëŠ” ê°ê° ë³„ë„ë¡œ `**í‚¤ì›Œë“œ1**, **í‚¤ì›Œë“œ2**` í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.

âš ï¸ **ì¤‘ìš”:** ì´ ì„¹ì…˜ì€ **ë°˜ë“œì‹œ ì œê³µëœ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ** ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤. ì˜ˆì‹œ ë¬¸êµ¬ë‚˜ í…œí”Œë¦¿ì„ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”. ê° í•­ëª© ì‚¬ì´ì—ëŠ” ë°˜ë“œì‹œ ë¹ˆ ì¤„ì„ ì¶”ê°€í•˜ì„¸ìš”.

## Section 3. TRENDS

âš ï¸ **ì¤‘ìš”:** ê° ì¹´í…Œê³ ë¦¬ë³„ë¡œ **ê°€ì¥ ê°•ë ¥í•œ íŠ¸ë Œë“œ íë¦„ 2ê°€ì§€**ë¥¼ ì„ ì •í•˜ì—¬ ìš”ì•½í•˜ì„¸ìš”.

**[ë™ì  ì‚¬ê³  ê°€ì´ë“œ (Thinking Process)]**
ê° ì¹´í…Œê³ ë¦¬ ë¶„ì„ ì‹œ, ë‹¤ìŒ ê³¼ì •ì„ ê±°ì³ ì‘ì„±í•˜ì„¸ìš”:
1.  **ê´€ì°°:** ìƒìœ„ê¶Œ ìƒí’ˆë“¤ì˜ ê³µí†µì ì€ ë¬´ì—‡ì¸ê°€? (ì˜ˆ: ë¡œê³ ê°€ ë§ìŒ, ê¸°ì¥ì´ ì§§ìŒ, ì†Œì¬ê°€ ë…íŠ¹í•¨)
2.  **ëª…ëª…(Naming):** ì´ í˜„ìƒì„ í•œ ë‹¨ì–´ë¡œ ì •ì˜í•˜ë©´ ë¬´ì—‡ì¸ê°€? (ì˜ˆ: "Y2K ë¡œê³  í”Œë ˆì´", "í¬ë¡­íŠ¸ ì‹¤ë£¨ì—£ì˜ ë¶€ìƒ") -> ì´ê²ƒì´ **í—¤ë“œë¼ì¸**ì´ ë©ë‹ˆë‹¤.
3.  **ì„¤ëª…:** ì´ íŠ¸ë Œë“œê°€ ì™œ ë°œìƒí–ˆëŠ”ê°€? ì–´ë–¤ êµ¬ì²´ì  ë””í…Œì¼(ì†Œì¬, íŒ¨í„´ ë“±)ì´ ì†Œë¹„ìë¥¼ ìê·¹í–ˆëŠ”ê°€? -> ì´ê²ƒì´ **ì„¤ëª… ë³¸ë¬¸**ì´ ë©ë‹ˆë‹¤.

**[ì‘ì„± í¬ë§· ì¤€ìˆ˜]**
ê° ì¹´í…Œê³ ë¦¬ ì•„ë˜ì— ë°˜ë“œì‹œ ë¶ˆë › í¬ì¸íŠ¸(`*`)ë¥¼ ì‚¬ìš©í•˜ì—¬ ë”± 2ì¤„ì„ ì‘ì„±í•˜ì„¸ìš”.
* **íŠ¸ë Œë“œ í—¤ë“œë¼ì¸:** íŠ¸ë Œë“œ ë°°ê²½ ë° ë””í…Œì¼ ì„¤ëª… ë¬¸ì¥.
* **íŠ¸ë Œë“œ í—¤ë“œë¼ì¸:** íŠ¸ë Œë“œ ë°°ê²½ ë° ë””í…Œì¼ ì„¤ëª… ë¬¸ì¥.

(ì£¼ì˜: í—¤ë“œë¼ì¸ì€ ëª…ì‚¬í˜•ìœ¼ë¡œ ëë‚´ê³  êµµê²Œ ì²˜ë¦¬, ì„¤ëª… ë¬¸ì¥ ë‚´ í•µì‹¬ íŒ¨ì…˜ í‚¤ì›Œë“œë„ ë°˜ë“œì‹œ êµµê²Œ ì²˜ë¦¬í•  ê²ƒ)

**âš ï¸ ë§ˆí¬ë‹¤ìš´ êµµê²Œ ì²˜ë¦¬ ì£¼ì˜ì‚¬í•­:**
- `**êµµê²Œ**` ì²˜ë¦¬ ì‹œ, ì•ë’¤ì— ê´„í˜¸ `()` ë‚˜ ì‰¼í‘œ `,` ê°™ì€ íŠ¹ìˆ˜ë¬¸ìê°€ ë°”ë¡œ ë¶™ìœ¼ë©´ ë§ˆí¬ë‹¤ìš´ íš¨ê³¼ê°€ ì‚¬ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- ì˜¬ë°”ë¥¸ ì˜ˆì‹œ: `**íŠ¸ë Œë“œ í‚¤ì›Œë“œ** (ì„¤ëª…)` ë˜ëŠ” `**í‚¤ì›Œë“œ1**, **í‚¤ì›Œë“œ2**`
- ì˜ëª»ëœ ì˜ˆì‹œ: `**íŠ¸ë Œë“œ í‚¤ì›Œë“œ**(ì„¤ëª…)` (íŠ¹ìˆ˜ë¬¸ìê°€ ë°”ë¡œ ë¶™ìœ¼ë©´ íŒŒì‹± ì‹¤íŒ¨)
- íŠ¹ìˆ˜ë¬¸ì ì•ì—ëŠ” ê³µë°±ì„ ë‘ê±°ë‚˜, ì—¬ëŸ¬ í‚¤ì›Œë“œë¥¼ ë‚˜ì—´í•  ë•ŒëŠ” ê°ê° ë³„ë„ë¡œ `**í‚¤ì›Œë“œ1**, **í‚¤ì›Œë“œ2**` í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.

**âš ï¸ ì¹´í…Œê³ ë¦¬ í—¤ë“œë¼ì¸ í˜•ì‹ (í•„ìˆ˜ ì¤€ìˆ˜):**
- ê° ì¹´í…Œê³ ë¦¬ëŠ” ë°˜ë“œì‹œ `**ì¹´í…Œê³ ë¦¬ëª…:**` í˜•ì‹ìœ¼ë¡œ ì‹œì‘í•´ì•¼ í•©ë‹ˆë‹¤.
- ì¹´í…Œê³ ë¦¬ëª…ì€ ì œê³µëœ ë°ì´í„°ì— ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ” ì¹´í…Œê³ ë¦¬ëª…ì„ ì •í™•í•˜ê²Œ ì‚¬ìš©í•˜ì„¸ìš”. (ì˜ˆ: 29CMì˜ ê²½ìš° "ìƒì˜", "ë°”ì§€", "ìŠ¤ì»¤íŠ¸", "ì›í”¼ìŠ¤", "ë‹ˆíŠ¸ì›¨ì–´", "ì…‹ì—…", Ablyì˜ ê²½ìš° "ìƒì˜", "íŒ¬ì¸ ", "ìŠ¤ì»¤íŠ¸", "ì›í”¼ìŠ¤/ì„¸íŠ¸", "íŠ¸ë ˆì´ë‹", "ë¹„ì¹˜ì›¨ì–´", "ì•„ìš°í„°" ë“±)
- ì¹´í…Œê³ ë¦¬ í—¤ë“œë¼ì¸ ë‹¤ìŒì—ëŠ” ë¹ˆ ì¤„ì„ ì¶”ê°€í•˜ê³ , ê·¸ ë‹¤ìŒì— ë¶„ì„ í…ìŠ¤íŠ¸ë¥¼ ì‘ì„±í•˜ì„¸ìš”.

**ğŸ”¥ ê¸‰ìƒìŠ¹ (Rising Star)**

**ì¹´í…Œê³ ë¦¬ëª…:** (ë°ì´í„°ì— ìˆëŠ” ì¹´í…Œê³ ë¦¬ë§Œ ì‘ì„±)
- ìœ„ [ë™ì  ì‚¬ê³  ê°€ì´ë“œ]ì— ë”°ë¼ ê¸‰ìƒìŠ¹ íŠ¸ë Œë“œ 2ê°€ì§€ë¥¼ ì‘ì„±.

**ğŸš€ ì‹ ê·œ ì§„ì… (New Entry)**

**ì¹´í…Œê³ ë¦¬ëª…:** (ë°ì´í„°ì— ìˆëŠ” ì¹´í…Œê³ ë¦¬ë§Œ ì‘ì„±)
- ìœ„ [ë™ì  ì‚¬ê³  ê°€ì´ë“œ]ì— ë”°ë¼ ì‹ ê·œ ì§„ì… íŠ¸ë Œë“œ 2ê°€ì§€ë¥¼ ì‘ì„±.

**ğŸ“‰ ìˆœìœ„ í•˜ë½ (Rank Drop)**

**ì¹´í…Œê³ ë¦¬ëª…:** (ë°ì´í„°ì— ìˆëŠ” ì¹´í…Œê³ ë¦¬ë§Œ ì‘ì„±)
- ìœ„ [ë™ì  ì‚¬ê³  ê°€ì´ë“œ]ì— ë”°ë¼ í•˜ë½ì„¸ì— ìˆëŠ” ìŠ¤íƒ€ì¼ì´ë‚˜ ëŒ€ì²´ë˜ê³  ìˆëŠ” íë¦„ 2ê°€ì§€ë¥¼ ì‘ì„±.

[ì‘ì„± ìŠ¤íƒ€ì¼]
- **ë¶ˆë › í¬ì¸íŠ¸ í˜•ì‹ í•„ìˆ˜:** ê° ì¹´í…Œê³ ë¦¬ë³„ ë¶„ì„ì€ ë°˜ë“œì‹œ ë¶ˆë › í¬ì¸íŠ¸(`-`)ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‘ì„±í•˜ì„¸ìš”. í•œ ì¤„ë¡œ ì´ì–´ì§€ëŠ” ê¸´ ë¬¸ì¥ë³´ë‹¤ëŠ” ë¶ˆë › í¬ì¸íŠ¸ë¡œ ë‚˜ëˆ„ì–´ ì‘ì„±í•˜ì„¸ìš”.
- **ì¹´í…Œê³ ë¦¬ í—¤ë“œë¼ì¸ ë‹¤ìŒ ë¶ˆë › í¬ì¸íŠ¸:** ì¹´í…Œê³ ë¦¬ í—¤ë“œë¼ì¸(`**ì¹´í…Œê³ ë¦¬ëª…:**`) ë‹¤ìŒ ì¤„ë¶€í„° ë¶ˆë › í¬ì¸íŠ¸ë¡œ ì‹œì‘í•˜ëŠ” ë¶„ì„ í…ìŠ¤íŠ¸ë¥¼ ì‘ì„±í•˜ì„¸ìš”.
- **ì¹´í…Œê³ ë¦¬, ì„¸ê·¸ë¨¼íŠ¸, ì£¼ìš” í•­ëª© ì‚¬ì´ì—ëŠ” ë°˜ë“œì‹œ ë¹ˆ ì¤„ì„ ì¶”ê°€**í•˜ì—¬ ê°€ë…ì„±ì„ ë†’ì´ì„¸ìš”.
- ë°ì´í„°ì— ë‚˜íƒ€ë‚œ êµ¬ì²´ì ì¸ íŒ¨í„´ì„ ë°ì´í„°ì—ì„œ í™•ì¸ëœ ì‹¤ì œ ë‚´ìš©ë§Œ ê¸°ë°˜ìœ¼ë¡œ ì–¸ê¸‰í•˜ì„¸ìš”.
- **ë§¤ì£¼ ë‹¤ë¥¸ ë‚´ìš© í•„ìˆ˜:** ë§¤ì£¼ ë‹¤ë¥¸ ë°ì´í„°ê°€ ì œê³µë˜ë¯€ë¡œ, ë§¤ì£¼ ì™„ì „íˆ ë‹¤ë¥¸ ê´€ì ê³¼ ë‚´ìš©ìœ¼ë¡œ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤. ì´ì „ ì£¼ì™€ ìœ ì‚¬í•œ í‘œí˜„ì´ë‚˜ íŒ¨í„´ì„ ë°˜ë³µí•˜ì§€ ë§ˆì„¸ìš”.
- **ë§ˆí¬ë‹¤ìš´ í˜•ì‹(**êµµê²Œ**, *ê¸°ìš¸ì„*, ë¶ˆë › í¬ì¸íŠ¸)ì„ ì ì ˆíˆ í™œìš©í•˜ì„¸ìš”.**
"""


# ============================================
# ë°ì´í„° ìµœì í™” í•¨ìˆ˜
# ============================================

def optimize_data_for_flash(json_data: Dict) -> str:
    """
    JSON ë°ì´í„°ë¥¼ í…ìŠ¤íŠ¸ í˜•íƒœë¡œ ì••ì¶•í•˜ì—¬ Flash ëª¨ë¸ì´ ì²˜ë¦¬í•˜ê¸° ì‰½ê²Œ ë³€í™˜
    ìƒí’ˆëª… ê¸¸ì´ë¥¼ íŒŒê²©ì ìœ¼ë¡œ ì¤„ì—¬ í† í° ì ˆì•½ ë° ê°€ë…ì„± í™•ë³´
    **ì´ ë°ì´í„°ëŠ” AIê°€ "ì½ê¸°ìš©"ì´ì§€, "ì“°ê¸°ìš©"ì´ ì•„ë‹˜ì„ ëª…ì‹¬.**
    
    Args:
        json_data: ì¹´í…Œê³ ë¦¬ë³„ íŠ¸ë Œë“œ ë°ì´í„°
    
    Returns:
        ì••ì¶•ëœ ì „ì²´ ë°ì´í„° í…ìŠ¤íŠ¸
    """
    lines = []
    
    # JSON êµ¬ì¡° ìˆœíšŒ
    for category, cat_data in json_data.items():
        if category == 'insights':
            continue  # ë¶ˆí•„ìš”í•œ ë©”íƒ€ë°ì´í„° ì œì™¸
        
        lines.append(f"\n== {category} ==")
        
        for segment, items in cat_data.items():  # rising_star, new_entry, rank_drop
            if not items:  # ë¹ˆ ë¦¬ìŠ¤íŠ¸ëŠ” ê±´ë„ˆë›°ê¸°
                continue
                
            segment_name = segment.upper()
            lines.append(f"[{segment_name}]")
            
            # ìƒìœ„ 15ê°œ ì•„ì´í…œë§Œ ì²˜ë¦¬ (ë°ì´í„° ì¤„ì´ê¸°)
            for item in items[:15]:
                brand = item.get('Brand', '') or ''
                product = item.get('Product', '') or ''
                
                # ìƒí’ˆëª… ë‹¨ì¶• ë¡œì§ (20ì ì´ˆê³¼ ì‹œ 18ì + ..)
                if len(product) > 20:
                    product = product[:18] + ".."
                
                # í•œê¸€ ê¹¨ì§ ë°©ì§€ë¥¼ ìœ„í•´ ë³€ìˆ˜ ì§ì ‘ ì‚¬ìš©
                change = item.get('Rank_Change', 0) or 0
                price = item.get('Price', 0) or 0
                
                # ìˆœìœ„ ë³€í™” í¬ë§·íŒ…
                if change is None or change == 0:
                    change_str = "ë³€ë™ì—†ìŒ"
                elif change > 0:
                    change_str = f"+{change}ìœ„ ìƒìŠ¹"
                else:
                    change_str = f"{change}ìœ„ í•˜ë½"
                
                # í•œ ì¤„ ìš”ì•½ í¬ë§·
                line = f"- {brand} | {product} | {change_str} | {price}ì›"
                lines.append(line)
    
    return "\n".join(lines)


# ============================================
# í”„ë¡¬í”„íŠ¸ ìƒì„± í•¨ìˆ˜
# ============================================

def build_trend_analysis_prompt(
    snapshot_data: Dict,
    target_brand: str = DEFAULT_TARGET_BRAND
) -> str:
    """
    29CM íŠ¸ë Œë“œ ë¶„ì„ í”„ë¡¬í”„íŠ¸ ìƒì„±
    
    Args:
        snapshot_data: íŠ¸ë Œë“œ ìŠ¤ëƒ…ìƒ· ë°ì´í„°
        target_brand: ë¶„ì„ íƒ€ê²Ÿ ë¸Œëœë“œëª… (í•œê¸€ëª…)
    
    Returns:
        í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´
    """
    tabs_data = snapshot_data.get("tabs_data", {})
    current_week = snapshot_data.get("current_week", "")
    
    # ë°ì´í„° ìš”ì•½ ë° í•„ìˆ˜ í•„ë“œë§Œ ì¶”ì¶œ
    def extract_essential_fields(items: list, max_items: int = 15) -> list:
        """í•„ìˆ˜ í•„ë“œë§Œ ì¶”ì¶œí•˜ì—¬ AI í”„ë¡¬í”„íŠ¸ í¬ê¸° ìµœì í™”"""
        essential = []
        for item in items[:max_items]:  # ìƒìœ„ Nê°œë§Œ ì‚¬ìš©
            essential.append({
                "Brand": item.get("Brand_Name"),  # í•„ìˆ˜: ë¸Œëœë“œëª…
                "Product": item.get("Product_Name"),  # í•„ìˆ˜: ìƒí’ˆëª…
                "Rank_Change": item.get("Rank_Change"),  # í•„ìˆ˜: ìˆœìœ„ ë³€í™”
                "Price": item.get("price")  # í•„ìˆ˜: ê°€ê²©
            })
        return essential
    
    # ëª¨ë“  ì¹´í…Œê³ ë¦¬ ì„ íƒ (CORE_CATEGORIES í•„í„°ë§ ì œê±°)
    # tabs_dataì— ìˆëŠ” ëª¨ë“  ì¹´í…Œê³ ë¦¬ë¥¼ ì‚¬ìš© (29CMì™€ Ably ëª¨ë‘ ì§€ì›)
    all_tabs = list(tabs_data.keys())
    
    # "ì „ì²´" íƒ­ì´ ìˆìœ¼ë©´ ì œì™¸ (ì„¸ë¶€ ì¹´í…Œê³ ë¦¬ë§Œ ì‚¬ìš©)
    if "ì „ì²´" in all_tabs:
        all_tabs = [tab for tab in all_tabs if tab != "ì „ì²´"]
    
    # ë°ì´í„° ì¤€ë¹„ (ëª¨ë“  ì¹´í…Œê³ ë¦¬, ê° ì„¸ê·¸ë¨¼íŠ¸ë‹¹ ìƒìœ„ 15ê°œ)
    all_categories_data = {}
    
    for tab_name in all_tabs:
        if tab_name not in tabs_data:
            continue
        tab_data = tabs_data[tab_name]
        all_categories_data[tab_name] = {
            "rising_star": extract_essential_fields(tab_data.get("rising_star", []), max_items=15),
            "new_entry": extract_essential_fields(tab_data.get("new_entry", []), max_items=15),
            "rank_drop": extract_essential_fields(tab_data.get("rank_drop", []), max_items=15)
        }
    
    # ë°ì´í„° ìš”ì•½ í†µê³„ (ì „ì²´ íƒ­ ê¸°ì¤€)
    total_rising = sum(len(tab_data.get("rising_star", [])) for tab_data in tabs_data.values())
    total_new_entry = sum(len(tab_data.get("new_entry", [])) for tab_data in tabs_data.values())
    total_rank_drop = sum(len(tab_data.get("rank_drop", [])) for tab_data in tabs_data.values())
    
    # ë°ì´í„°ë¥¼ í…ìŠ¤íŠ¸ í˜•íƒœë¡œ ì••ì¶• (Flash ëª¨ë¸ ìµœì í™” + ìƒí’ˆëª… ë‹¨ì¶•)
    optimized_data = optimize_data_for_flash(all_categories_data)
    
    # ë””ë²„ê¹…: ì••ì¶•ëœ ë°ì´í„° í™•ì¸
    print(f"ğŸ” [DEBUG] ì••ì¶•ëœ ë°ì´í„° ê¸¸ì´: {len(optimized_data):,} ì", file=sys.stderr)
    print(f"ğŸ” [DEBUG] ì••ì¶•ëœ ë°ì´í„° ì¼ë¶€ (ì²˜ìŒ 300ì):\n{optimized_data[:300]}", file=sys.stderr)
    
    # í•œê¸€ í¬í•¨ ì—¬ë¶€ í™•ì¸
    has_korean = any('\uac00' <= char <= '\ud7a3' for char in optimized_data)
    print(f"ğŸ” [DEBUG] ì••ì¶•ëœ ë°ì´í„° í•œê¸€ í¬í•¨ ì—¬ë¶€: {has_korean}", file=sys.stderr)
    
    # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    prompt = f"""
[ë¶„ì„í•  ë°ì´í„°]
í˜„ì¬ ì£¼ì°¨: {current_week}

ë°ì´í„° ìš”ì•½:
- ê¸‰ìƒìŠ¹ ìƒí’ˆ: {total_rising}ê°œ
- ì‹ ê·œ ì§„ì… ìƒí’ˆ: {total_new_entry}ê°œ
- ìˆœìœ„ í•˜ë½ ìƒí’ˆ: {total_rank_drop}ê°œ

ì „ì²´ ì¹´í…Œê³ ë¦¬ ë°ì´í„° (ê° ì„¸ê·¸ë¨¼íŠ¸ë‹¹ ìƒìœ„ 15ê°œ):
{optimized_data}

âš ï¸ [ì¤‘ìš” ì§€ì¹¨]
1. **ë°ì´í„° ê¸°ë°˜ ë¶„ì„ í•„ìˆ˜:** ìœ„ì— ì œê³µëœ ì‹¤ì œ ë°ì´í„°ë§Œì„ ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„í•˜ì„¸ìš”. ë°ì´í„°ì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”.
2. **ì˜ˆì‹œë‚˜ í…œí”Œë¦¿ ê¸ˆì§€:** "(ì˜ˆ: ...)" ê°™ì€ ì˜ˆì‹œ ë¬¸êµ¬ë‚˜ ê³ ì •ëœ í…œí”Œë¦¿ì„ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”. ì‹¤ì œ ë°ì´í„° íŒ¨í„´ë§Œ ë¶„ì„í•˜ì„¸ìš”.
3. **ë§¤ì£¼ ë‹¤ë¥¸ ë‚´ìš© (í•„ìˆ˜):** ì´ë²ˆ ì£¼ ë°ì´í„°ëŠ” ì´ì „ ì£¼ì™€ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ì´ë²ˆ ì£¼ ë°ì´í„°ì—ë§Œ ê¸°ë°˜í•˜ì—¬ ì™„ì „íˆ ìƒˆë¡œìš´ ë‚´ìš©ì„ ì‘ì„±í•˜ì„¸ìš”. ì´ì „ ì£¼ ë¦¬í¬íŠ¸ì™€ ìœ ì‚¬í•œ í‘œí˜„, íŒ¨í„´, êµ¬ì¡°ë¥¼ ì ˆëŒ€ ë°˜ë³µí•˜ì§€ ë§ˆì„¸ìš”. ë§¤ì£¼ ë°ì´í„°ë¥¼ ìƒˆë¡­ê²Œ ë¶„ì„í•˜ì—¬ ê³ ìœ í•œ ì¸ì‚¬ì´íŠ¸ë¥¼ ë„ì¶œí•˜ì„¸ìš”.
4. **ìœ ì—°í•œ êµ¬ì¡°:** ë°ì´í„°ê°€ ì—†ëŠ” ì¹´í…Œê³ ë¦¬ë‚˜ ì„¸ê·¸ë¨¼íŠ¸ëŠ” ìƒëµí•˜ì„¸ìš”. ëª¨ë“  í•­ëª©ì„ ê°•ì œë¡œ ì±„ìš¸ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤.
5. **êµ¬ì²´ì  íŒ¨í„´ ë¶„ì„:** ì¶”ìƒì  í‘œí˜„ë³´ë‹¤ëŠ”, ë°ì´í„°ì—ì„œ í™•ì¸ëœ êµ¬ì²´ì  íŒ¨í„´ì„ ë°ì´í„°ì— ë‚˜íƒ€ë‚œ ì‹¤ì œ ë‚´ìš©ë§Œ ê¸°ë°˜ìœ¼ë¡œ ì œì‹œí•˜ì„¸ìš”.
6. **ë§ˆí¬ë‹¤ìš´ í˜•ì‹ í•„ìˆ˜:** ë°˜ë“œì‹œ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì„ ì‚¬ìš©í•˜ì„¸ìš”. **êµµê²Œ**, *ê¸°ìš¸ì„*, ì¤„ë°”ê¿ˆ(ë¹ˆ ì¤„), ë¶ˆë › í¬ì¸íŠ¸(`*` ë˜ëŠ” `-`)ë¥¼ ì ì ˆíˆ í™œìš©í•˜ì„¸ìš”.
7. **ì¤„ë°”ê¿ˆ í•„ìˆ˜:** ê°€ë…ì„±ì„ ìœ„í•´ ì ì ˆí•œ ì¤„ë°”ê¿ˆì„ ì‚¬ìš©í•˜ì„¸ìš”. ì„¹ì…˜, ì¹´í…Œê³ ë¦¬, ì„¸ê·¸ë¨¼íŠ¸, ì£¼ìš” í•­ëª© ì‚¬ì´ì—ëŠ” ë°˜ë“œì‹œ ë¹ˆ ì¤„ì„ ì¶”ê°€í•˜ì„¸ìš”.

ìœ„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ 3ê°€ì§€ ì„¹ì…˜ìœ¼ë¡œ êµ¬ì„±ëœ íŠ¸ë Œë“œ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""
    
    return prompt


# ============================================
# AI ë¶„ì„ ìƒì„± í•¨ìˆ˜
# ============================================

def generate_trend_analysis(
    snapshot_data: Dict,
    api_key: Optional[str] = None,
    target_brand: Optional[str] = None,
    max_tokens: int = 16384,
    platform: str = "29CM"
) -> Optional[str]:
    """
    29CM íŠ¸ë Œë“œ ìŠ¤ëƒ…ìƒ· ë°ì´í„°ë¥¼ AIë¡œ ë¶„ì„í•˜ì—¬ ë¦¬í¬íŠ¸ ìƒì„±
    
    Args:
        snapshot_data: íŠ¸ë Œë“œ ìŠ¤ëƒ…ìƒ· ë°ì´í„° (tabs_data, current_week í¬í•¨)
        api_key: Gemini API í‚¤ (Noneì´ë©´ í™˜ê²½ë³€ìˆ˜ì—ì„œ ë¡œë“œ)
        target_brand: ë¶„ì„ íƒ€ê²Ÿ ë¸Œëœë“œëª… (í•œê¸€ëª…, Noneì´ë©´ DEFAULT_TARGET_BRAND ì‚¬ìš©)
        max_tokens: ìµœëŒ€ í† í° ìˆ˜ (ê¸°ë³¸ê°’ 16384)
    
    Returns:
        AI ë¶„ì„ ë¦¬í¬íŠ¸ í…ìŠ¤íŠ¸ (ë§ˆí¬ë‹¤ìš´ í˜•ì‹)
    """
    # google-genai íŒ¨í‚¤ì§€ í™•ì¸
    if not GENAI_AVAILABLE or genai is None or types is None:
        raise ImportError("google-genai íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'pip install google-genai'ë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")
    
    # API í‚¤ í™•ì¸
    api_key = api_key or GEMINI_API_KEY
    if not api_key:
        raise ValueError("GEMINI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ê±°ë‚˜ api_key íŒŒë¼ë¯¸í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    
    # íƒ€ê²Ÿ ë¸Œëœë“œ í™•ì¸ (ìš°ì„ ìˆœìœ„: íŒŒë¼ë¯¸í„° > snapshot_data > ê¸°ë³¸ê°’)
    if target_brand is None:
        # snapshot_dataì—ì„œ company_name ì¶”ì¶œ ì‹œë„ (ìˆìœ¼ë©´)
        company_name_en = snapshot_data.get("company_name")
        if company_name_en and COMPANY_MAPPING_AVAILABLE:
            # company_name_enì´ ë¬¸ìì—´ì´ë©´ ê·¸ëŒ€ë¡œ, ë¦¬ìŠ¤íŠ¸ë©´ ì²« ë²ˆì§¸ ìš”ì†Œ
            if isinstance(company_name_en, list):
                company_name_en = company_name_en[0] if company_name_en else None
            
            if company_name_en:
                # ì†Œë¬¸ìë¡œ ì •ê·œí™”
                company_name_en = str(company_name_en).lower().strip()
                target_brand = get_company_korean_name(company_name_en)
        
        if not target_brand:
            target_brand = DEFAULT_TARGET_BRAND
    
    print(f"ğŸ¯ [INFO] ë¶„ì„ íƒ€ê²Ÿ ë¸Œëœë“œ: {target_brand}", file=sys.stderr)
    
    # Google Gen AI SDK Client ì´ˆê¸°í™”
    try:
        client = genai.Client(api_key=api_key)
    except Exception as e:
        raise ImportError(f"google-genai ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    try:
        print(f"ğŸ¤– [INFO] 29CM íŠ¸ë Œë“œ ë¶„ì„ AI ë¦¬í¬íŠ¸ ìƒì„± ì‹œì‘...", file=sys.stderr)
        
        # System Instruction ìƒì„±
        system_instruction = build_system_instruction(target_brand, platform=platform)
        
        # Safety Settings ì„¤ì • (í•œê¸€ í•„í„°ë§ ë°©ì§€ - í•„ìˆ˜)
        safety_settings = None
        if SAFETY_SETTINGS_AVAILABLE and HarmCategory is not None and HarmBlockThreshold is not None:
            try:
                safety_settings = [
                    types.SafetySetting(
                        category=types.HarmCategory.HARM_CATEGORY_HARASSMENT,
                        threshold=types.HarmBlockThreshold.BLOCK_NONE
                    ),
                    types.SafetySetting(
                        category=types.HarmCategory.HARM_CATEGORY_HATE_SPEECH,
                        threshold=types.HarmBlockThreshold.BLOCK_NONE
                    ),
                    types.SafetySetting(
                        category=types.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,
                        threshold=types.HarmBlockThreshold.BLOCK_NONE
                    ),
                    types.SafetySetting(
                        category=types.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,
                        threshold=types.HarmBlockThreshold.BLOCK_NONE
                    ),
                ]
                print(f"âœ… [DEBUG] Safety Settings ì„¤ì • ì™„ë£Œ (ëª¨ë“  ì¹´í…Œê³ ë¦¬ BLOCK_NONE)", file=sys.stderr)
            except (AttributeError, TypeError) as e:
                print(f"âš ï¸ [WARN] Safety Settings ì„¤ì • ì‹¤íŒ¨: {e}, ê¸°ë³¸ ì„¤ì • ì‚¬ìš©", file=sys.stderr)
        else:
            print(f"âš ï¸ [WARN] Safety Settings ì‚¬ìš© ë¶ˆê°€ (import ì‹¤íŒ¨), ê¸°ë³¸ ì„¤ì • ì‚¬ìš©", file=sys.stderr)
        
        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = build_trend_analysis_prompt(snapshot_data, target_brand=target_brand)
        
        # System Instructionê³¼ í”„ë¡¬í”„íŠ¸ ê²°í•©
        full_prompt = f"{system_instruction}\n\n{prompt}"
        
        # í”„ë¡¬í”„íŠ¸ í¬ê¸° í™•ì¸
        prompt_length = len(full_prompt)
        print(f"ğŸ“Š [INFO] í”„ë¡¬í”„íŠ¸ í¬ê¸°: {prompt_length:,}ì", file=sys.stderr)
        
        # AI ëª¨ë¸ í˜¸ì¶œ
        print(f"ğŸ“¤ [INFO] Gemini API í˜¸ì¶œ ì¤‘...", file=sys.stderr)
        
        # GenerateContentConfig êµ¬ì„±
        config_kwargs = {
            "temperature": 0.7,
            "top_p": 0.95,
            "top_k": 40,
            "max_output_tokens": max_tokens,
        }
        
        # Safety Settings ì¶”ê°€ (ìˆëŠ” ê²½ìš°)
        if safety_settings:
            config_kwargs["safety_settings"] = safety_settings
        
        response = client.models.generate_content(
            model=GEMINI_MODEL,
            contents=full_prompt,
            config=types.GenerateContentConfig(**config_kwargs)
        )
        
        # ì‘ë‹µ íŒŒì‹±
        analysis_text = None
        if hasattr(response, 'text'):
            analysis_text = response.text
        elif hasattr(response, 'candidates') and response.candidates:
            candidate = response.candidates[0]
            if hasattr(candidate, 'content') and hasattr(candidate.content, 'parts') and candidate.content.parts:
                analysis_text = candidate.content.parts[0].text
            elif hasattr(candidate, 'content'):
                analysis_text = str(candidate.content)
            else:
                analysis_text = str(candidate)
        
        if not analysis_text:
            analysis_text = str(response)
        
        # ë§ˆí¬ë‹¤ìš´ ë³´ì¡´: í›„ì²˜ë¦¬ ì—†ì´ ì›ë³¸ ê·¸ëŒ€ë¡œ ì €ì¥
        # âš ï¸ remove_icons_and_emojis í•¨ìˆ˜ í˜¸ì¶œ ê¸ˆì§€ (ë§ˆí¬ë‹¤ìš´ ê¹¨ì§ ë°©ì§€)
        analysis_text = analysis_text.strip()
        
        # í•œê¸€ í¬í•¨ ì—¬ë¶€ í™•ì¸ (ë””ë²„ê¹…)
        if analysis_text:
            korean_count = sum(1 for char in analysis_text if '\uac00' <= char <= '\ud7a3')
            total_chars = len(analysis_text)
            korean_ratio = (korean_count / total_chars * 100) if total_chars > 0 else 0
            print(f"ğŸ” [DEBUG] ë¦¬í¬íŠ¸ í•œê¸€ í¬í•¨ ì—¬ë¶€: {korean_count}/{total_chars} ({korean_ratio:.1f}%)", file=sys.stderr)
            if korean_ratio < 30:
                print(f"âš ï¸ [WARN] ë¦¬í¬íŠ¸ì— í•œê¸€ì´ ì ìŠµë‹ˆë‹¤ ({korean_ratio:.1f}%)!", file=sys.stderr)
        
        char_count = len(analysis_text)
        print(f"âœ… [INFO] ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ ({char_count}ì)", file=sys.stderr)
        
        return analysis_text if analysis_text else None
        
    except Exception as e:
        print(f"âŒ [ERROR] AI ë¶„ì„ ìƒì„± ì‹¤íŒ¨: {e}", file=sys.stderr)
        traceback.print_exc()
        return None


# ============================================
# ìŠ¤ëƒ…ìƒ· ì²˜ë¦¬ í•¨ìˆ˜
# ============================================

def generate_trend_analysis_from_snapshot(
    snapshot_data: Dict,
    api_key: Optional[str] = None,
    target_brand: Optional[str] = None,
    platform: str = "29CM"
) -> Dict:
    """
    ìŠ¤ëƒ…ìƒ· ë°ì´í„°ì— AI ë¶„ì„ ë¦¬í¬íŠ¸ë¥¼ ì¶”ê°€í•˜ì—¬ ë°˜í™˜
    
    Args:
        snapshot_data: íŠ¸ë Œë“œ ìŠ¤ëƒ…ìƒ· ë°ì´í„°
        api_key: Gemini API í‚¤
        target_brand: ë¶„ì„ íƒ€ê²Ÿ ë¸Œëœë“œëª… (í•œê¸€ëª…, Noneì´ë©´ ìë™ ê°ì§€)
    
    Returns:
        AI ë¶„ì„ ë¦¬í¬íŠ¸ê°€ ì¶”ê°€ëœ snapshot_data
    """
    try:
        # AI ë¶„ì„ ìƒì„±
        analysis_text = generate_trend_analysis(
            snapshot_data,
            api_key=api_key,
            target_brand=target_brand,
            platform=platform
        )
        
        if analysis_text:
            # snapshot_dataì— ë¶„ì„ ë¦¬í¬íŠ¸ ì¶”ê°€
            if "insights" not in snapshot_data:
                snapshot_data["insights"] = {}
            
            from datetime import datetime
            snapshot_data["insights"]["analysis_report"] = analysis_text
            snapshot_data["insights"]["generated_at"] = datetime.utcnow().isoformat() + "Z"
            
            print(f"âœ… [SUCCESS] AI ë¶„ì„ ë¦¬í¬íŠ¸ê°€ ìŠ¤ëƒ…ìƒ·ì— ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.", file=sys.stderr)
        else:
            print(f"âš ï¸ [WARN] AI ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨, ìŠ¤ëƒ…ìƒ·ì€ ê·¸ëŒ€ë¡œ ìœ ì§€ë©ë‹ˆë‹¤.", file=sys.stderr)
        
        return snapshot_data
        
    except Exception as e:
        print(f"âŒ [ERROR] AI ë¶„ì„ ë¦¬í¬íŠ¸ ì¶”ê°€ ì‹¤íŒ¨: {e}", file=sys.stderr)
        traceback.print_exc()
        # ì—ëŸ¬ê°€ ë‚˜ë„ ìŠ¤ëƒ…ìƒ· ë°ì´í„°ëŠ” ê·¸ëŒ€ë¡œ ë°˜í™˜
        return snapshot_data


def generate_ai_analysis_from_file(
    snapshot_file: str,
    output_file: Optional[str] = None,
    api_key: Optional[str] = None,
    target_brand: Optional[str] = None,
    platform: str = "29CM"
) -> Dict:
    """
    ìŠ¤ëƒ…ìƒ· íŒŒì¼(GCS ë˜ëŠ” ë¡œì»¬)ì—ì„œ ì½ì–´ì„œ AI ë¶„ì„ í›„ ì €ì¥
    
    Args:
        snapshot_file: ì…ë ¥ ìŠ¤ëƒ…ìƒ· íŒŒì¼ ê²½ë¡œ (ë¡œì»¬ íŒŒì¼ ë˜ëŠ” gs:// ê²½ë¡œ)
        output_file: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ (Noneì´ë©´ ì…ë ¥ íŒŒì¼ì— ë®ì–´ì“°ê¸°, ë¡œì»¬ íŒŒì¼ ë˜ëŠ” gs:// ê²½ë¡œ)
        api_key: Gemini API í‚¤
        target_brand: ë¶„ì„ íƒ€ê²Ÿ ë¸Œëœë“œëª… (í•œê¸€ëª…, Noneì´ë©´ ìë™ ê°ì§€)
    
    Returns:
        AI ë¶„ì„ ë¦¬í¬íŠ¸ê°€ ì¶”ê°€ëœ snapshot_data
    """
    try:
        from google.cloud import storage
        import gzip
    except ImportError:
        print("âŒ [ERROR] google-cloud-storage íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤.", file=sys.stderr)
        raise
    
    # ì…ë ¥ íŒŒì¼ ì½ê¸° (GCS ë˜ëŠ” ë¡œì»¬)
    if snapshot_file.startswith("gs://"):
        print(f"ğŸ“¥ [INFO] GCSì—ì„œ íŒŒì¼ ë¡œë“œ ì¤‘: {snapshot_file}", file=sys.stderr)
        # GCSì—ì„œ ë‹¤ìš´ë¡œë“œ
        parts = snapshot_file.replace("gs://", "").split("/", 1)
        if len(parts) != 2:
            raise ValueError(f"GCS ê²½ë¡œ íŒŒì‹± ì‹¤íŒ¨: {snapshot_file}")
        
        bucket_name = parts[0]
        blob_path = parts[1]
        
        storage_client = storage.Client()
        bucket = storage_client.bucket(bucket_name)
        blob = bucket.blob(blob_path)
        
        if not blob.exists():
            raise FileNotFoundError(f"GCS íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {snapshot_file}")
        
        # Gzip ì••ì¶• í•´ì œ
        snapshot_bytes = blob.download_as_bytes(raw_download=True)
        try:
            snapshot_json_str = gzip.decompress(snapshot_bytes).decode('utf-8')
            print(f"âœ… [DEBUG] Gzip ì••ì¶• í•´ì œ ì„±ê³µ", file=sys.stderr)
        except (gzip.BadGzipFile, OSError) as e:
            snapshot_json_str = snapshot_bytes.decode('utf-8')
            print(f"âš ï¸ [WARN] Gzip ì••ì¶• í•´ì œ ì‹¤íŒ¨, ì¼ë°˜ í…ìŠ¤íŠ¸ë¡œ ì²˜ë¦¬: {e}", file=sys.stderr)
        
        snapshot_data = json.loads(snapshot_json_str)
    else:
        print(f"ğŸ“¥ [INFO] ë¡œì»¬ íŒŒì¼ ë¡œë“œ ì¤‘: {snapshot_file}", file=sys.stderr)
        with open(snapshot_file, 'r', encoding='utf-8') as f:
            snapshot_data = json.load(f)
    
    # AI ë¶„ì„ ìˆ˜í–‰
    snapshot_data = generate_trend_analysis_from_snapshot(
        snapshot_data,
        api_key=api_key,
        target_brand=target_brand,
        platform=platform
    )
    
    # AI ë¶„ì„ ê²°ê³¼ í™•ì¸ (ë””ë²„ê¹…)
    if "insights" in snapshot_data and snapshot_data["insights"].get("analysis_report"):
        analysis_report_len = len(snapshot_data["insights"]["analysis_report"])
        print(f"âœ… [DEBUG] AI ë¶„ì„ ë¦¬í¬íŠ¸ê°€ ìŠ¤ëƒ…ìƒ· ë°ì´í„°ì— í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤ ({analysis_report_len}ì).", file=sys.stderr)
    else:
        print(f"âš ï¸ [DEBUG] AI ë¶„ì„ ë¦¬í¬íŠ¸ê°€ ìŠ¤ëƒ…ìƒ· ë°ì´í„°ì— í¬í•¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.", file=sys.stderr)
    
    # ê²°ê³¼ ì €ì¥ (ì¶œë ¥ ê²½ë¡œ ë¯¸ì§€ì • ì‹œ ì…ë ¥ íŒŒì¼ ê²½ë¡œì— ë®ì–´ì“°ê¸°)
    output_path = output_file or snapshot_file
    
    if output_path.startswith("gs://"):
        print(f"ğŸ“¤ [INFO] GCSì— íŒŒì¼ ì—…ë¡œë“œ ì¤‘: {output_path}", file=sys.stderr)
        parts = output_path.replace("gs://", "").split("/", 1)
        if len(parts) != 2:
            raise ValueError(f"GCS ê²½ë¡œ íŒŒì‹± ì‹¤íŒ¨: {output_path}")
        
        bucket_name = parts[0]
        blob_path = parts[1]
        
        storage_client = storage.Client()
        bucket = storage_client.bucket(bucket_name)
        blob = bucket.blob(blob_path)
        
        # JSON ì§ë ¬í™” ë° Gzip ì••ì¶•
        json_str = json.dumps(snapshot_data, ensure_ascii=False, indent=2)
        json_bytes = json_str.encode('utf-8')
        compressed_bytes = gzip.compress(json_bytes)
        
        blob.upload_from_string(compressed_bytes, content_type='application/gzip')
        print(f"âœ… [DEBUG] GCS ì—…ë¡œë“œ ì™„ë£Œ. íŒŒì¼ í¬ê¸°: {len(compressed_bytes):,} bytes", file=sys.stderr)
    else:
        print(f"ğŸ“¤ [INFO] ë¡œì»¬ íŒŒì¼ ì €ì¥ ì¤‘: {output_path}", file=sys.stderr)
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(snapshot_data, f, ensure_ascii=False, indent=2, sort_keys=True)
    
    print(f"âœ… [SUCCESS] AI ë¶„ì„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_path}", file=sys.stderr)
    
    return snapshot_data


# ============================================
# CLI ì§„ì…ì 
# ============================================

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="29CM íŠ¸ë Œë“œ ë¶„ì„ AI ë¦¬í¬íŠ¸ ìƒì„±")
    parser.add_argument("snapshot_file", help="ìŠ¤ëƒ…ìƒ· íŒŒì¼ ê²½ë¡œ (ë¡œì»¬ ë˜ëŠ” gs:// ê²½ë¡œ)")
    parser.add_argument("--output", "-o", help="ì¶œë ¥ íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: ì…ë ¥ íŒŒì¼ì— ë®ì–´ì“°ê¸°)")
    parser.add_argument("--api-key", help="Gemini API í‚¤ (ê¸°ë³¸ê°’: í™˜ê²½ë³€ìˆ˜ì—ì„œ ë¡œë“œ)")
    parser.add_argument("--target-brand", help="ë¶„ì„ íƒ€ê²Ÿ ë¸Œëœë“œëª… (í•œê¸€ëª…, ì˜ˆ: 'ì¸ì›¨ì–´ë²„í„°', 'íŒŒì´ì‹œìŠ¤')")
    
    args = parser.parse_args()
    
    # AI ë¶„ì„ ì¶”ê°€ (GCS ì§€ì›)
    generate_ai_analysis_from_file(
        snapshot_file=args.snapshot_file,
        output_file=args.output,
        api_key=args.api_key,
        target_brand=args.target_brand
    )
