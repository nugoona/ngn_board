# File: services/data_service.py
import os   
import sys
import datetime
import json
import gzip
import io
import re
from flask import Blueprint, request, jsonify, session, Response
from google.cloud import bigquery
from google.cloud import storage
import time
from concurrent.futures import ThreadPoolExecutor
import requests
from urllib.parse import quote, unquote

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€ (company_mapping ëª¨ë“ˆ ì„í¬íŠ¸ìš©)
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
tools_path = os.path.join(project_root, "tools")
if tools_path not in sys.path:
    sys.path.insert(0, tools_path)

# ìì‚¬ëª° ë§¤í•‘ ì„í¬íŠ¸
try:
    from config.company_mapping import get_company_korean_name, get_company_brands, COMPANY_MAPPING
    COMPANY_MAPPING_AVAILABLE = True
except (ImportError, ModuleNotFoundError) as e:
    print(f"[WARN] company_mapping ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")
    COMPANY_MAPPING_AVAILABLE = False
    def get_company_korean_name(name): return None
    def get_company_brands(name): return []
    COMPANY_MAPPING = {}

# ìºì‹œ ìœ í‹¸ë¦¬í‹° ì„í¬íŠ¸
from ..utils.cache_utils import get_cache_stats, invalidate_cache_by_pattern

# ğŸ“¦ ì„œë¹„ìŠ¤ í•¨ìˆ˜ ì„í¬íŠ¸ (ê¸°ëŠ¥ë³„ ì •ë¦¬)
from ..services.cafe24_service import (
    get_cafe24_sales_data,
    get_cafe24_product_sales,
)
from ..services.catalog_sidebar_service import create_or_update_product_set
from ..services.ga4_source_summary import get_ga4_source_summary
from ..services.meta_ads_insight import get_meta_account_list_filtered
from ..services.meta_ads_service import get_meta_ads_data
from ..services.performance_summary_new import get_performance_summary_new
from ..services.platform_sales_summary import get_monthly_platform_sales
from ..services.Fetch_Adset_Summary import get_meta_ads_adset_summary_by_type
from ..services.viewitem_summary import get_viewitem_summary
from ..services.monthly_net_sales_visitors import get_monthly_net_sales_visitors
from ..services.trend_29cm_service import (
    get_rising_star,
    get_new_entry,
    get_rank_drop,
    get_current_week_info,
    get_available_tabs,
    load_trend_snapshot_from_gcs,
    save_trend_snapshot_to_gcs,
    get_all_tabs_data_from_bigquery
)
from ..services.trend_ably_service import (
    get_rising_star as get_ably_rising_star,
    get_new_entry as get_ably_new_entry,
    get_rank_drop as get_ably_rank_drop,
    get_current_week_info as get_ably_current_week_info,
    get_available_tabs as get_ably_available_tabs,
    load_trend_snapshot_from_gcs as load_ably_trend_snapshot_from_gcs,
    save_trend_snapshot_to_gcs as save_ably_trend_snapshot_to_gcs,
    get_all_tabs_data_from_bigquery as get_ably_all_tabs_data_from_bq
)
from ..services.compare_29cm_service import (
    get_competitor_keywords,
    fetch_product_reviews,
    load_search_results_from_bq,
)



data_blueprint = Blueprint("data", __name__, url_prefix="/dashboard")


def filter_ai_report_by_company(analysis_report: str, company_name: str) -> str:
    """
    AI ë¦¬í¬íŠ¸ì—ì„œ í˜„ì¬ ì—…ì²´ì— ë§ê²Œ Section 1ì˜ ìì‚¬ëª° ë¸Œëœë“œëª…ì„ ë™ì ìœ¼ë¡œ ë³€ê²½
    
    Args:
        analysis_report: ì›ë³¸ AI ë¦¬í¬íŠ¸ (ë§ˆí¬ë‹¤ìš´ í˜•ì‹)
        company_name: í˜„ì¬ ë¡œê·¸ì¸í•œ ì—…ì²´ëª… (ì˜ˆ: "piscess")
    
    Returns:
        í•„í„°ë§ëœ AI ë¦¬í¬íŠ¸ (Section 1ì˜ ìì‚¬ëª° ë¸Œëœë“œëª…ì´ í˜„ì¬ ì—…ì²´ì— ë§ê²Œ ë³€ê²½ë¨)
    """
    if not analysis_report or not company_name or not COMPANY_MAPPING_AVAILABLE:
        return analysis_report
    
    company_ko = get_company_korean_name(company_name)
    if not company_ko:
        # ë§¤í•‘ë˜ì§€ ì•Šì€ ì—…ì²´ì¸ ê²½ìš°, Section 1ì—ì„œ ìì‚¬ëª° ì„¹ì…˜ ì œê±° ë˜ëŠ” ê¸°ë³¸ ë©”ì‹œì§€ë¡œ ë³€ê²½
        # Section 1ì˜ ìì‚¬ëª° ë¶€ë¶„ì„ "ìì‚¬ëª° ìƒí’ˆì´ í¬í•¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"ë¡œ ë³€ê²½
        section1_pattern = r'##\s*Section\s*1[^#]*?(?=##|$)'
        section1_match = re.search(section1_pattern, analysis_report, flags=re.IGNORECASE | re.DOTALL)
        if section1_match:
            section1_text = section1_match.group(0)
            # ìì‚¬ëª° ê´€ë ¨ ë‚´ìš©ì„ ì œê±°í•˜ê³  ê¸°ë³¸ ë©”ì‹œì§€ë¡œ êµì²´
            updated_section1 = re.sub(
                r'ìì‚¬ëª°\([^)]+\)[^#]*',
                'ìì‚¬ëª° ì„±ê³¼ ë¶„ì„\n\nê¸ˆì£¼ ë­í‚¹ ë°ì´í„°ì— ìì‚¬ëª° ìƒí’ˆì´ í¬í•¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.',
                section1_text,
                flags=re.DOTALL
            )
            analysis_report = analysis_report.replace(section1_text, updated_section1)
        return analysis_report.strip()
    
    # Section 1ì˜ ìì‚¬ëª° ë¸Œëœë“œëª…ì„ í˜„ì¬ ì—…ì²´ì˜ í•œê¸€ëª…ìœ¼ë¡œ ë³€ê²½
    # íŒ¨í„´: "## Section 1. ìì‚¬ëª°({ë¸Œëœë“œëª…}) ì„±ê³¼ ë¶„ì„"
    section1_pattern = r'(##\s*Section\s*1[^#]*?(?=##|$))'
    section1_match = re.search(section1_pattern, analysis_report, flags=re.IGNORECASE | re.DOTALL)
    
    if section1_match:
        section1_text = section1_match.group(1)
        
        # ê¸°ì¡´ ë¸Œëœë“œëª… íŒ¨í„´ ì°¾ê¸° ë° êµì²´
        # íŒ¨í„´ 1: "ìì‚¬ëª°({ë¸Œëœë“œëª…})" ë˜ëŠ” "ìì‚¬ëª° ({ë¸Œëœë“œëª…})"
        updated_section1 = re.sub(
            r'ìì‚¬ëª°\s*\([^)]+\)',
            f'ìì‚¬ëª°({company_ko})',
            section1_text,
            flags=re.IGNORECASE
        )
        
        # íŒ¨í„´ 2: Section 1 í…ìŠ¤íŠ¸ ë‚´ì˜ ëª¨ë“  ë¸Œëœë“œëª… ì¸ìŠ¤í„´ìŠ¤ êµì²´
        # ì¼ë°˜ì ì¸ ë¸Œëœë“œëª… íŒ¨í„´ êµì²´ (ë”°ì˜´í‘œ ì•ˆì˜ ë¸Œëœë“œëª… í¬í•¨)
        brand_patterns = [
            r"'ì¸ì›¨ì–´ë²„í„°'",
            r'"ì¸ì›¨ì–´ë²„í„°"',
            r'ì¸ì›¨ì–´ë²„í„°',
            r"'íŒŒì´ì‹œìŠ¤'",
            r'"íŒŒì´ì‹œìŠ¤"',
            r'íŒŒì´ì‹œìŠ¤',
            r"'Somewhere Butter'",
            r'"Somewhere Butter"',
            r'Somewhere Butter',
            r"'somewhere butter'",
            r"'PISCESS'",
            r'"PISCESS"',
            r'PISCESS',
            r"'piscess'",
        ]
        
        for pattern in brand_patterns:
            updated_section1 = re.sub(
                pattern,
                company_ko,
                updated_section1,
                flags=re.IGNORECASE
            )
        
        # íŒ¨í„´ 3: "{target_brand}" ë˜ëŠ” ë‹¤ë¥¸ ë³€ìˆ˜ëª… êµì²´
        updated_section1 = re.sub(
            r"\{target_brand\}|\{TARGET_BRAND\}|\{brand\}|\{BRAND\}",
            company_ko,
            updated_section1,
            flags=re.IGNORECASE
        )
        
        analysis_report = analysis_report.replace(section1_text, updated_section1)
    
    return analysis_report.strip()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ“Œ ìºì‹œ ê´€ë¦¬ ì—”ë“œí¬ì¸íŠ¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@data_blueprint.route("/cache/stats", methods=["GET"])
def cache_stats():
    """ìºì‹œ ìƒíƒœ ì •ë³´ ì¡°íšŒ"""
    try:
        stats = get_cache_stats()
        return jsonify({"status": "success", "cache_stats": stats}), 200
    except Exception as e:
        return jsonify({"status": "error", "message": str(e)}), 500

@data_blueprint.route("/cache/invalidate", methods=["POST"])
def cache_invalidate():
    """ìºì‹œ ë¬´íš¨í™” (íŒ¨í„´ ê¸°ë°˜)"""
    try:
        data = request.get_json() or {}
        pattern = data.get("pattern", "")
        
        if not pattern:
            return jsonify({"status": "error", "message": "pattern íŒŒë¼ë¯¸í„° í•„ìš”"}), 400
        
        deleted_count = invalidate_cache_by_pattern(pattern)
        return jsonify({
            "status": "success", 
            "message": f"{pattern} íŒ¨í„´ìœ¼ë¡œ {deleted_count}ê°œ ìºì‹œ ì‚­ì œë¨"
        }), 200
    except Exception as e:
        return jsonify({"status": "error", "message": str(e)}), 500

@data_blueprint.route("/cache/invalidate/ga4_source", methods=["POST"])
def cache_invalidate_ga4_source():
    """GA4 ì†ŒìŠ¤ ìš”ì•½ ìºì‹œ ë¬´íš¨í™” ì—”ë“œí¬ì¸íŠ¸"""
    try:
        from ..utils.cache_utils import invalidate_cache_by_pattern
        deleted_count = invalidate_cache_by_pattern("ga4_source_summary")
        
        return jsonify({
            "status": "success",
            "message": f"GA4 ì†ŒìŠ¤ ìš”ì•½ ìºì‹œ ë¬´íš¨í™” ì™„ë£Œ: {deleted_count}ê°œ í‚¤ ì‚­ì œ",
            "deleted_count": deleted_count
        })
    except Exception as e:
        return jsonify({
            "status": "error",
            "message": f"GA4 ì†ŒìŠ¤ ìš”ì•½ ìºì‹œ ë¬´íš¨í™” ì‹¤íŒ¨: {str(e)}"
        }), 500

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def get_start_end_dates(period, start_date=None, end_date=None):
    """ âœ… í•„í„°ë§ ê¸°ê°„ì„ ê²°ì •í•˜ëŠ” í•¨ìˆ˜ (KST ê¸°ì¤€ ì ìš©) """
    now_utc = datetime.datetime.utcnow()
    now_kst = now_utc + datetime.timedelta(hours=9)

    date_map = {
        "today": (now_kst.strftime("%Y-%m-%d"), now_kst.strftime("%Y-%m-%d")),
        "yesterday": (
            (now_kst - datetime.timedelta(days=1)).strftime("%Y-%m-%d"),
            (now_kst - datetime.timedelta(days=1)).strftime("%Y-%m-%d")
        ),
        "last7days": (
            (now_kst - datetime.timedelta(days=7)).strftime("%Y-%m-%d"),
            (now_kst - datetime.timedelta(days=1)).strftime("%Y-%m-%d")
        ),
        "current_month": (
            now_kst.replace(day=1).strftime("%Y-%m-%d"),
            now_kst.strftime("%Y-%m-%d")
        ),
        "last_month": (
            (now_kst.replace(day=1) - datetime.timedelta(days=1)).replace(day=1).strftime("%Y-%m-%d"),
            (now_kst.replace(day=1) - datetime.timedelta(days=1)).strftime("%Y-%m-%d")
        )
    }

    if start_date == "":
        start_date = None
    if end_date == "":
        end_date = None

    if period in date_map:
        start_date, end_date = date_map[period]

    # ğŸ”¥ 'ì§ì ‘ ì„ íƒ' ëª¨ë“œì—ì„œëŠ” ë‚ ì§œê°€ ë¹„ì–´ìˆìœ¼ë©´ ì˜¤ë¥˜ ë°œìƒ
    if period == "manual":
        if not start_date or not end_date:
            raise ValueError("ì§ì ‘ ì„ íƒ ëª¨ë“œì—ì„œëŠ” ì‹œì‘ì¼ê³¼ ì¢…ë£Œì¼ì´ ëª¨ë‘ í•„ìš”í•©ë‹ˆë‹¤.")
    
    # ğŸ”¥ ë¯¸ë¦¬ ì •ì˜ëœ ê¸°ê°„ì˜ ê²½ìš°ì—ë§Œ ê¸°ë³¸ê°’ ì„¤ì •
    if not start_date:
        start_date = now_kst.strftime("%Y-%m-%d")
    if not end_date:
        end_date = now_kst.strftime("%Y-%m-%d")

    print(f"[DEBUG] ë³€í™˜ëœ ë‚ ì§œ ê°’ - start_date: {start_date}, end_date: {end_date}")
    return start_date, end_date

@data_blueprint.route("/get_data", methods=["POST"])
def get_dashboard_data_route():
    t0 = time.time()
    try:
        data = request.get_json()
        user_id = session.get("user_id")
        raw_company_name = data.get("company_name", "all")

        # âœ… company_name ì²˜ë¦¬
        if raw_company_name == "all":
            company_name = ["demo"] if user_id == "demo" else [
                name for name in session.get("company_names", []) if name.lower() != "demo"
            ]
        elif isinstance(raw_company_name, list):
            company_name = ["demo"] if user_id == "demo" else [
                name.lower() for name in raw_company_name if name.lower() != "demo"
            ]
        else:
            name = str(raw_company_name).strip().lower()
            if name == "demo" and user_id != "demo":
                return jsonify({
                    "status": "success",
                    "message": "demo ì—…ì²´ ì ‘ê·¼ ë¶ˆê°€",
                    "cafe24_sales": [],
                    "cafe24_sales_total_count": 0
                }), 200
            company_name = name

        # âœ… ê³µí†µ íŒŒë¼ë¯¸í„° ì²˜ë¦¬
        period = str(data.get("period", "today")).strip()
        start_date = data.get("start_date")
        end_date = data.get("end_date")
        data_type = (data.get("data_type", "all") or "").strip().lower()
        data_type = data_type.replace("-", "_")  # kebab-case -> snake_case
        data_type = data_type.replace(" ", "_")  # spaces -> underscores
        date_type = str(data.get("date_type", "summary")).strip()
        date_sort = str(data.get("date_sort", "desc")).strip()
        sort_by = str(data.get("sort_by", "item_product_sales")).strip()

        # ì•ˆì „í•œ int ë³€í™˜
        try:
            page = int(data.get("page", 1)) if isinstance(data.get("page"), (int, str)) else 1
        except (ValueError, TypeError):
            page = 1
            
        try:
            limit = int(data.get("limit", 15)) if isinstance(data.get("limit"), (int, str)) else 15
        except (ValueError, TypeError):
            limit = 15
        offset = (page - 1) * limit

        # âœ… ê¸°ê°„ í•„í„° í•„ìš” ì—†ëŠ” í…Œì´ë¸” ì˜ˆì™¸ ì²˜ë¦¬
        if data_type not in ["monthly_net_sales_visitors", "platform_sales_monthly"]:
            # ğŸ”¥ periodê°€ ì—†ìœ¼ë©´ "manual"ë¡œ ì²˜ë¦¬ (ì§ì ‘ ì„ íƒ ëª¨ë“œ)
            if not period:
                period = "manual"
            start_date, end_date = get_start_end_dates(period, start_date, end_date)

        print(f"[DEBUG] ìš”ì²­ í•„í„° - company_name={company_name}, period={period}, "
              f"start_date={start_date}, end_date={end_date}, page={page}, limit={limit}, data_type={data_type}")
        print(f"[DEBUG] date_type={date_type}, date_sort={date_sort}, sort_by={sort_by}")
        print(f"[DEBUG] ì •ê·œí™”ëœ data_type: '{data_type}'")
        print(f"[DEBUG] performance_summary ì¡°ê±´ í™•ì¸: data_type in ['performance_summary', 'all'] = {data_type in ['performance_summary', 'all']}")

        response_data = {"status": "success"}
        timing_log = {}
        fetch_tasks = []
        results_map = {}
        with ThreadPoolExecutor() as executor:
            # Performance Summary
            if data_type in ["performance_summary", "all"]:
                def fetch_performance():
                    t1 = time.time()
                    performance_data = get_performance_summary_new(
                        company_name=company_name,
                        start_date=start_date,
                        end_date=end_date,
                        user_id=user_id
                    )
                    t2 = time.time()
                    timing_log["performance_summary"] = round(t2-t1, 3)
                    
                    # ğŸ”¥ ISO í˜•ì‹ìœ¼ë¡œ ë‚ ì§œ ë³€í™˜ (JavaScriptì—ì„œ íŒŒì‹± ê°€ëŠ¥)
                    latest_update = None
                    if performance_data:
                        for row in performance_data:
                            if row.get("updated_at"):
                                # datetime ê°ì²´ë¥¼ ISO í˜•ì‹ ë¬¸ìì—´ë¡œ ë³€í™˜
                                if hasattr(row["updated_at"], 'isoformat'):
                                    latest_update = row["updated_at"].isoformat()
                                else:
                                    latest_update = str(row["updated_at"])
                                break
                    
                    return ("performance_summary", performance_data[offset:offset + limit], len(performance_data), latest_update)
                fetch_tasks.append(executor.submit(fetch_performance))
            
            # Cafe24 Sales
            if data_type in ["cafe24_sales", "all"]:
                def fetch_cafe24_sales():
                    t1 = time.time()
                    result = get_cafe24_sales_data(
                        company_name, period, start_date, end_date,
                        date_type, date_sort, limit, page, user_id
                    )
                    t2 = time.time()
                    timing_log["cafe24_sales"] = round(t2-t1, 3)
                    return ("cafe24_sales", result["rows"], result["total_count"])
                fetch_tasks.append(executor.submit(fetch_cafe24_sales))
            
            # Cafe24 Product Sales
            if data_type in ["cafe24_product_sales", "all"]:
                def fetch_cafe24_product_sales():
                    t1 = time.time()
                    result = get_cafe24_product_sales(
                        company_name, period, start_date, end_date,
                        sort_by=sort_by, limit=limit, page=page, user_id=user_id
                    )
                    t2 = time.time()
                    timing_log["cafe24_product_sales"] = round(t2-t1, 3)
                    return ("cafe24_product_sales", result["rows"], result["total_count"])
                fetch_tasks.append(executor.submit(fetch_cafe24_product_sales))
            
            # ViewItem Summary
            if data_type in ["viewitem_summary", "all"]:
                def fetch_viewitem_summary():
                    t1 = time.time()
                    data_rows = get_viewitem_summary(company_name, start_date, end_date, limit=500)
                    t2 = time.time()
                    timing_log["viewitem_summary"] = round(t2-t1, 3)
                    return ("viewitem_summary", data_rows, len(data_rows))
                fetch_tasks.append(executor.submit(fetch_viewitem_summary))
            
            # GA4 Source Summary
            if data_type in ["ga4_source_summary", "all"]:
                def fetch_ga4_source_summary():
                    t1 = time.time()
                    try:
                        # ìºì‹œ ë¬´íš¨í™” íŒŒë¼ë¯¸í„° ì¶”ì¶œ
                        cache_buster = data.get('_cache_buster')
                        print(f"[DEBUG] GA4 Source Summary í˜¸ì¶œ - company: {company_name}, start: {start_date}, end: {end_date}")
                        print(f"[DEBUG] GA4 Source Summary íŒŒë¼ë¯¸í„° íƒ€ì… - company: {type(company_name)}, start: {type(start_date)}, end: {type(end_date)}")
                        print(f"[DEBUG] GA4 Source Summary ì „ì²´ data: {data}")
                        
                        if not start_date or not end_date:
                            print(f"[ERROR] GA4 Source Summary - start_date ë˜ëŠ” end_dateê°€ ì—†ìŠµë‹ˆë‹¤!")
                            return ("ga4_source_summary", [], 0)
                        
                        data_rows = get_ga4_source_summary(company_name, start_date, end_date, limit=100, _cache_buster=cache_buster)
                        t2 = time.time()
                        timing_log["ga4_source_summary"] = round(t2-t1, 3)
                        return ("ga4_source_summary", data_rows[offset:offset + limit], len(data_rows))
                    except Exception as e:
                        print(f"[ERROR] GA4 Source Summary ì˜¤ë¥˜: {type(e).__name__}: {str(e)}")
                        return ("ga4_source_summary", [], 0)
                fetch_tasks.append(executor.submit(fetch_ga4_source_summary))
            
            # Monthly Net Sales & Visitors Chart
            if data_type == "monthly_net_sales_visitors":
                def fetch_monthly_net_sales_visitors():
                    t1 = time.time()
                    data_rows = get_monthly_net_sales_visitors(company_name)
                    t2 = time.time()
                    timing_log["monthly_net_sales_visitors"] = round(t2-t1, 3)
                    return ("monthly_net_sales_visitors", data_rows, len(data_rows))
                fetch_tasks.append(executor.submit(fetch_monthly_net_sales_visitors))
            
            # Product Sales Ratio
            if data_type == "product_sales_ratio":
                def fetch_product_sales_ratio():
                    t1 = time.time()
                    from ..services.product_sales_ratio import get_product_sales_ratio
                    # â¬‡ï¸ ì„œë¹„ìŠ¤ í•¨ìˆ˜ëŠ” ë¦¬ìŠ¤íŠ¸ íŒŒë¼ë¯¸í„°ë¥¼ ê¸°ëŒ€í•˜ë¯€ë¡œ ë¬¸ìì—´ì´ë©´ ë¦¬ìŠ¤íŠ¸ë¡œ ë˜í•‘
                    _company_names = company_name if isinstance(company_name, list) else [company_name]
                    data_rows = get_product_sales_ratio(_company_names, start_date, end_date, limit=50, user_id=user_id)
                    t2 = time.time()
                    timing_log["product_sales_ratio"] = round(t2-t1, 3)
                    return ("product_sales_ratio", data_rows)
                fetch_tasks.append(executor.submit(fetch_product_sales_ratio))
            
            # Platform Sales Summary
            if data_type == "platform_sales_summary":
                def fetch_platform_sales_summary():
                    t1 = time.time()
                    from ..services.platform_sales_summary import get_platform_sales_by_day
                    # â¬‡ï¸ ì„œë¹„ìŠ¤ í•¨ìˆ˜ëŠ” ë¦¬ìŠ¤íŠ¸ íŒŒë¼ë¯¸í„°ë¥¼ ê¸°ëŒ€í•˜ë¯€ë¡œ ë¬¸ìì—´ì´ë©´ ë¦¬ìŠ¤íŠ¸ë¡œ ë˜í•‘
                    _company_names = company_name if isinstance(company_name, list) else [company_name]

                    data_rows = get_platform_sales_by_day(
                        company_names=_company_names,
                        start_date=start_date,
                        end_date=end_date,
                        date_type=date_type,
                        date_sort=date_sort
                    )
                    t2 = time.time()
                    timing_log["platform_sales_summary"] = round(t2-t1, 3)
                    return ("platform_sales_summary", data_rows, len(data_rows))
                fetch_tasks.append(executor.submit(fetch_platform_sales_summary))
            
            # Platform Sales Ratio (íŒŒì´ì°¨íŠ¸ìš©)
            if data_type == "platform_sales_ratio":
                def fetch_platform_sales_ratio():
                    t1 = time.time()
                    from ..services.platform_sales_summary import get_platform_sales_ratio
                    _company_names = company_name if isinstance(company_name, list) else [company_name]

                    data_rows = get_platform_sales_ratio(
                        company_names=_company_names,
                        start_date=start_date,
                        end_date=end_date
                    )
                    t2 = time.time()
                    timing_log["platform_sales_ratio"] = round(t2-t1, 3)
                    return ("platform_sales_ratio", data_rows)
                fetch_tasks.append(executor.submit(fetch_platform_sales_ratio))
            
            # Platform Sales Monthly
            if data_type == "platform_sales_monthly":
                def fetch_monthly_platform_sales():
                    t1 = time.time()
                    from ..services.platform_sales_summary import get_monthly_platform_sales
                    _company_names = company_name if isinstance(company_name, list) else [company_name]
                    data_rows = get_monthly_platform_sales(_company_names)
                    t2 = time.time()
                    timing_log["platform_sales_monthly"] = round(t2-t1, 3)
                    return ("platform_sales_monthly", data_rows, len(data_rows))
                fetch_tasks.append(executor.submit(fetch_monthly_platform_sales))

        # Collect results
        for future in fetch_tasks:
            result = future.result()
            if result[0] == "performance_summary":
                response_data["performance_summary"] = result[1]
                response_data["performance_summary_total_count"] = result[2]
                response_data["latest_update"] = result[3]
            elif result[0] == "cafe24_sales":
                response_data["cafe24_sales"] = result[1]
                response_data["cafe24_sales_total_count"] = result[2]
            elif result[0] == "cafe24_product_sales":
                response_data["cafe24_product_sales"] = result[1]
                response_data["cafe24_product_sales_total_count"] = result[2]
            elif result[0] == "viewitem_summary":
                response_data["viewitem_summary"] = result[1]
                response_data["viewitem_summary_total_count"] = result[2]
            elif result[0] == "ga4_source_summary":
                response_data["ga4_source_summary"] = result[1]
                response_data["ga4_source_summary_total_count"] = result[2]
            elif result[0] == "monthly_net_sales_visitors":
                response_data["monthly_net_sales_visitors"] = result[1]
                response_data["monthly_net_sales_visitors_total_count"] = result[2]
            elif result[0] == "product_sales_ratio":
                response_data["product_sales_ratio"] = result[1]
            elif result[0] == "platform_sales_summary":
                response_data["platform_sales_summary"] = result[1]
                response_data["platform_sales_summary_total_count"] = result[2]
            elif result[0] == "platform_sales_ratio":
                response_data["platform_sales_ratio"] = result[1]
            elif result[0] == "platform_sales_monthly":
                response_data["platform_sales_monthly"] = result[1]
                response_data["platform_sales_monthly_total_count"] = result[2]

        # Meta ê´‘ê³  ê´€ë ¨ ë°ì´í„° ìš”ì²­ ì²˜ë¦¬
        if data_type == "meta_ads_insight_table":
            t1 = time.time()
            from ..services.meta_ads_insight import get_meta_ads_insight_table

            level = data.get("level", "account")
            account_id = data.get("account_id")
            campaign_id = data.get("campaign_id")
            adset_id = data.get("adset_id")
            date_type = data.get("date_type", "summary")
            # í˜ì´ì§€ë„¤ì´ì…˜ íŒŒë¼ë¯¸í„° (ì›¹ UIì— ì˜í–¥ ì—†ë„ë¡ ê¸°ë³¸ê°’ ìœ ì§€)
            limit = data.get("limit", None)
            page = data.get("page", 1)

            rows = get_meta_ads_insight_table(
                level=level,
                company_name=company_name,
                start_date=start_date,
                end_date=end_date,
                account_id=account_id,
                campaign_id=campaign_id,
                adset_id=adset_id,
                date_type=date_type,
                limit=limit,
                page=page
            )
            t2 = time.time()
            timing_log["meta_ads_insight_table"] = round(t2-t1, 3)
            
            # í˜ì´ì§€ë„¤ì´ì…˜ëœ ê²°ê³¼ ì²˜ë¦¬
            if isinstance(rows, dict) and "rows" in rows:
                # í˜ì´ì§€ë„¤ì´ì…˜ëœ ê²°ê³¼ (ì „ì²´ ê°œìˆ˜ í¬í•¨)
                response_data["meta_ads_insight_table"] = rows["rows"]
                response_data["meta_ads_insight_table_total_count"] = rows["total_count"]
                if rows["rows"]:
                    response_data["updated_at"] = rows["rows"][0].get("updated_at")
            else:
                # ê¸°ì¡´ í˜•ì‹ (í˜ì´ì§€ë„¤ì´ì…˜ ì—†ìŒ)
                response_data["meta_ads_insight_table"] = rows
                if rows:
                    response_data["updated_at"] = rows[0].get("updated_at")

        # Meta Ads ê³„ì • ëª©ë¡ ìš”ì²­ ì²˜ë¦¬
        if data_type == "meta_account_list":
            if user_id == "demo":
                session["company_names"] = ["demo"]

            from ..services.meta_ads_insight import get_meta_account_list_filtered
            rows = get_meta_account_list_filtered(company_name)
            response_data["meta_accounts"] = rows

        # Meta Ads ìº í˜ì¸ ëª©í‘œë³„ ì„±ê³¼ ìš”ì•½
        if data_type == "meta_ads_adset_summary_by_type":
            account_id = data.get("account_id")
            period = data.get("period")
            start_date = data.get("start_date")
            end_date = data.get("end_date")

            type_summary, total_spend_sum = get_meta_ads_adset_summary_by_type(
                account_id=account_id,
                period=period,
                start_date=start_date,
                end_date=end_date
            )

            response_data["data"] = {
                "type_summary": type_summary,
                "total_spend_sum": total_spend_sum
            }

        # Meta Ads ê´‘ê³  ë¯¸ë¦¬ë³´ê¸° - ë‹¨ì¼ (ìºì‹œ ì œê±° ë²„ì „)
        if data_type == "meta_ads_preview_list":
            from ..services.meta_ads_preview import get_meta_ads_preview_list
            import logging
            handler_logger = logging.getLogger(__name__)

            account_id = data.get("account_id")
            
            # âœ… [NO_CACHE] ìºì‹œ ì™„ì „ ì œê±° - í•­ìƒ ì§ì ‘ í˜¸ì¶œ
            handler_logger.warning(f"[META_API][NO_CACHE] live preview - cache bypassed, account_id={account_id}")
            handler_logger.warning(f"[META_API][ENTER] get_meta_ads_preview_list account_id={account_id}")
            
            start_time = time.time()
            ad_list = get_meta_ads_preview_list(account_id)
            processing_time = time.time() - start_time
            
            handler_logger.warning(f"[META_API][RESULT] ê²°ê³¼: {len(ad_list) if ad_list else 0}ê°œ, {processing_time:.2f}ì´ˆ")
            
            response_data["meta_ads_preview_list"] = ad_list
            response_data["cached"] = False
            response_data["processing_time"] = round(processing_time, 2)

        # Meta Ads ê´‘ê³  ë¯¸ë¦¬ë³´ê¸° - ì½œë ‰ì…˜/ìŠ¬ë¼ì´ë“œë“œ
        if data_type == "slide_collection_ads":
            from ..services.meta_ads_slide_collection import get_slide_collection_ads

            account_id = data.get("account_id")
            ad_list = get_slide_collection_ads(account_id)

            response_data["slide_collection_ads"] = ad_list

        # catalog_sidebar
        if data_type == "catalog_sidebar":
            from ..services.catalog_sidebar_service import get_catalog_sidebar_data

            account_id = data.get("account_id")
            if not account_id:
                return jsonify({"status": "error", "message": "account_id ëˆ„ë½"}), 400

            result, error = get_catalog_sidebar_data(account_id)
            if error:
                return jsonify({"status": "error", "message": error}), 404

            response_data["catalog_sidebar"] = result

        # catalog_manual  â”€ ìì‚¬ëª° URL ìˆ˜ì§‘
        if data_type == "catalog_manual":
            from ..services.catalog_sidebar_service import get_manual_product_list

            category_url = data.get("category_url")
            if not category_url:
                return jsonify({"status": "error", "message": "category_url ëˆ„ë½"}), 400

            result, error = get_manual_product_list(category_url)
            if error:
                return jsonify({"status": "error", "message": error}), 404

            response_data["products"] = result

        # catalog_manual_search  â”€ ìˆ˜ë™ ì„¸íŠ¸ í‚¤ì›Œë“œ ê²€ìƒ‰
        if data_type == "catalog_manual_search":
            from ..services.catalog_sidebar_service import search_products_for_manual_set

            account_id = data.get("account_id")
            keyword = (data.get("keyword") or "").strip()
            search_type = data.get("search_type")   # 'product_name' | 'product_no'

            # â”€â”€ íŒŒë¼ë¯¸í„° ê²€ì¦ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            if not account_id:
                return jsonify({"status": "error", "message": "account_id ëˆ„ë½"}), 400
            if not keyword:
                return jsonify({"status": "error", "message": "keyword ëˆ„ë½"}), 400
            if search_type not in ("product_name", "product_no"):
                return jsonify({"status": "error", "message": "search_type ëˆ„ë½ ë˜ëŠ” ì˜ëª»ë¨"}), 400

            # â”€â”€ ì„œë¹„ìŠ¤ í˜¸ì¶œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            result, error = search_products_for_manual_set(
                account_id=account_id,
                keyword=keyword,
                search_type=search_type
            )
            if error:
                return jsonify({"status": "error", "message": error}), 404

            response_data["results"] = result

        t_end = time.time()
        print("[TIMING_LOG] /dashboard/get_data timing:", timing_log, "total:", round(t_end-t0, 3), "s")
        return jsonify(response_data), 200

    except TypeError as te:
        print(f"[ERROR] ìš”ì²­ ë°ì´í„° íƒ€ì… ì˜¤ë¥˜: {te}")
        return jsonify({"status": "error", "message": f"ì˜ëª»ëœ ìš”ì²­ í˜•ì‹: {str(te)}"}), 400

    except Exception as e:
        print(f"[ERROR] ë°ì´í„° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return jsonify({"status": "error", "message": f"ë°ì´í„° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"}), 500


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ“Œ ì¹´íƒˆë¡œê·¸ ìƒí’ˆì„¸íŠ¸ ìƒì„± / ì—…ë°ì´íŠ¸
#     POST  /dashboard/catalog_set
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@data_blueprint.route("/catalog_set", methods=["POST"])
def catalog_set_route():
    try:
        data = request.get_json(silent=True) or {}

        catalog_id   = str(data.get("catalog_id", "")).strip()
        set_name     = str(data.get("set_name", "")).strip()
        retailer_ids = [str(r).strip() for r in data.get("retailer_ids", [])]

        # â”€â”€â”€ â‘  í•„ìˆ˜ íŒŒë¼ë¯¸í„° í™•ì¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if not (catalog_id and set_name and retailer_ids):
            return jsonify({
                "status": "error",
                "message": "catalog_id / set_name / retailer_ids ëˆ„ë½"
            }), 400

        # â”€â”€â”€ â‘¡ ì‹œìŠ¤í…œ-í† í° ì¡´ì¬ ì—¬ë¶€ë§Œ í™•ì¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if not os.getenv("META_SYSTEM_TOKEN"):
            return jsonify({
                "status": "error",
                "message": "META_SYSTEM_TOKEN ì´ í™˜ê²½ë³€ìˆ˜ì— ì—†ìŠµë‹ˆë‹¤."
            }), 500

        # â”€â”€â”€ â‘¢ ì„¸íŠ¸ ìƒì„±/ì—…ë°ì´íŠ¸ í˜¸ì¶œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        result, err = create_or_update_product_set(
            catalog_id   = catalog_id,
            set_name     = set_name,
            retailer_ids = retailer_ids
        )

        if err:
            return jsonify({"status": "error", "message": err}), 500

        return jsonify({"status": "success", **result}), 200

    except Exception as e:
        return jsonify({"status": "error", "message": str(e)}), 500


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ“Œ ì´ë¯¸ì§€ í”„ë¡ì‹œ ì—”ë“œí¬ì¸íŠ¸ (CORS ë¬¸ì œ í•´ê²°)
#     GET  /dashboard/proxy_image?url=<encoded_image_url>
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@data_blueprint.route("/test", methods=["GET"])
def test():
    return "Hello World"


@data_blueprint.route("/monthly_report", methods=["POST"])
def get_monthly_report():
    """ì›”ê°„ ë¦¬í¬íŠ¸ ìŠ¤ëƒ…ìƒ· ë°ì´í„° ì¡°íšŒ (GCS ë²„í‚·ì—ì„œ)"""
    try:
        data = request.get_json()
        company_name = data.get("company_name")
        year = int(data.get("year"))
        month = int(data.get("month"))
        
        if not company_name or company_name == "all":
            return jsonify({"status": "error", "message": "ì—…ì²´ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”"}), 400
        
        # GCS ë²„í‚·ì—ì„œ ìŠ¤ëƒ…ìƒ· íŒŒì¼ ì½ê¸°
        PROJECT_ID = os.environ.get("GOOGLE_CLOUD_PROJECT", "winged-precept-443218-v8")
        GCS_BUCKET = os.environ.get("GCS_BUCKET", "winged-precept-443218-v8.appspot.com")
        
        # ê²½ë¡œ í˜•ì‹: ai-reports/monthly/{company}/{YYYY-MM}/snapshot.json[.gz] (ì‹¤ì œ ì €ì¥ ê²½ë¡œ)
        month_str = f"{year}-{month:02d}"
        
        # ì—¬ëŸ¬ ê²½ë¡œ ì‹œë„ (ì••ì¶• íŒŒì¼ ìš°ì„ , ê·¸ ë‹¤ìŒ ì••ì¶• ì—†ëŠ” íŒŒì¼)
        blob_paths = [
            f"ai-reports/monthly/{company_name}/{month_str}/snapshot.json.gz",  # ì••ì¶• íŒŒì¼ (ì›ë³¸)
            f"ai-reports/monthly/{company_name.lower()}/{month_str}/snapshot.json.gz",  # ì••ì¶• íŒŒì¼ (ì†Œë¬¸ì)
            f"ai-reports/monthly/{company_name}/{month_str}/snapshot.json",  # ì••ì¶• ì—†ëŠ” íŒŒì¼ (ì›ë³¸, í•˜ìœ„ í˜¸í™˜)
            f"ai-reports/monthly/{company_name.lower()}/{month_str}/snapshot.json",  # ì••ì¶• ì—†ëŠ” íŒŒì¼ (ì†Œë¬¸ì)
            f"ai-reports/{company_name}/{month_str}.json",  # ëŒ€ì²´ ê²½ë¡œ (ì›ë³¸)
            f"ai-reports/{company_name.lower()}/{month_str}.json"  # ëŒ€ì²´ ê²½ë¡œ (ì†Œë¬¸ì)
        ]
        
        try:
            client = storage.Client(project=PROJECT_ID)
            bucket = client.bucket(GCS_BUCKET)
            
            # ì—¬ëŸ¬ ê²½ë¡œ ì‹œë„
            blob = None
            found_path = None
            for blob_path in blob_paths:
                test_blob = bucket.blob(blob_path)
                if test_blob.exists():
                    blob = test_blob
                    found_path = blob_path
                    break
            
            if not blob:
                return jsonify({
                    "status": "error",
                    "message": f"{year}ë…„ {month}ì›” ë¦¬í¬íŠ¸ê°€ ì•„ì§ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. (ì‹œë„í•œ ê²½ë¡œ: {', '.join(blob_paths[:2])})"
                }), 404
            
            # í•˜ì´ë¸Œë¦¬ë“œ ì½ê¸° ë¡œì§: Gzip ì••ì¶• ì—¬ë¶€ì™€ ê´€ê³„ì—†ì´ ë°”ì´íŠ¸ë¡œ ë‹¤ìš´ë¡œë“œ í›„ ìë™ íŒë³„
            snapshot_bytes = blob.download_as_bytes()
            
            # Gzip ì••ì¶• í•´ì œ ì‹œë„ (ì„±ê³µí•˜ë©´ ì••ì¶•ëœ íŒŒì¼, ì‹¤íŒ¨í•˜ë©´ ì••ì¶•ë˜ì§€ ì•Šì€ íŒŒì¼)
            try:
                # Python ë²„ì „ í˜¸í™˜ì„±ì„ ìœ„í•´ gzip.GzipFile ì‚¬ìš© (max_length íŒŒë¼ë¯¸í„° ë¬¸ì œ íšŒí”¼)
                with gzip.GzipFile(fileobj=io.BytesIO(snapshot_bytes)) as gz_file:
                    snapshot_json_str = gz_file.read().decode('utf-8')
                print(f"âœ… GCSì—ì„œ ìŠ¤ëƒ…ìƒ·ì„ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤: {found_path} (Gzip ì••ì¶• í•´ì œë¨)", file=sys.stderr)
            except (gzip.BadGzipFile, OSError, Exception) as e:
                # Gzip ì••ì¶• í•´ì œ ì‹¤íŒ¨ â†’ ì••ì¶•ë˜ì§€ ì•Šì€ JSON íŒŒì¼ë¡œ ì²˜ë¦¬ (í•˜ìœ„ í˜¸í™˜)
                snapshot_json_str = snapshot_bytes.decode('utf-8')
                print(f"âœ… GCSì—ì„œ ìŠ¤ëƒ…ìƒ·ì„ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤: {found_path} (ì••ì¶• ì—†ìŒ, í•˜ìœ„ í˜¸í™˜)", file=sys.stderr)
            
            snapshot_data = json.loads(snapshot_json_str)
            
            return jsonify({
                "status": "success",
                "data": snapshot_data
            }), 200
            
        except Exception as e:
            return jsonify({
                "status": "error",
                "message": f"ìŠ¤ëƒ…ìƒ· íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            }), 500
            
    except Exception as e:
        return jsonify({"status": "error", "message": str(e)}), 500

@data_blueprint.route("/monthly_report/check_new", methods=["POST"])
def check_new_monthly_report():
    """GCS íŒŒì¼ ìˆ˜ì • ì‹œê°„ë§Œ í™•ì¸ (íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì•ˆ í•¨, ë¹„ìš© ìµœì†Œí™”)"""
    try:
        data = request.get_json()
        company_name = data.get("company_name")
        year = int(data.get("year"))
        month = int(data.get("month"))
        
        if not company_name or company_name == "all":
            return jsonify({"status": "error", "message": "ì—…ì²´ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”"}), 400
        
        # GCS ë²„í‚·ì—ì„œ ìŠ¤ëƒ…ìƒ· íŒŒì¼ ë©”íƒ€ë°ì´í„°ë§Œ í™•ì¸ (íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì•ˆ í•¨)
        PROJECT_ID = os.environ.get("GOOGLE_CLOUD_PROJECT", "winged-precept-443218-v8")
        GCS_BUCKET = os.environ.get("GCS_BUCKET", "winged-precept-443218-v8.appspot.com")
        
        month_str = f"{year}-{month:02d}"
        
        # ì—¬ëŸ¬ ê²½ë¡œ ì‹œë„
        blob_paths = [
            f"ai-reports/monthly/{company_name}/{month_str}/snapshot.json.gz",
            f"ai-reports/monthly/{company_name.lower()}/{month_str}/snapshot.json.gz",
            f"ai-reports/monthly/{company_name}/{month_str}/snapshot.json",
            f"ai-reports/monthly/{company_name.lower()}/{month_str}/snapshot.json",
        ]
        
        try:
            client = storage.Client(project=PROJECT_ID)
            bucket = client.bucket(GCS_BUCKET)
            
            # ì—¬ëŸ¬ ê²½ë¡œ ì‹œë„ (ë©”íƒ€ë°ì´í„°ë§Œ í™•ì¸, íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì•ˆ í•¨)
            blob = None
            for blob_path in blob_paths:
                test_blob = bucket.blob(blob_path)
                if test_blob.exists():
                    blob = test_blob
                    # ë©”íƒ€ë°ì´í„°ë§Œ ê°€ì ¸ì˜¤ê¸° (íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì•ˆ í•¨)
                    blob.reload()
                    break
            
            if not blob:
                return jsonify({
                    "status": "error",
                    "message": f"{year}ë…„ {month}ì›” ë¦¬í¬íŠ¸ê°€ ì•„ì§ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
                }), 404
            
            # íŒŒì¼ ìˆ˜ì • ì‹œê°„ë§Œ ë°˜í™˜ (ISO í˜•ì‹)
            return jsonify({
                "status": "success",
                "snapshot_updated": blob.updated.isoformat() if blob.updated else None,
                "snapshot_created": blob.time_created.isoformat() if blob.time_created else None
            }), 200
            
        except Exception as e:
            return jsonify({
                "status": "error",
                "message": f"ìŠ¤ëƒ…ìƒ· íŒŒì¼ í™•ì¸ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            }), 500
            
    except Exception as e:
        return jsonify({"status": "error", "message": str(e)}), 500

@data_blueprint.route("/proxy_image", methods=["GET"])
def proxy_image():
    """
    ì™¸ë¶€ ì´ë¯¸ì§€ URLì„ í”„ë¡ì‹œí•˜ì—¬ CORS ë° Mixed Content ë¬¸ì œë¥¼ í•´ê²°í•©ë‹ˆë‹¤.
    Meta APIì—ì„œ ê°€ì ¸ì˜¨ ì´ë¯¸ì§€ URLì„ ì„œë²„ì—ì„œ ê°€ì ¸ì™€ì„œ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    print(f"[PROXY] proxy_image í˜¸ì¶œë¨ - args: {request.args}")
    try:
        # URL íŒŒë¼ë¯¸í„°ì—ì„œ ì´ë¯¸ì§€ URL ê°€ì ¸ì˜¤ê¸°
        image_url = request.args.get("url")
        
        if not image_url:
            return jsonify({"status": "error", "message": "url íŒŒë¼ë¯¸í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤"}), 400
        
        # URL ë””ì½”ë”©
        try:
            image_url = unquote(image_url)
        except Exception:
            pass  # ì´ë¯¸ ë””ì½”ë”©ëœ ê²½ìš° ê·¸ëŒ€ë¡œ ì‚¬ìš©
        
        # ë³´ì•ˆ: í—ˆìš©ëœ ë„ë©”ì¸ë§Œ í”„ë¡ì‹œ (Meta/Facebook ì´ë¯¸ì§€)
        allowed_domains = [
            "fbcdn.net",
            "facebook.com",
            "scontent",
            "cdninstagram.com",
            "instagram.com"
        ]
        
        if not any(domain in image_url.lower() for domain in allowed_domains):
            # ë¡œì»¬ íŒŒì¼ ê²½ë¡œì¸ ê²½ìš° í—ˆìš© (ì˜ˆ: /static/demo_ads/...)
            if not image_url.startswith("/static/"):
                return jsonify({"status": "error", "message": "í—ˆìš©ë˜ì§€ ì•Šì€ ë„ë©”ì¸ì…ë‹ˆë‹¤"}), 403
        
        # ë¡œì»¬ íŒŒì¼ì¸ ê²½ìš° ì§ì ‘ ë°˜í™˜
        if image_url.startswith("/static/"):
            from flask import send_from_directory
            import os
            static_folder = os.path.join(os.path.dirname(__file__), "..", "static")
            file_path = image_url.replace("/static/", "")
            return send_from_directory(static_folder, file_path)
        
        # ì™¸ë¶€ ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸°
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
        }
        
        response = requests.get(image_url, headers=headers, timeout=10, stream=True)
        response.raise_for_status()
        
        # Content-Type í™•ì¸
        content_type = response.headers.get("Content-Type", "image/jpeg")
        
        # ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ìŠ¤íŠ¸ë¦¼ìœ¼ë¡œ ë°˜í™˜
        def generate():
            for chunk in response.iter_content(chunk_size=8192):
                if chunk:
                    yield chunk
        
        return Response(
            generate(),
            mimetype=content_type,
            headers={
                "Cache-Control": "public, max-age=3600",  # 1ì‹œê°„ ìºì‹œ
                "Access-Control-Allow-Origin": "*",  # CORS í—ˆìš©
            }
        )
        
    except requests.exceptions.RequestException as e:
        print(f"[ERROR] ì´ë¯¸ì§€ í”„ë¡ì‹œ ì‹¤íŒ¨: {image_url}, ì˜¤ë¥˜: {str(e)}")
        return jsonify({"status": "error", "message": f"ì´ë¯¸ì§€ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}"}), 500
    except Exception as e:
        print(f"[ERROR] ì´ë¯¸ì§€ í”„ë¡ì‹œ ì˜¤ë¥˜: {str(e)}")
        return jsonify({"status": "error", "message": f"í”„ë¡ì‹œ ì˜¤ë¥˜: {str(e)}"}), 500


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ“Œ Batch Dashboard Data API (Single Request)
#     POST  /dashboard/get_batch_dashboard_data
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@data_blueprint.route("/get_batch_dashboard_data", methods=["POST"])
def get_batch_dashboard_data_route():
    """
    ëŒ€ì‹œë³´ë“œ ì´ˆê¸° ë¡œë”©ì„ ìœ„í•œ í†µí•© API
    ëª¨ë“  ìœ„ì ¯ ë°ì´í„°ë¥¼ í•œ ë²ˆì˜ ìš”ì²­ìœ¼ë¡œ ë³‘ë ¬ ì²˜ë¦¬í•˜ì—¬ ë°˜í™˜
    """
    t0 = time.time()
    try:
        data = request.get_json()
        user_id = session.get("user_id")
        raw_company_name = data.get("company_name", "all")

        # âœ… company_name ì²˜ë¦¬ (ê¸°ì¡´ ë¡œì§ê³¼ ë™ì¼)
        if raw_company_name == "all":
            company_name = ["demo"] if user_id == "demo" else [
                name for name in session.get("company_names", []) if name.lower() != "demo"
            ]
        elif isinstance(raw_company_name, list):
            company_name = ["demo"] if user_id == "demo" else [
                name.lower() for name in raw_company_name if name.lower() != "demo"
            ]
        else:
            name = str(raw_company_name).strip().lower()
            if name == "demo" and user_id != "demo":
                return jsonify({
                    "status": "success",
                    "message": "demo ì—…ì²´ ì ‘ê·¼ ë¶ˆê°€",
                    "performance_summary": [],
                    "cafe24_sales": [],
                    "cafe24_product_sales": [],
                    "ga4_source_summary": [],
                    "viewitem_summary": [],
                    "monthly_net_sales_visitors": [],
                    "platform_sales_summary": [],
                    "platform_sales_ratio": [],
                    "product_sales_ratio": []
                }), 200
            company_name = name

        # âœ… ê³µí†µ íŒŒë¼ë¯¸í„° ì²˜ë¦¬
        period = str(data.get("period", "today")).strip()
        start_date = data.get("start_date")
        end_date = data.get("end_date")
        
        # âœ… ì¶”ê°€ íŒŒë¼ë¯¸í„° (ê¸°ë³¸ê°’ ì ìš©)
        date_type = str(data.get("date_type", "summary")).strip()
        date_sort = str(data.get("date_sort", "desc")).strip()
        sort_by = str(data.get("sort_by", "sales")).strip()
        platform_date_type = str(data.get("platform_date_type", "summary")).strip()
        platform_date_sort = str(data.get("platform_date_sort", "desc")).strip()

        # âœ… ê¸°ê°„ í•„í„° ì²˜ë¦¬
        if period and period not in ["monthly_net_sales_visitors", "platform_sales_monthly"]:
            if not period:
                period = "manual"
            try:
                start_date, end_date = get_start_end_dates(period, start_date, end_date)
            except ValueError as ve:
                return jsonify({"status": "error", "message": str(ve)}), 400

        print(f"[BATCH_API] ìš”ì²­ - company_name={company_name}, period={period}, "
              f"start_date={start_date}, end_date={end_date}")

        # âœ… ì‘ë‹µ ë°ì´í„° ì´ˆê¸°í™”
        response_data = {
            "status": "success",
            "performance_summary": [],
            "performance_summary_total_count": 0,
            "latest_update": None,
            "cafe24_sales": [],
            "cafe24_sales_total_count": 0,
            "cafe24_product_sales": [],
            "cafe24_product_sales_total_count": 0,
            "ga4_source_summary": [],
            "ga4_source_summary_total_count": 0,
            "viewitem_summary": [],
            "viewitem_summary_total_count": 0,
            "monthly_net_sales_visitors": [],
            "monthly_net_sales_visitors_total_count": 0,
            "platform_sales_summary": [],
            "platform_sales_summary_total_count": 0,
            "platform_sales_ratio": [],
            "product_sales_ratio": []
        }
        
        timing_log = {}
        fetch_tasks = []

        # âœ… ThreadPoolExecutorë¡œ ë³‘ë ¬ ì²˜ë¦¬
        with ThreadPoolExecutor() as executor:
            # 1. Performance Summary
            def fetch_performance():
                try:
                    t1 = time.time()
                    performance_data = get_performance_summary_new(
                        company_name=company_name,
                        start_date=start_date,
                        end_date=end_date,
                        user_id=user_id
                    )
                    t2 = time.time()
                    timing_log["performance_summary"] = round(t2-t1, 3)
                    
                    latest_update = None
                    if performance_data:
                        for row in performance_data:
                            if row.get("updated_at"):
                                if hasattr(row["updated_at"], 'isoformat'):
                                    latest_update = row["updated_at"].isoformat()
                                else:
                                    latest_update = str(row["updated_at"])
                                break
                    
                    return ("performance_summary", performance_data[:100], len(performance_data), latest_update)
                except Exception as e:
                    print(f"[ERROR] Performance Summary ì˜¤ë¥˜: {type(e).__name__}: {str(e)}")
                    return ("performance_summary", [], 0, None)
            
            fetch_tasks.append(executor.submit(fetch_performance))
            
            # 2. Cafe24 Sales
            def fetch_cafe24_sales():
                try:
                    t1 = time.time()
                    result = get_cafe24_sales_data(
                        company_name, period, start_date, end_date,
                        date_type, date_sort, limit=30, page=1, user_id=user_id
                    )
                    t2 = time.time()
                    timing_log["cafe24_sales"] = round(t2-t1, 3)
                    return ("cafe24_sales", result.get("rows", []), result.get("total_count", 0))
                except Exception as e:
                    print(f"[ERROR] Cafe24 Sales ì˜¤ë¥˜: {type(e).__name__}: {str(e)}")
                    return ("cafe24_sales", [], 0)
            
            fetch_tasks.append(executor.submit(fetch_cafe24_sales))
            
            # 3. Cafe24 Product Sales
            def fetch_cafe24_product_sales():
                try:
                    t1 = time.time()
                    result = get_cafe24_product_sales(
                        company_name, period, start_date, end_date,
                        sort_by=sort_by, limit=13, page=1, user_id=user_id
                    )
                    t2 = time.time()
                    timing_log["cafe24_product_sales"] = round(t2-t1, 3)
                    return ("cafe24_product_sales", result.get("rows", []), result.get("total_count", 0))
                except Exception as e:
                    print(f"[ERROR] Cafe24 Product Sales ì˜¤ë¥˜: {type(e).__name__}: {str(e)}")
                    return ("cafe24_product_sales", [], 0)
            
            fetch_tasks.append(executor.submit(fetch_cafe24_product_sales))
            
            # 4. GA4 Source Summary
            def fetch_ga4_source_summary():
                try:
                    t1 = time.time()
                    if not start_date or not end_date:
                        print(f"[ERROR] GA4 Source Summary - start_date ë˜ëŠ” end_dateê°€ ì—†ìŠµë‹ˆë‹¤!")
                        return ("ga4_source_summary", [], 0)
                    
                    cache_buster = data.get('_cache_buster')
                    data_rows = get_ga4_source_summary(company_name, start_date, end_date, limit=100, _cache_buster=cache_buster)
                    t2 = time.time()
                    timing_log["ga4_source_summary"] = round(t2-t1, 3)
                    return ("ga4_source_summary", data_rows[:100], len(data_rows))
                except Exception as e:
                    print(f"[ERROR] GA4 Source Summary ì˜¤ë¥˜: {type(e).__name__}: {str(e)}")
                    return ("ga4_source_summary", [], 0)
            
            fetch_tasks.append(executor.submit(fetch_ga4_source_summary))
            
            # 5. ViewItem Summary
            def fetch_viewitem_summary():
                try:
                    t1 = time.time()
                    if not start_date or not end_date:
                        print(f"[ERROR] ViewItem Summary - start_date ë˜ëŠ” end_dateê°€ ì—†ìŠµë‹ˆë‹¤!")
                        return ("viewitem_summary", [], 0)
                    
                    data_rows = get_viewitem_summary(company_name, start_date, end_date, limit=500)
                    t2 = time.time()
                    timing_log["viewitem_summary"] = round(t2-t1, 3)
                    return ("viewitem_summary", data_rows, len(data_rows))
                except Exception as e:
                    print(f"[ERROR] ViewItem Summary ì˜¤ë¥˜: {type(e).__name__}: {str(e)}")
                    return ("viewitem_summary", [], 0)
            
            fetch_tasks.append(executor.submit(fetch_viewitem_summary))
            
            # 6. Monthly Net Sales & Visitors
            def fetch_monthly_net_sales_visitors():
                try:
                    t1 = time.time()
                    data_rows = get_monthly_net_sales_visitors(company_name)
                    t2 = time.time()
                    timing_log["monthly_net_sales_visitors"] = round(t2-t1, 3)
                    return ("monthly_net_sales_visitors", data_rows, len(data_rows))
                except Exception as e:
                    print(f"[ERROR] Monthly Net Sales Visitors ì˜¤ë¥˜: {type(e).__name__}: {str(e)}")
                    return ("monthly_net_sales_visitors", [], 0)
            
            fetch_tasks.append(executor.submit(fetch_monthly_net_sales_visitors))
            
            # 7. Platform Sales Summary
            def fetch_platform_sales_summary():
                try:
                    t1 = time.time()
                    from ..services.platform_sales_summary import get_platform_sales_by_day
                    _company_names = company_name if isinstance(company_name, list) else [company_name]
                    
                    if not start_date or not end_date:
                        print(f"[ERROR] Platform Sales Summary - start_date ë˜ëŠ” end_dateê°€ ì—†ìŠµë‹ˆë‹¤!")
                        return ("platform_sales_summary", [], 0)
                    
                    data_rows = get_platform_sales_by_day(
                        company_names=_company_names,
                        start_date=start_date,
                        end_date=end_date,
                        date_type=platform_date_type,
                        date_sort=platform_date_sort
                    )
                    t2 = time.time()
                    timing_log["platform_sales_summary"] = round(t2-t1, 3)
                    return ("platform_sales_summary", data_rows, len(data_rows))
                except Exception as e:
                    print(f"[ERROR] Platform Sales Summary ì˜¤ë¥˜: {type(e).__name__}: {str(e)}")
                    return ("platform_sales_summary", [], 0)
            
            fetch_tasks.append(executor.submit(fetch_platform_sales_summary))
            
            # 8. Platform Sales Ratio
            def fetch_platform_sales_ratio():
                try:
                    t1 = time.time()
                    from ..services.platform_sales_summary import get_platform_sales_ratio
                    _company_names = company_name if isinstance(company_name, list) else [company_name]
                    
                    if not start_date or not end_date:
                        print(f"[ERROR] Platform Sales Ratio - start_date ë˜ëŠ” end_dateê°€ ì—†ìŠµë‹ˆë‹¤!")
                        return ("platform_sales_ratio", [])
                    
                    data_rows = get_platform_sales_ratio(
                        company_names=_company_names,
                        start_date=start_date,
                        end_date=end_date
                    )
                    t2 = time.time()
                    timing_log["platform_sales_ratio"] = round(t2-t1, 3)
                    return ("platform_sales_ratio", data_rows)
                except Exception as e:
                    print(f"[ERROR] Platform Sales Ratio ì˜¤ë¥˜: {type(e).__name__}: {str(e)}")
                    return ("platform_sales_ratio", [])
            
            fetch_tasks.append(executor.submit(fetch_platform_sales_ratio))
            
            # 9. Product Sales Ratio
            def fetch_product_sales_ratio():
                try:
                    t1 = time.time()
                    from ..services.product_sales_ratio import get_product_sales_ratio
                    _company_names = company_name if isinstance(company_name, list) else [company_name]
                    
                    if not start_date or not end_date:
                        print(f"[ERROR] Product Sales Ratio - start_date ë˜ëŠ” end_dateê°€ ì—†ìŠµë‹ˆë‹¤!")
                        return ("product_sales_ratio", [])
                    
                    data_rows = get_product_sales_ratio(
                        _company_names, start_date, end_date, limit=50, user_id=user_id
                    )
                    t2 = time.time()
                    timing_log["product_sales_ratio"] = round(t2-t1, 3)
                    return ("product_sales_ratio", data_rows)
                except Exception as e:
                    print(f"[ERROR] Product Sales Ratio ì˜¤ë¥˜: {type(e).__name__}: {str(e)}")
                    return ("product_sales_ratio", [])
            
            fetch_tasks.append(executor.submit(fetch_product_sales_ratio))

        # âœ… ê²°ê³¼ ìˆ˜ì§‘
        for future in fetch_tasks:
            try:
                result = future.result()
                if result[0] == "performance_summary":
                    response_data["performance_summary"] = result[1]
                    response_data["performance_summary_total_count"] = result[2]
                    response_data["latest_update"] = result[3]
                elif result[0] == "cafe24_sales":
                    response_data["cafe24_sales"] = result[1]
                    response_data["cafe24_sales_total_count"] = result[2]
                elif result[0] == "cafe24_product_sales":
                    response_data["cafe24_product_sales"] = result[1]
                    response_data["cafe24_product_sales_total_count"] = result[2]
                elif result[0] == "ga4_source_summary":
                    response_data["ga4_source_summary"] = result[1]
                    response_data["ga4_source_summary_total_count"] = result[2]
                elif result[0] == "viewitem_summary":
                    response_data["viewitem_summary"] = result[1]
                    response_data["viewitem_summary_total_count"] = result[2]
                elif result[0] == "monthly_net_sales_visitors":
                    response_data["monthly_net_sales_visitors"] = result[1]
                    response_data["monthly_net_sales_visitors_total_count"] = result[2]
                elif result[0] == "platform_sales_summary":
                    response_data["platform_sales_summary"] = result[1]
                    response_data["platform_sales_summary_total_count"] = result[2]
                elif result[0] == "platform_sales_ratio":
                    response_data["platform_sales_ratio"] = result[1]
                elif result[0] == "product_sales_ratio":
                    response_data["product_sales_ratio"] = result[1]
            except Exception as e:
                print(f"[ERROR] Future ê²°ê³¼ ì²˜ë¦¬ ì˜¤ë¥˜: {type(e).__name__}: {str(e)}")
                # ê°œë³„ ì‹¤íŒ¨ëŠ” ë¬´ì‹œí•˜ê³  ê³„ì† ì§„í–‰

        t_end = time.time()
        print("[BATCH_API] /dashboard/get_batch_dashboard_data timing:", timing_log, "total:", round(t_end-t0, 3), "s")
        return jsonify(response_data), 200

    except TypeError as te:
        print(f"[ERROR] Batch API ìš”ì²­ ë°ì´í„° íƒ€ì… ì˜¤ë¥˜: {te}")
        return jsonify({"status": "error", "message": f"ì˜ëª»ëœ ìš”ì²­ í˜•ì‹: {str(te)}"}), 400

    except Exception as e:
        print(f"[ERROR] Batch API ë°ì´í„° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return jsonify({"status": "error", "message": f"ë°ì´í„° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"}), 500


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ“Œ 29CM íŠ¸ë Œë“œ API
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@data_blueprint.route("/trend", methods=["POST"])
def get_trend_data():
    """29CM íŠ¸ë Œë“œ ë°ì´í„° ì¡°íšŒ (ìŠ¤ëƒ…ìƒ· ìš°ì„ , ì—†ìœ¼ë©´ BigQuery ì¡°íšŒ)"""
    try:
        data = request.get_json() or {}
        tab_names = data.get("tab_names")  # ë¦¬ìŠ¤íŠ¸ë¡œ ë°›ì•„ì„œ ì—¬ëŸ¬ íƒ­ í•œ ë²ˆì— ì²˜ë¦¬
        tab_name = data.get("tab_name")  # ë‹¨ì¼ íƒ­ (í•˜ìœ„ í˜¸í™˜)
        trend_type = data.get("trend_type", "all")  # "rising", "new_entry", "rank_drop", "all"
        company_name = data.get("company_name")  # í˜„ì¬ ë¡œê·¸ì¸í•œ ì—…ì²´ëª… (ìì‚¬ëª° í•„í„°ë§ìš©)
        
        # ì£¼ì°¨ ì •ë³´ ì¡°íšŒ (ìŠ¤ëƒ…ìƒ· ê²½ë¡œ ìƒì„±ì„ ìœ„í•´)
        current_week = get_current_week_info()
        if not current_week:
            return jsonify({"status": "error", "message": "ì£¼ì°¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}), 404
        
        # ìŠ¤ëƒ…ìƒ·ì—ì„œ ë¡œë“œ ì‹œë„ (ìš°ì„ ìˆœìœ„ 1: GCS ë²„í‚·)
        snapshot_data = load_trend_snapshot_from_gcs(current_week)
        
        if snapshot_data:
            # ìŠ¤ëƒ…ìƒ· ë°ì´í„° ì‚¬ìš© (GCS ë²„í‚·ì—ì„œ ë¡œë“œ ì„±ê³µ)
            print(f"[INFO] âœ… GCS ìŠ¤ëƒ…ìƒ·ì—ì„œ íŠ¸ë Œë“œ ë°ì´í„° ë¡œë“œ ì„±ê³µ: {current_week}")
            
            if tab_names and isinstance(tab_names, list):
                # ì—¬ëŸ¬ íƒ­ ì²˜ë¦¬
                # AI ë¦¬í¬íŠ¸ í•„í„°ë§ (í˜„ì¬ ì—…ì²´ì— í•´ë‹¹í•˜ëŠ” ìì‚¬ëª° ì„¹ì…˜ë§Œ í¬í•¨)
                insights = snapshot_data.get("insights", {})
                if company_name and insights.get("analysis_report"):
                    filtered_report = filter_ai_report_by_company(
                        insights["analysis_report"],
                        company_name.lower() if isinstance(company_name, str) else company_name
                    )
                    insights = insights.copy()
                    insights["analysis_report"] = filtered_report
                
                result = {
                    "status": "success",
                    "current_week": snapshot_data.get("current_week", current_week),
                    "tabs_data": {},
                    "insights": insights  # í•„í„°ë§ëœ AI ë¶„ì„ ë¦¬í¬íŠ¸ í¬í•¨
                }
                
                for tab in tab_names:
                    tab_data = snapshot_data.get("tabs_data", {}).get(tab, {})
                    if trend_type == "all":
                        result["tabs_data"][tab] = tab_data
                    else:
                        filtered_data = {}
                        if trend_type == "rising" and "rising_star" in tab_data:
                            filtered_data["rising_star"] = tab_data["rising_star"]
                        if trend_type == "new_entry" and "new_entry" in tab_data:
                            filtered_data["new_entry"] = tab_data["new_entry"]
                        if trend_type == "rank_drop" and "rank_drop" in tab_data:
                            filtered_data["rank_drop"] = tab_data["rank_drop"]
                        result["tabs_data"][tab] = filtered_data
                
                return jsonify(result), 200
            else:
                # ë‹¨ì¼ íƒ­ ì²˜ë¦¬ (í•˜ìœ„ í˜¸í™˜)
                tab_name = tab_name or "ì „ì²´"
                tab_data = snapshot_data.get("tabs_data", {}).get(tab_name, {})
                
                # AI ë¦¬í¬íŠ¸ í•„í„°ë§ (í˜„ì¬ ì—…ì²´ì— í•´ë‹¹í•˜ëŠ” ìì‚¬ëª° ì„¹ì…˜ë§Œ í¬í•¨)
                insights = snapshot_data.get("insights", {})
                if company_name and insights.get("analysis_report"):
                    filtered_report = filter_ai_report_by_company(
                        insights["analysis_report"],
                        company_name.lower() if isinstance(company_name, str) else company_name
                    )
                    insights = insights.copy()
                    insights["analysis_report"] = filtered_report
                
                result = {
                    "status": "success",
                    "tab_name": tab_name,
                    "current_week": snapshot_data.get("current_week", current_week),
                    "insights": insights  # í•„í„°ë§ëœ AI ë¶„ì„ ë¦¬í¬íŠ¸ í¬í•¨
                }
                
                if trend_type == "all":
                    result["rising_star"] = tab_data.get("rising_star", [])
                    result["new_entry"] = tab_data.get("new_entry", [])
                    result["rank_drop"] = tab_data.get("rank_drop", [])
                else:
                    if trend_type == "rising" or trend_type == "all":
                        result["rising_star"] = tab_data.get("rising_star", [])
                    if trend_type == "new_entry" or trend_type == "all":
                        result["new_entry"] = tab_data.get("new_entry", [])
                    if trend_type == "rank_drop" or trend_type == "all":
                        result["rank_drop"] = tab_data.get("rank_drop", [])
                
                return jsonify(result), 200
        else:
            # ìŠ¤ëƒ…ìƒ·ì´ ì—†ìœ¼ë©´ BigQueryì—ì„œ ì¡°íšŒ (Fallback)
            print(f"[WARN] âš ï¸ GCS ìŠ¤ëƒ…ìƒ· ì—†ìŒ, BigQueryì—ì„œ ì§ì ‘ ì¡°íšŒ (ë¹„ìš© ë°œìƒ): {current_week}")
            
            if tab_names and isinstance(tab_names, list):
                # ì—¬ëŸ¬ íƒ­ ë°ì´í„°ë¥¼ í•œ ë²ˆì— ë°˜í™˜
                result = {
                    "status": "success",
                    "tabs_data": {},
                    "current_week": current_week
                }
                
                # ê° íƒ­ë³„ ë°ì´í„° ì¡°íšŒ
                for tab in tab_names:
                    tab_data = {}
                    if trend_type == "rising" or trend_type == "all":
                        tab_data["rising_star"] = get_rising_star(tab)
                    if trend_type == "new_entry" or trend_type == "all":
                        tab_data["new_entry"] = get_new_entry(tab)
                    if trend_type == "rank_drop" or trend_type == "all":
                        tab_data["rank_drop"] = get_rank_drop(tab)
                    result["tabs_data"][tab] = tab_data
                
                return jsonify(result), 200
            else:
                # ë‹¨ì¼ íƒ­ ì²˜ë¦¬ (í•˜ìœ„ í˜¸í™˜)
                tab_name = tab_name or "ì „ì²´"
                result = {
                    "status": "success",
                    "tab_name": tab_name,
                    "current_week": current_week
                }
                
                # íŠ¸ë Œë“œ íƒ€ì…ë³„ ë°ì´í„° ì¡°íšŒ
                if trend_type == "rising" or trend_type == "all":
                    result["rising_star"] = get_rising_star(tab_name)
                
                if trend_type == "new_entry" or trend_type == "all":
                    result["new_entry"] = get_new_entry(tab_name)
                
                if trend_type == "rank_drop" or trend_type == "all":
                    result["rank_drop"] = get_rank_drop(tab_name)
                
                return jsonify(result), 200
        
    except Exception as e:
        print(f"[ERROR] get_trend_data ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({"status": "error", "message": str(e)}), 500


@data_blueprint.route("/trend/snapshot/create", methods=["POST"])
def create_trend_snapshot():
    """íŠ¸ë Œë“œ ìŠ¤ëƒ…ìƒ· ìƒì„± (ìˆ˜ë™ ì‹¤í–‰ìš©, ìŠ¤ì¼€ì¤„ ì¶”ê°€ ì˜ˆì •)"""
    try:
        data = request.get_json() or {}
        tab_names = data.get("tab_names", [])
        
        if not tab_names:
            # ê¸°ë³¸ íƒ­ ëª©ë¡ ì¡°íšŒ
            tab_names = get_available_tabs()
        
        # ì£¼ì°¨ ì •ë³´ ì¡°íšŒ
        current_week = get_current_week_info()
        if not current_week:
            return jsonify({"status": "error", "message": "ì£¼ì°¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}), 404
        
        # ëª¨ë“  íƒ­ ë°ì´í„° ì¡°íšŒ (ìºì‹œ ë¬´ì‹œí•˜ê³  ì§ì ‘ ì¡°íšŒ)
        print(f"[INFO] ìŠ¤ëƒ…ìƒ· ìƒì„± ì‹œì‘: {current_week}")
        tabs_data = get_all_tabs_data_from_bigquery(tab_names)
        
        # GCSì— ì €ì¥
        success = save_trend_snapshot_to_gcs(current_week, tabs_data, current_week)
        
        if success:
            return jsonify({
                "status": "success",
                "message": f"ìŠ¤ëƒ…ìƒ· ìƒì„± ì™„ë£Œ: {current_week}",
                "run_id": current_week,
                "tabs_count": len(tab_names)
            }), 200
        else:
            return jsonify({"status": "error", "message": "ìŠ¤ëƒ…ìƒ· ì €ì¥ ì‹¤íŒ¨"}), 500
        
    except Exception as e:
        print(f"[ERROR] create_trend_snapshot ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({"status": "error", "message": str(e)}), 500


@data_blueprint.route("/trend/tabs", methods=["GET"])
def get_trend_tabs():
    """ì‚¬ìš© ê°€ëŠ¥í•œ íƒ­ ëª©ë¡ ì¡°íšŒ"""
    try:
        tabs = get_available_tabs()
        return jsonify({"status": "success", "tabs": tabs}), 200
    except Exception as e:
        print(f"[ERROR] get_trend_tabs ì‹¤íŒ¨: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ“Œ Ably íŠ¸ë Œë“œ API
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@data_blueprint.route("/trend/ably", methods=["POST"])
def get_ably_trend_data():
    """Ably íŠ¸ë Œë“œ ë°ì´í„° ì¡°íšŒ (ìŠ¤ëƒ…ìƒ· ìš°ì„ , ì—†ìœ¼ë©´ BigQuery ì¡°íšŒ)"""
    try:
        data = request.get_json() or {}
        tab_names = data.get("tab_names")  # ë¦¬ìŠ¤íŠ¸ë¡œ ë°›ì•„ì„œ ì—¬ëŸ¬ íƒ­ í•œ ë²ˆì— ì²˜ë¦¬
        tab_name = data.get("tab_name")  # ë‹¨ì¼ íƒ­ (í•˜ìœ„ í˜¸í™˜)
        trend_type = data.get("trend_type", "all")  # "rising", "new_entry", "rank_drop", "all"
        company_name = data.get("company_name")  # í˜„ì¬ ë¡œê·¸ì¸í•œ ì—…ì²´ëª… (ìì‚¬ëª° í•„í„°ë§ìš©)
        
        # ì£¼ì°¨ ì •ë³´ ì¡°íšŒ (ìŠ¤ëƒ…ìƒ· ê²½ë¡œ ìƒì„±ì„ ìœ„í•´)
        current_week = get_ably_current_week_info()
        if not current_week:
            return jsonify({"status": "error", "message": "ì£¼ì°¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}), 404
        
        # ìŠ¤ëƒ…ìƒ·ì—ì„œ ë¡œë“œ ì‹œë„ (ìš°ì„ ìˆœìœ„ 1: GCS ë²„í‚·)
        snapshot_data = load_ably_trend_snapshot_from_gcs(current_week)
        
        if snapshot_data:
            # ìŠ¤ëƒ…ìƒ· ë°ì´í„° ì‚¬ìš© (GCS ë²„í‚·ì—ì„œ ë¡œë“œ ì„±ê³µ)
            print(f"[INFO] âœ… GCS ìŠ¤ëƒ…ìƒ·ì—ì„œ Ably íŠ¸ë Œë“œ ë°ì´í„° ë¡œë“œ ì„±ê³µ: {current_week}")
            
            if tab_names and isinstance(tab_names, list):
                # ì—¬ëŸ¬ íƒ­ ì²˜ë¦¬
                # AI ë¦¬í¬íŠ¸ í•„í„°ë§ (í˜„ì¬ ì—…ì²´ì— í•´ë‹¹í•˜ëŠ” ìì‚¬ëª° ì„¹ì…˜ë§Œ í¬í•¨)
                insights = snapshot_data.get("insights", {})
                if company_name and insights.get("analysis_report"):
                    filtered_report = filter_ai_report_by_company(
                        insights["analysis_report"],
                        company_name.lower() if isinstance(company_name, str) else company_name
                    )
                    insights = insights.copy()
                    insights["analysis_report"] = filtered_report
                
                result = {
                    "status": "success",
                    "current_week": snapshot_data.get("current_week", current_week),
                    "tabs_data": {},
                    "insights": insights  # í•„í„°ë§ëœ AI ë¶„ì„ ë¦¬í¬íŠ¸ í¬í•¨
                }
                
                for tab in tab_names:
                    tab_data = snapshot_data.get("tabs_data", {}).get(tab, {})
                    if trend_type == "all":
                        result["tabs_data"][tab] = tab_data
                    else:
                        filtered_data = {}
                        if trend_type == "rising" and "rising_star" in tab_data:
                            filtered_data["rising_star"] = tab_data["rising_star"]
                        if trend_type == "new_entry" and "new_entry" in tab_data:
                            filtered_data["new_entry"] = tab_data["new_entry"]
                        if trend_type == "rank_drop" and "rank_drop" in tab_data:
                            filtered_data["rank_drop"] = tab_data["rank_drop"]
                        result["tabs_data"][tab] = filtered_data
                
                return jsonify(result), 200
            else:
                # ë‹¨ì¼ íƒ­ ì²˜ë¦¬ (í•˜ìœ„ í˜¸í™˜)
                tab_name = tab_name or "ìƒì˜"
                tab_data = snapshot_data.get("tabs_data", {}).get(tab_name, {})
                
                # AI ë¦¬í¬íŠ¸ í•„í„°ë§ (í˜„ì¬ ì—…ì²´ì— í•´ë‹¹í•˜ëŠ” ìì‚¬ëª° ì„¹ì…˜ë§Œ í¬í•¨)
                insights = snapshot_data.get("insights", {})
                if company_name and insights.get("analysis_report"):
                    filtered_report = filter_ai_report_by_company(
                        insights["analysis_report"],
                        company_name.lower() if isinstance(company_name, str) else company_name
                    )
                    insights = insights.copy()
                    insights["analysis_report"] = filtered_report
                
                result = {
                    "status": "success",
                    "tab_name": tab_name,
                    "current_week": snapshot_data.get("current_week", current_week),
                    "insights": insights  # í•„í„°ë§ëœ AI ë¶„ì„ ë¦¬í¬íŠ¸ í¬í•¨
                }
                
                if trend_type == "all":
                    result["rising_star"] = tab_data.get("rising_star", [])
                    result["new_entry"] = tab_data.get("new_entry", [])
                    result["rank_drop"] = tab_data.get("rank_drop", [])
                else:
                    if trend_type == "rising" or trend_type == "all":
                        result["rising_star"] = tab_data.get("rising_star", [])
                    if trend_type == "new_entry" or trend_type == "all":
                        result["new_entry"] = tab_data.get("new_entry", [])
                    if trend_type == "rank_drop" or trend_type == "all":
                        result["rank_drop"] = tab_data.get("rank_drop", [])
                
                return jsonify(result), 200
        else:
            # ìŠ¤ëƒ…ìƒ·ì´ ì—†ìœ¼ë©´ BigQueryì—ì„œ ì¡°íšŒ (Fallback)
            print(f"[WARN] âš ï¸ GCS ìŠ¤ëƒ…ìƒ· ì—†ìŒ, BigQueryì—ì„œ ì§ì ‘ ì¡°íšŒ (ë¹„ìš© ë°œìƒ): {current_week}")
            
            if tab_names and isinstance(tab_names, list):
                # ì—¬ëŸ¬ íƒ­ ë°ì´í„°ë¥¼ í•œ ë²ˆì— ë°˜í™˜
                result = {
                    "status": "success",
                    "tabs_data": {},
                    "current_week": current_week
                }
                
                # ê° íƒ­ë³„ ë°ì´í„° ì¡°íšŒ
                for tab in tab_names:
                    tab_data = {}
                    if trend_type == "rising" or trend_type == "all":
                        tab_data["rising_star"] = get_ably_rising_star(tab)
                    if trend_type == "new_entry" or trend_type == "all":
                        tab_data["new_entry"] = get_ably_new_entry(tab)
                    if trend_type == "rank_drop" or trend_type == "all":
                        tab_data["rank_drop"] = get_ably_rank_drop(tab)
                    result["tabs_data"][tab] = tab_data
                
                return jsonify(result), 200
            else:
                # ë‹¨ì¼ íƒ­ ì²˜ë¦¬ (í•˜ìœ„ í˜¸í™˜)
                tab_name = tab_name or "ìƒì˜"
                result = {
                    "status": "success",
                    "tab_name": tab_name,
                    "current_week": current_week
                }
                
                # íŠ¸ë Œë“œ íƒ€ì…ë³„ ë°ì´í„° ì¡°íšŒ
                if trend_type == "rising" or trend_type == "all":
                    result["rising_star"] = get_ably_rising_star(tab_name)
                
                if trend_type == "new_entry" or trend_type == "all":
                    result["new_entry"] = get_ably_new_entry(tab_name)
                
                if trend_type == "rank_drop" or trend_type == "all":
                    result["rank_drop"] = get_ably_rank_drop(tab_name)
                
                return jsonify(result), 200
        
    except Exception as e:
        print(f"[ERROR] get_ably_trend_data ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({"status": "error", "message": str(e)}), 500


@data_blueprint.route("/trend/ably/snapshot/create", methods=["POST"])
def create_ably_trend_snapshot():
    """Ably íŠ¸ë Œë“œ ìŠ¤ëƒ…ìƒ· ìƒì„± (ìˆ˜ë™ ì‹¤í–‰ìš©, ìŠ¤ì¼€ì¤„ ì¶”ê°€ ì˜ˆì •)"""
    try:
        data = request.get_json() or {}
        tab_names = data.get("tab_names", [])
        
        if not tab_names:
            # ê¸°ë³¸ íƒ­ ëª©ë¡ ì¡°íšŒ
            tab_names = get_ably_available_tabs()
        
        # ì£¼ì°¨ ì •ë³´ ì¡°íšŒ
        current_week = get_ably_current_week_info()
        if not current_week:
            return jsonify({"status": "error", "message": "ì£¼ì°¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}), 404
        
        # ëª¨ë“  íƒ­ ë°ì´í„° ì¡°íšŒ (ìºì‹œ ë¬´ì‹œí•˜ê³  ì§ì ‘ ì¡°íšŒ)
        print(f"[INFO] Ably ìŠ¤ëƒ…ìƒ· ìƒì„± ì‹œì‘: {current_week}")
        tabs_data = get_ably_all_tabs_data_from_bigquery(tab_names)
        
        # GCSì— ì €ì¥ (AI ë¶„ì„ ë¦¬í¬íŠ¸ í¬í•¨)
        success = save_ably_trend_snapshot_to_gcs(current_week, tabs_data, current_week, enable_ai_analysis=True)
        
        if success:
            return jsonify({
                "status": "success",
                "message": f"Ably ìŠ¤ëƒ…ìƒ· ìƒì„± ì™„ë£Œ: {current_week}",
                "run_id": current_week,
                "tabs_count": len(tab_names)
            }), 200
        else:
            return jsonify({"status": "error", "message": "ìŠ¤ëƒ…ìƒ· ì €ì¥ ì‹¤íŒ¨"}), 500
        
    except Exception as e:
        print(f"[ERROR] create_ably_trend_snapshot ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({"status": "error", "message": str(e)}), 500


@data_blueprint.route("/trend/ably/tabs", methods=["GET"])
def get_ably_trend_tabs():
    """ì‚¬ìš© ê°€ëŠ¥í•œ Ably íƒ­ ëª©ë¡ ì¡°íšŒ"""
    try:
        tabs = get_ably_available_tabs()
        return jsonify({"status": "success", "tabs": tabs}), 200
    except Exception as e:
        print(f"[ERROR] get_ably_trend_tabs ì‹¤íŒ¨: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ“Œ 29CM ê²½ìŸì‚¬ ë¹„êµ í˜ì´ì§€ API
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@data_blueprint.route("/compare/29cm/keywords", methods=["GET"])
def get_compare_keywords():
    """ê²½ìŸì‚¬ ê²€ìƒ‰ì–´ ëª©ë¡ ì¡°íšŒ"""
    try:
        company_name = request.args.get("company_name")
        if not company_name:
            return jsonify({"status": "error", "message": "company_name íŒŒë¼ë¯¸í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400
        
        keywords = get_competitor_keywords(company_name)
        return jsonify({
            "status": "success",
            "keywords": keywords
        }), 200
    except Exception as e:
        print(f"[ERROR] get_compare_keywords ì‹¤íŒ¨: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


@data_blueprint.route("/compare/29cm/search", methods=["POST"])
def get_compare_search_results():
    """ê²½ìŸì‚¬ ê²€ìƒ‰ ê²°ê³¼ ì¡°íšŒ"""
    try:
        data = request.get_json() or {}
        company_name = data.get("company_name")
        search_keyword = data.get("search_keyword")
        run_id = data.get("run_id")
        get_run_id_only = data.get("get_run_id_only", False)
        
        if not company_name:
            return jsonify({"status": "error", "message": "company_nameì´ í•„ìš”í•©ë‹ˆë‹¤."}), 400
        
        # run_idë§Œ ì¡°íšŒí•˜ëŠ” ê²½ìš°
        if get_run_id_only:
            run_id = get_current_week_info()
            if not run_id:
                return jsonify({"status": "error", "message": "ì£¼ì°¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}), 404
            return jsonify({"status": "success", "run_id": run_id}), 200
        
        # run_idê°€ ì—†ìœ¼ë©´ ìµœì‹  ì£¼ì°¨ ì‚¬ìš©
        if not run_id:
            run_id = get_current_week_info()
            if not run_id:
                return jsonify({"status": "error", "message": "ì£¼ì°¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}), 404
        
        # ìì‚¬ëª° ê²€ìƒ‰ì¸ ê²½ìš° (search_keywordê°€ 'own'ì¸ ê²½ìš°)
        # company_mappingì—ì„œ ë¸Œëœë“œëª… ê°€ì ¸ì˜¤ê¸°
        if search_keyword == 'own':
            if COMPANY_MAPPING_AVAILABLE:
                brands = get_company_brands(company_name)
                if brands:
                    # ì²« ë²ˆì§¸ ë¸Œëœë“œëª…ìœ¼ë¡œ ê²€ìƒ‰
                    search_keyword = brands[0]
                else:
                    # ë¸Œëœë“œëª…ì´ ì—†ìœ¼ë©´ í•œê¸€ëª… ì‚¬ìš©
                    korean_name = get_company_korean_name(company_name)
                    if korean_name:
                        search_keyword = korean_name
                    else:
                        search_keyword = company_name
            else:
                # ê¸°ë³¸ ë§¤í•‘ (ì„ì‹œ)
                brand_mapping = {
                    'piscess': 'íŒŒì´ì‹œìŠ¤'
                }
                search_keyword = brand_mapping.get(company_name.lower(), company_name)
        
        # BigQueryì—ì„œ ê²€ìƒ‰ ê²°ê³¼ ë¡œë“œ
        results = load_search_results_from_bq(
            company_name=company_name,
            run_id=run_id,
            search_keyword=search_keyword
        )
        
        # search_keywordê°€ ì§€ì •ëœ ê²½ìš° í•´ë‹¹ í‚¤ì›Œë“œë§Œ ë°˜í™˜
        if search_keyword:
            return jsonify({
                "status": "success",
                "run_id": run_id,
                "search_keyword": search_keyword,
                "results": results.get(search_keyword, [])
            }), 200
        else:
            # ëª¨ë“  í‚¤ì›Œë“œ ë°˜í™˜
            return jsonify({
                "status": "success",
                "run_id": run_id,
                "results": results
            }), 200
            
    except Exception as e:
        print(f"[ERROR] get_compare_search_results ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({"status": "error", "message": str(e)}), 500


@data_blueprint.route("/compare/29cm/reviews", methods=["GET"])
def get_compare_reviews():
    """ìƒí’ˆ ë¦¬ë·° ì¡°íšŒ"""
    try:
        item_id = request.args.get("item_id")
        if not item_id:
            return jsonify({"status": "error", "message": "item_id íŒŒë¼ë¯¸í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400
        
        try:
            item_id_int = int(item_id)
        except ValueError:
            return jsonify({"status": "error", "message": "item_idëŠ” ìˆ«ìì—¬ì•¼ í•©ë‹ˆë‹¤."}), 400
        
        reviews = fetch_product_reviews(item_id_int, limit=10)
        return jsonify({
            "status": "success",
            "item_id": item_id_int,
            "reviews": reviews
        }), 200
        
    except Exception as e:
        print(f"[ERROR] get_compare_reviews ì‹¤íŒ¨: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500