import os
import pandas as pd
from google.cloud import bigquery
from googleapiclient.discovery import build
from datetime import datetime, timezone, timedelta
import logging

# âœ… í•œêµ­ ì‹œê°„ëŒ€ ì„¤ì •
KST = timezone(timedelta(hours=9))

# âœ… ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")

PROJECT_ID = "winged-precept-443218-v8"
DATASET_ID = "ngn_dataset"
TABLE_ID_TRAFFIC = "ga4_traffic"
TABLE_ID_TRAFFIC_NGN = "ga4_traffic_ngn"

# âœ… BigQuery í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (ADC ì‚¬ìš©)
bigquery_client = bigquery.Client(project=PROJECT_ID)

# âœ… GA4 API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (ADC ì‚¬ìš©)
analytics = build("analyticsdata", "v1beta")

# âœ… company_info í…Œì´ë¸”ì—ì„œ GA4 Property ID ë™ì ìœ¼ë¡œ ê°€ì ¸ì˜¤ê¸°
def get_ga4_property_ids():
    """company_info í…Œì´ë¸”ì—ì„œ ga4_property_idê°€ NULLì´ ì•„ë‹ˆê³  5ìë¦¬ ì´ìƒì¸ ê²ƒë“¤ë§Œ ê°€ì ¸ì˜¤ê¸°"""
    query = f"""
    SELECT DISTINCT ga4_property_id
    FROM `{PROJECT_ID}.{DATASET_ID}.company_info`
    WHERE ga4_property_id IS NOT NULL
      AND ga4_property_id >= 10000
    ORDER BY ga4_property_id
    """
    try:
        results = bigquery_client.query(query).result()
        property_ids = [int(row.ga4_property_id) for row in results]
        logging.info(f"âœ… GA4 Property IDs ë¡œë“œ ì™„ë£Œ: {property_ids}")
        return property_ids
    except Exception as e:
        logging.error(f"âŒ GA4 Property IDs ì¡°íšŒ ì‹¤íŒ¨: {e}")
        # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
        return [443411644, 449713217, 452725867]


def collect_ga4_traffic(start_date, end_date):
    """ âœ… GA4 APIì—ì„œ íŠ¸ë˜í”½ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì—¬ BigQueryì— ì €ì¥ """
    # âœ… 1. ì¤‘ë³µ ë°©ì§€: í•´ë‹¹ ê¸°ê°„ì˜ ê¸°ì¡´ ë°ì´í„° ì‚­ì œ
    logging.info(f"ğŸ—‘ï¸ ì¤‘ë³µ ë°©ì§€: {start_date} ~ {end_date} ê¸°ê°„ì˜ ê¸°ì¡´ ë°ì´í„° ì‚­ì œ ì¤‘...")
    delete_query = f"""
    DELETE FROM `{PROJECT_ID}.{DATASET_ID}.{TABLE_ID_TRAFFIC}`
    WHERE event_date BETWEEN DATE("{start_date}") AND DATE("{end_date}")
    """
    try:
        delete_job = bigquery_client.query(delete_query)
        delete_job.result()
        logging.info(f"âœ… ê¸°ì¡´ ë°ì´í„° ì‚­ì œ ì™„ë£Œ")
    except Exception as e:
        logging.error(f"âŒ ê¸°ì¡´ ë°ì´í„° ì‚­ì œ ì‹¤íŒ¨: {e}")
        raise
    
    # âœ… 2. ë™ì ìœ¼ë¡œ GA4 Property IDs ê°€ì ¸ì˜¤ê¸°
    GA4_PROPERTY_IDS = get_ga4_property_ids()
    
    date_range = pd.date_range(start=start_date, end=end_date).strftime("%Y-%m-%d").tolist()
    all_rows_traffic = []

    for target_date in date_range:
        for GA4_PROPERTY_ID in GA4_PROPERTY_IDS:
            logging.info(f"ğŸ“¡ {GA4_PROPERTY_ID} ({target_date}) íŠ¸ë˜í”½ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")

            try:
                request_body = {
                    "dateRanges": [{"startDate": target_date, "endDate": target_date}],
                    "dimensions": [{"name": "date"}, {"name": "firstUserSource"}],
                    "metrics": [
                        {"name": "activeUsers"},  # âœ… ë´‡ íŠ¸ë˜í”½ ì œê±°ë¥¼ ìœ„í•´ totalUsers ëŒ€ì‹  activeUsers ì‚¬ìš©
                        {"name": "engagementRate"},
                        {"name": "bounceRate"},
                        {"name": "eventCount"},
                        {"name": "screenPageViews"}
                    ]
                }

                response = analytics.properties().runReport(
                    property=f"properties/{GA4_PROPERTY_ID}", body=request_body
                ).execute()

                for row in response.get("rows", []):
                    dims = [dim["value"] for dim in row["dimensionValues"]]
                    event_date, first_user_source = dims  
                    metrics = [float(metric["value"]) for metric in row["metricValues"]]
                    
                    # âœ… ì›ë³¸ ê°’ í™•ì¸ (ë””ë²„ê¹…ìš©)
                    original_engagement = metrics[1]
                    original_bounce = metrics[2]
                    
                    # âœ… engagement_rate ì²˜ë¦¬ (0~1 ì†Œìˆ˜ ê°’ì„ í¼ì„¼íŠ¸ë¡œ ë³€í™˜)
                    if original_engagement > 1.0:
                        logging.error(f"âŒ ì´ìƒí•œ engagement_rate ê°’: {GA4_PROPERTY_ID} {event_date} {first_user_source} - ì›ë³¸: {original_engagement} (1.0ë³´ë‹¤ í¼)")
                        engagement_rate_final = round(original_engagement, 2)
                    else:
                        engagement_rate_final = round(original_engagement * 100, 2)
                    
                    # âœ… bounce_rate ê³„ì‚°: GA4ì—ì„œëŠ” ì´íƒˆë¥  = 1 - ì°¸ì—¬ìœ¨
                    # GA4 APIì˜ bounceRate ë©”íŠ¸ë¦­ì´ ì‹¤ì œ ëŒ€ì‹œë³´ë“œì™€ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ,
                    # engagementRateë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê³„ì‚°í•˜ëŠ” ê²ƒì´ ë” ì •í™•í•¨
                    bounce_rate_from_engagement = round((1.0 - original_engagement) * 100, 2)
                    
                    # âœ… GA4 APIì˜ bounceRateë„ ìˆ˜ì§‘í•˜ë˜, engagement ê¸°ë°˜ ê³„ì‚°ê°’ê³¼ ë¹„êµ
                    if original_bounce > 1.0:
                        bounce_rate_from_api = round(original_bounce, 2)
                    else:
                        bounce_rate_from_api = round(original_bounce * 100, 2)
                    
                    # âœ… ë‘ ê°’ì´ í¬ê²Œ ë‹¤ë¥´ë©´ ë¡œê¹… (ì°¨ì´ê°€ 5% ì´ìƒ)
                    if abs(bounce_rate_from_engagement - bounce_rate_from_api) > 5.0:
                        logging.warning(f"âš ï¸ bounce_rate ë¶ˆì¼ì¹˜: {GA4_PROPERTY_ID} {event_date} {first_user_source} - engagement ê¸°ë°˜: {bounce_rate_from_engagement}%, API bounceRate: {bounce_rate_from_api}%")
                    
                    # âœ… engagement ê¸°ë°˜ ê³„ì‚°ê°’ ì‚¬ìš© (GA4 ëŒ€ì‹œë³´ë“œì™€ ì¼ì¹˜)
                    bounce_rate_final = bounce_rate_from_engagement

                    all_rows_traffic.append({
                        "event_date": event_date,
                        "ga4_property_id": GA4_PROPERTY_ID,
                        "first_user_source": first_user_source,
                        "total_users": int(metrics[0]),  # âœ… activeUsers ê°’ì„ total_users ì»¬ëŸ¼ì— ë§¤í•‘ (ìŠ¤í‚¤ë§ˆ ìœ ì§€)
                        "engagement_rate": engagement_rate_final,
                        "bounce_rate": bounce_rate_final,
                        "event_count": int(metrics[3]),
                        "screen_page_views": int(metrics[4])
                    })
            except Exception as e:
                logging.error(f"âŒ {GA4_PROPERTY_ID} ({target_date}) íŠ¸ë˜í”½ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                continue

    df_traffic = pd.DataFrame(all_rows_traffic)
    if not df_traffic.empty:
        df_traffic["event_date"] = pd.to_datetime(df_traffic["event_date"]).dt.date
        df_traffic["ga4_property_id"] = df_traffic["ga4_property_id"].astype(int)
        
        # âœ… 3. DataFrame ë ˆë²¨ ì¤‘ë³µ ë°ì´í„° í™•ì¸ ë° ë¡œê¹… (API ì‘ë‹µì—ì„œ ì¤‘ë³µì´ ì˜¬ ìˆ˜ ìˆìœ¼ë¯€ë¡œ)
        before_dedup = len(df_traffic)
        # ê°™ì€ ë‚ ì§œ/ì†ŒìŠ¤/property_idì— ì¤‘ë³µì´ ìˆëŠ”ì§€ í™•ì¸
        duplicates = df_traffic.duplicated(subset=['event_date', 'ga4_property_id', 'first_user_source'], keep=False)
        if duplicates.any():
            dup_count = duplicates.sum()
            logging.warning(f"âš ï¸ DataFrame ë‚´ ì¤‘ë³µ ë°ì´í„° ë°œê²¬: {dup_count}ê°œ í–‰ (ì „ì²´: {before_dedup}ê°œ)")
            # ì¤‘ë³µëœ í–‰ì˜ ìƒ˜í”Œ ë¡œê¹…
            dup_rows = df_traffic[duplicates].head(5)
            for _, row in dup_rows.iterrows():
                logging.warning(f"  ì¤‘ë³µ: {row['event_date']} {row['ga4_property_id']} {row['first_user_source']} - users: {row['total_users']}, bounce: {row['bounce_rate']}%")
        
        # âœ… ì¤‘ë³µ ì œê±° (ê°™ì€ ë‚ ì§œ/ì†ŒìŠ¤/property_id ì¤‘ ê°€ì¥ í° total_usersë¥¼ ê°€ì§„ í–‰ ìœ ì§€)
        df_traffic = df_traffic.sort_values('total_users', ascending=False).drop_duplicates(
            subset=['event_date', 'ga4_property_id', 'first_user_source'], 
            keep='first'
        )
        after_dedup = len(df_traffic)
        if before_dedup != after_dedup:
            logging.info(f"âœ… DataFrame ì¤‘ë³µ ì œê±°: {before_dedup}ê°œ â†’ {after_dedup}ê°œ")

        # âœ… 4. BigQuery ì ì¬
        table_ref_traffic = bigquery_client.dataset(DATASET_ID).table(TABLE_ID_TRAFFIC)
        load_job_traffic = bigquery_client.load_table_from_dataframe(df_traffic, table_ref_traffic)
        load_job_traffic.result()

        logging.info(f"âœ… GA4 íŠ¸ë˜í”½ ë°ì´í„° {len(df_traffic)}ê°œ ì ì¬ ì™„ë£Œ!")
    else:
        logging.info(f"âœ… {start_date} ~ {end_date} êµ¬ê°„ì— ëŒ€í•œ íŠ¸ë˜í”½ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")


def update_ga4_traffic_ngn(start_date, end_date):
    """ âœ… ga4_traffic ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ga4_traffic_ngn í…Œì´ë¸” ì—…ë°ì´íŠ¸ """
    logging.info(f"ğŸ“¡ {TABLE_ID_TRAFFIC_NGN} í…Œì´ë¸” ì—…ë°ì´íŠ¸ ì¤‘...")

    merge_query = f"""
    MERGE `{PROJECT_ID}.{DATASET_ID}.{TABLE_ID_TRAFFIC_NGN}` AS target
    USING (
        SELECT 
            t.event_date, 
            c.company_name,
            t.ga4_property_id, 
            t.first_user_source,
            SUM(t.total_users) AS total_users,
            -- engagement_rateì™€ bounce_rateëŠ” ê°€ì¤‘í‰ê· ìœ¼ë¡œ ê³„ì‚°
            SAFE_DIVIDE(
                SUM(t.engagement_rate * t.total_users),
                SUM(t.total_users)
            ) AS engagement_rate,
            SAFE_DIVIDE(
                SUM(t.bounce_rate * t.total_users),
                SUM(t.total_users)
            ) AS bounce_rate,
            SUM(t.event_count) AS event_count,
            SUM(t.screen_page_views) AS screen_page_views
        FROM `{PROJECT_ID}.{DATASET_ID}.{TABLE_ID_TRAFFIC}` t
        LEFT JOIN `{PROJECT_ID}.{DATASET_ID}.company_info` c 
            ON t.ga4_property_id = c.ga4_property_id
        WHERE t.event_date BETWEEN DATE("{start_date}") AND DATE("{end_date}")
          AND c.company_name IS NOT NULL
        GROUP BY t.event_date, c.company_name, t.ga4_property_id, t.first_user_source
    ) AS source
    ON target.event_date = source.event_date
       AND target.company_name = source.company_name
       AND target.ga4_property_id = source.ga4_property_id
       AND target.first_user_source = source.first_user_source
       AND target.event_date BETWEEN DATE("{start_date}") AND DATE("{end_date}")
    WHEN MATCHED THEN
        UPDATE SET 
            target.total_users = source.total_users,
            target.engagement_rate = source.engagement_rate,
            target.bounce_rate = source.bounce_rate,
            target.event_count = source.event_count,
            target.screen_page_views = source.screen_page_views
    WHEN NOT MATCHED THEN
        INSERT (
            event_date, company_name, ga4_property_id, first_user_source, 
            total_users, engagement_rate, bounce_rate, event_count, screen_page_views
        )
        VALUES (
            source.event_date, source.company_name, source.ga4_property_id, 
            source.first_user_source, source.total_users, 
            source.engagement_rate, source.bounce_rate, 
            source.event_count, source.screen_page_views
        );
    """

    query_job = bigquery_client.query(merge_query)
    query_job.result()
    logging.info(f"âœ… {TABLE_ID_TRAFFIC_NGN} í…Œì´ë¸” ì—…ë°ì´íŠ¸ ì™„ë£Œ!")


if __name__ == "__main__":
    now_kst = datetime.now(timezone.utc).astimezone(KST)
    today = now_kst.strftime("%Y-%m-%d")
    yesterday = (now_kst - timedelta(days=1)).strftime("%Y-%m-%d")

    # âœ… ì˜¤ëŠ˜ ì‹¤í–‰
    if os.getenv("RUN_MODE", "today") == "today":
        collect_ga4_traffic(today, today)
        update_ga4_traffic_ngn(today, today)

    # âœ… ì–´ì œ ì‹¤í–‰
    elif os.getenv("RUN_MODE", "yesterday") == "yesterday":
        collect_ga4_traffic(yesterday, yesterday)
        update_ga4_traffic_ngn(yesterday, yesterday)

    logging.info("âœ… ëª¨ë“  ë°ì´í„° ìˆ˜ì§‘ ë° ì—…ë°ì´íŠ¸ ì™„ë£Œ!")
