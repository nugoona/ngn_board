import os
import sys
import json
import hashlib
import re
import statistics
import time
import random
import concurrent.futures
import gzip
from datetime import date, timedelta, datetime, timezone
from decimal import Decimal
from collections import defaultdict
from urllib.request import Request, urlopen
from urllib.error import HTTPError
from urllib.parse import urlencode
from google.cloud import bigquery
from google.cloud import storage

PROJECT_ID = os.environ.get("GOOGLE_CLOUD_PROJECT", "winged-precept-443218-v8")
DATASET = "ngn_dataset"
GCS_BUCKET = os.environ.get("GCS_BUCKET", "winged-precept-443218-v8.appspot.com")

# ê´‘ê³  ê¸°ì¤€
TRAFFIC_TOP_MIN_SPEND = 10_000
TOP_LIMIT = 5

# 4ì¶• í™•ì¥ ìƒìˆ˜
PRODUCT_TOP_LIMIT = 50
GA4_TRAFFIC_TOP_LIMIT = 5
VIEWITEM_TOP_LIMIT = 50
PRODUCT_ROLLING_WINDOWS = [30, 90]
VIEWITEM_ATTENTION_MIN_VIEW = 300  # attention_without_conversion ê¸°ì¤€ ìµœì†Œ ì¡°íšŒìˆ˜
VIEWITEM_EFFICIENT_MIN_VIEW = 120  # efficient_conversion ê¸°ì¤€ ìµœì†Œ ì¡°íšŒìˆ˜
VIEWITEM_EFFICIENT_MIN_QTY_PER_VIEW = 0.010  # efficient_conversion ê¸°ì¤€ ìµœì†Œ êµ¬ë§¤ìœ¨

# ë¹„êµ ê¸°ì¤€ threshold
MALL_SALES_BASE_SMALL_THRESHOLD = 500000
META_ADS_BASE_SMALL_THRESHOLD = 100000
GA4_TRAFFIC_BASE_SMALL_THRESHOLD = 100

# Viewitem ìŠ¤í‚µ í”Œë˜ê·¸
SKIP_VIEWITEM = os.environ.get("SKIP_VIEWITEM", "0") == "1"
SKIP_META_ADS_GOALS = os.environ.get("SKIP_META_ADS_GOALS", "0") == "1"
SKIP_29CM_CRAWL = os.environ.get("SKIP_29CM_CRAWL", "0") == "1"

# ë¡œê·¸ ë ˆë²¨ ì œì–´ (DEBUG ë¡œê·¸ëŠ” í™˜ê²½ ë³€ìˆ˜ë¡œ í™œì„±í™”)
ENABLE_DEBUG_LOGS = os.environ.get("ENABLE_DEBUG_LOGS", "0") == "1"

# 29CM í¬ë¡¤ë§ ì„¤ì •
CRAWL_29CM_TARGET_TABS = ["ì „ì²´", "ì•„ìš°í„°", "ë‹ˆíŠ¸ì›¨ì–´", "ë°”ì§€", "ìŠ¤ì»¤íŠ¸", "ìƒì˜"]
CRAWL_29CM_TOP_N = 10
CRAWL_29CM_REVIEWS_PER_ITEM = 10
CRAWL_29CM_SLEEP_MIN = 0.05  # 0.5ì´ˆ -> 0.05ì´ˆ (10ë°° ë‹¨ì¶•)
CRAWL_29CM_SLEEP_MAX = 0.1   # 1.0ì´ˆ -> 0.1ì´ˆ (10ë°° ë‹¨ì¶•)

# GCS/BigQuery í´ë¼ì´ì–¸íŠ¸ ì „ì—­ ìƒì„± (ì¬ì‚¬ìš©)
storage_client = storage.Client(project=PROJECT_ID)
bq_client = bigquery.Client(project=PROJECT_ID)


# -----------------------
# ë‚ ì§œ í—¬í¼
# -----------------------
def month_range(year: int, month: int):
    """ì›” ì‹œì‘~ì›”ë§(end inclusive)"""
    start = date(year, month, 1)
    if month == 12:
        next_month = date(year + 1, 1, 1)
    else:
        next_month = date(year, month + 1, 1)
    end = next_month - timedelta(days=1)
    return start.isoformat(), end.isoformat()


def month_to_ym(year: int, month: int) -> str:
    """YYYY-MM í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    return f"{year:04d}-{month:02d}"


def shift_month(ym: str, delta: int) -> str:
    """YYYY-MM í˜•ì‹ì—ì„œ deltaê°œì›” ì´ë™"""
    y, m = map(int, ym.split("-"))
    m += delta
    while m > 12:
        m -= 12
        y += 1
    while m < 1:
        m += 12
        y -= 1
    return f"{y:04d}-{m:02d}"


def month_range_exclusive(ym: str):
    """YYYY-MM í˜•ì‹ì—ì„œ start_date (inclusive), end_date (exclusive) ë°˜í™˜"""
    y, m = map(int, ym.split("-"))
    start = date(y, m, 1)
    if m == 12:
        end_exclusive = date(y + 1, 1, 1)
    else:
        end_exclusive = date(y, m + 1, 1)
    return start.isoformat(), end_exclusive.isoformat()


def rolling_range(end_date_iso: str, days: int):
    end_d = date.fromisoformat(end_date_iso)
    start_d = end_d - timedelta(days=days - 1)
    return start_d.isoformat(), end_d.isoformat()


# -----------------------
# ìƒí’ˆëª… ì •ê·œí™” (í•µì‹¬)
# -----------------------
def normalize_item_name(name: str) -> str:
    if name is None:
        return ""

    s = str(name).strip()
    if not s or s == "(not set)":
        return ""

    # [ ] ì œê±° (ë‹¨, [SET]ì€ ë³´í˜¸) - ì—¬ëŸ¬ ê°œ ë°˜ë³µ ì œê±°
    if not s.startswith("[SET]"):
        while True:
            new_s = re.sub(r"^\[[^\]]+\]\s*", "", s)
            if new_s == s:
                break
            # ì œê±° ê³¼ì •ì—ì„œ [SET]ì´ ë§¨ ì•ìœ¼ë¡œ ì˜¤ë©´ ì¦‰ì‹œ ì¤‘ë‹¨
            if new_s.startswith("[SET]"):
                s = new_s
                break
            s = new_s

    # ì˜µì…˜ ì œê±°: "ì˜µì…˜ í† í°" + "ì˜µì…˜ ê²½ê³„"ì¼ ë•Œë§Œ ì ˆë‹¨
    # - í† í° ê¸¸ì´ ì œí•œìœ¼ë¡œ ê³¼ì‚­ì œ ë°©ì§€ (í•œê¸€ 1~6ì, ì˜ë¬¸ 1~12ì)
    # - ì˜µì…˜ ë’¤ëŠ” EOL/ê³µë°±/ê´„í˜¸/ëŒ€ê´„í˜¸ ë“± ì˜µì…˜ìŠ¤ëŸ¬ìš´ ê²½ê³„ë§Œ í—ˆìš©
    s = re.sub(
        r"_(?:\d{1,2}color|xs|s|m|l|xl|xxl|free|[a-z]{1,12}|[ê°€-í£]{1,6})(?=($|[\s\(\[])).*$",
        "",
        s,
        flags=re.IGNORECASE
    )

    # ê³µë°± ì •ë¦¬
    s = re.sub(r"\s+", " ", s).strip()

    return s


# -----------------------
# 29CM í¬ë¡¤ë§ í•¨ìˆ˜
# -----------------------
def crawl_29cm_best():
    """29CM ë² ìŠ¤íŠ¸ ìƒí’ˆ ë° ë¦¬ë·° í¬ë¡¤ë§"""
    if SKIP_29CM_CRAWL:
        return None
    
    API_URL = "https://display-bff-api.29cm.co.kr/api/v1/plp/best/items"
    CATEGORY_TREE_URL = "https://display-bff-api.29cm.co.kr/api/v1/category-groups/tree?categoryGroupNo=1"
    REVIEW_API_URL = "https://review-api.29cm.co.kr/api/v4/reviews"
    
    BEST_LARGE_ID = 268100100   # ì—¬ì„±ì˜ë¥˜
    PERIOD_TYPE = "MONTHLY"     # ì›”ê°„ ë² ìŠ¤íŠ¸
    RANKING_TYPE = "POPULARITY" # ì¸ê¸°ìˆœ
    GENDER = "F"
    AGE = "THIRTIES"            # 30ëŒ€ ì—¬ì„± íƒ€ê²Ÿ
    
    KST = timezone(timedelta(hours=9))
    
    HEADERS = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Accept": "application/json",
        "Content-Type": "application/json",
        "Origin": "https://home.29cm.co.kr",
        "Referer": "https://home.29cm.co.kr/",
    }
    
    def get_json(url: str, headers=None) -> dict:
        """JSON ìš”ì²­"""
        req = Request(url, headers=headers or HEADERS, method="GET")
        with urlopen(req, timeout=10) as resp:
            return json.loads(resp.read().decode("utf-8", errors="replace"))
    
    def post_json(payload: dict) -> dict:
        """POST JSON ìš”ì²­"""
        body = json.dumps(payload, ensure_ascii=False).encode("utf-8")
        req = Request(API_URL, data=body, headers=HEADERS, method="POST")
        with urlopen(req, timeout=10) as resp:
            return json.loads(resp.read().decode("utf-8", errors="replace"))
    
    def clean_text(text):
        """í…ìŠ¤íŠ¸ ì •ë¦¬"""
        if not text:
            return ""
        # ì´ëª¨ì§€ ì œê±°, ê³¼ë„í•œ ê³µë°± ì œê±°
        text = re.sub(r'[^\w\s.,?!%~+()-]', '', str(text))
        return re.sub(r'\s+', ' ', text).strip()
    
    def pick_thumbnail(it, info):
        """ì¸ë„¤ì¼ URL ì¶”ì¶œ"""
        candidates = [
            info.get("thumbnailUrl"), info.get("imageUrl"),
            it.get("thumbnailUrl"), it.get("imageUrl")
        ]
        for url in candidates:
            if url and "http" in url:
                return url
        return ""
    
    def get_target_tabs():
        """íƒ€ê²Ÿ ì¹´í…Œê³ ë¦¬ ID ì¶”ì¶œ"""
        tree = get_json(CATEGORY_TREE_URL)
        tabs = [{"name": "ì „ì²´", "middle_id": None}]  # ê¸°ë³¸ í¬í•¨
        
        # íŠ¸ë¦¬ì—ì„œ ì¤‘ë¶„ë¥˜ ì¶”ì¶œ
        for group in tree.get("data", {}).get("categoryGroups", []):
            for large in group.get("largeCategories", []):
                if int(large.get("categoryCode", 0)) == BEST_LARGE_ID:
                    for mid in large.get("mediumCategories", []):
                        c_name = mid.get("categoryName", "")
                        # ì„¤ì •ì— ìˆëŠ” ì¹´í…Œê³ ë¦¬ë§Œ ì¶”ê°€
                        if c_name in CRAWL_29CM_TARGET_TABS:
                            tabs.append({"name": c_name, "middle_id": int(mid["categoryCode"])})
        return tabs
    
    def fetch_item_reviews(item_id):
        """ë¦¬ë·° ìˆ˜ì§‘ (ìµœì‹ ìˆœ/ë² ìŠ¤íŠ¸ìˆœ ì‹œë„)"""
        for sort_type in ["RECENT", "BEST"]:
            try:
                params = {
                    "itemId": item_id,
                    "page": 1,
                    "size": CRAWL_29CM_REVIEWS_PER_ITEM,
                    "sort": sort_type
                }
                url = f"{REVIEW_API_URL}?{urlencode(params)}"
                data = get_json(url)
                
                reviews = []
                for r in data.get("data", {}).get("results", []):
                    content = clean_text(r.get("contents"))
                    if not content:
                        continue
                    reviews.append({
                        "txt": content[:200],  # ë„ˆë¬´ ê¸´ ë¦¬ë·°ëŠ” ìë¦„
                        "score": r.get("point"),
                        "opt": r.get("optionValue")  # êµ¬ë§¤ ì˜µì…˜(ìƒ‰ìƒ/ì‚¬ì´ì¦ˆ)
                    })
                
                if reviews:
                    return reviews  # ë¦¬ë·° ìˆìœ¼ë©´ ë°˜í™˜
            except Exception:
                continue
        return []
    
    # ë©”ì¸ ì‹¤í–‰
    try:
        if ENABLE_DEBUG_LOGS:
            print(f"ğŸš€ [INFO] 29CM ë² ìŠ¤íŠ¸ ìˆ˜ì§‘ ì‹œì‘ (Target: {CRAWL_29CM_TARGET_TABS})", file=sys.stderr)
        
        tabs = get_target_tabs()
        final_data = []
        
        for t in tabs:
            if ENABLE_DEBUG_LOGS:
                print(f"ğŸ“‚ [INFO] [{t['name']}] ìˆ˜ì§‘ ì¤‘... (Top {CRAWL_29CM_TOP_N})", file=sys.stderr)
            
            # ë­í‚¹ ìš”ì²­ payload
            payload = {
                "pageRequest": {"page": 1, "size": CRAWL_29CM_TOP_N},
                "userSegment": {"gender": GENDER, "age": AGE},
                "facets": {
                    "categoryFacetInputs": [{"largeId": BEST_LARGE_ID, "middleId": t["middle_id"]} if t["middle_id"] else {"largeId": BEST_LARGE_ID}],
                    "periodFacetInput": {"type": PERIOD_TYPE, "order": "DESC"},
                    "rankingFacetInput": {"type": RANKING_TYPE},
                },
            }
            
            try:
                resp = post_json(payload)
                items = resp.get("data", {}).get("list", [])
            except Exception as e:
                print(f"  âŒ API Error: {e}", file=sys.stderr)
                continue
            
            for rank, it in enumerate(items, 1):
                info = it.get("itemInfo", {})
                item_id = it.get("itemId")
                name = clean_text(info.get("productName"))
                
                if not item_id:
                    continue
                
                # ë¦¬ë·° ìˆ˜ì§‘ (ì ì‹œ ëŒ€ê¸° í›„ í˜¸ì¶œ)
                time.sleep(random.uniform(CRAWL_29CM_SLEEP_MIN, CRAWL_29CM_SLEEP_MAX))
                reviews = fetch_item_reviews(item_id)
                
                # URL ì¶”ì¶œ (itemUrl ê°ì²´ì—ì„œ webLink ê°€ì ¸ì˜¤ê¸°)
                item_url_obj = it.get("itemUrl", {})
                item_url = item_url_obj.get("webLink") if isinstance(item_url_obj, dict) else None
                
                # ë°ì´í„° ê²½ëŸ‰í™” ì €ì¥
                final_data.append({
                    "tab": t["name"],
                    "rank": rank,
                    "name": name,
                    "brand": info.get("brandName"),
                    "price": info.get("displayPrice"),
                    "img": pick_thumbnail(it, info),  # ì¸ë„¤ì¼ URL (ë¶„ì„ìš©)
                    "item_id": str(item_id),  # item_id ì¶”ê°€
                    "url": item_url,  # URL ì¶”ê°€
                    "reviews": reviews  # ë¦¬ë·° ë¦¬ìŠ¤íŠ¸ (ìµœëŒ€ 10ê°œ)
                })
        
        print(f"âœ… [SUCCESS] 29CM ìˆ˜ì§‘ ì™„ë£Œ! ì´ {len(final_data)}ê°œ ìƒí’ˆ", file=sys.stderr)
        return {
            "collected_at": datetime.now(KST).isoformat(),
            "items": final_data
        }
    except Exception as e:
        print("=" * 80, file=sys.stderr)
        print(f"âŒ [ERROR] 29CM í¬ë¡¤ë§ ì‹¤íŒ¨", file=sys.stderr)
        print(f"   ì˜¤ë¥˜ ë©”ì‹œì§€: {e}", file=sys.stderr)
        print("=" * 80, file=sys.stderr)
        import traceback
        traceback.print_exc(file=sys.stderr)
        return None


def _goal_from_campaign_name(campaign_name: str) -> str:
    """ìº í˜ì¸ëª…ì—ì„œ ëª©í‘œ ì¶”ì¶œ: conversion/traffic/awareness/unknown"""
    if not campaign_name:
        return "unknown"
    
    name_lower = campaign_name.lower()
    
    # ì „í™˜ (conversion)
    if "ì „í™˜" in campaign_name or "conversion" in name_lower:
        return "conversion"
    
    # ìœ ì… (traffic)
    if "ìœ ì…" in campaign_name or "traffic" in name_lower:
        return "traffic"
    
    # ë„ë‹¬ (awareness)
    if "ë„ë‹¬" in campaign_name or "awareness" in name_lower or "reach" in name_lower:
        return "awareness"
    
    return "unknown"


# -----------------------
# ê³µí†µ í—¬í¼
# -----------------------
def delta(curr, base):
    """ë³€í™”ëŸ‰ ê³„ì‚°: {"abs": ..., "pct": ...}
    - curr/baseê°€ Noneì´ë©´ None ë°˜í™˜
    - base==0ì´ë©´ pct None
    - BigQuery/JSON/ê³„ì‚° ì¤‘ Decimal ë“±ì´ ì„ì—¬ë„ ì•ˆì •ì ìœ¼ë¡œ ì²˜ë¦¬
    """
    if curr is None or base is None:
        return None
    # BigQuery/JSON/ê³„ì‚° ì¤‘ Decimal ë“±ì´ ì„ì—¬ë„ ì•ˆì •ì ìœ¼ë¡œ ì²˜ë¦¬
    try:
        c = float(curr)
        b = float(base)
    except (TypeError, ValueError):
        return None
    
    abs_diff = c - b
    pct = (abs_diff / b * 100) if b != 0 else None
    return {"abs": abs_diff, "pct": pct}


def note_if_base_small(base_value, threshold):
    """ê¸°ì¤€ê°’ì´ ì‘ì€ì§€ ì—¬ë¶€"""
    if base_value is None:
        return None
    return base_value < threshold


def json_safe(obj):
    """Decimal ë° ê¸°íƒ€ JSON ì§ë ¬í™” ë¶ˆê°€ëŠ¥í•œ íƒ€ì…ì„ ì•ˆì „í•˜ê²Œ ë³€í™˜"""
    if isinstance(obj, Decimal):
        return float(obj)
    if isinstance(obj, dict):
        # None ê°’ë„ ìœ ì§€ (íŠ¹íˆ meta_ads_goals ê°™ì€ í•„ìˆ˜ í‚¤)
        return {k: json_safe(v) for k, v in obj.items()}
    if isinstance(obj, list):
        return [json_safe(v) for v in obj]
    return obj


def has_rows(client, table_fq, date_col, company_name, start_date, end_date):
    """íŠ¹ì • ê¸°ê°„ì— ë°ì´í„°ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸ (ì²« ë²ˆì§¸ í–‰ë§Œ ì°¾ìœ¼ë©´ ì¤‘ë‹¨)"""
    query = f"""
    SELECT 1
    FROM `{table_fq}`
    WHERE company_name = @company_name
      AND {date_col} >= @start_date
      AND {date_col} <= @end_date
    LIMIT 1
    """
    
    rows = list(
        client.query(
            query,
            job_config=bigquery.QueryJobConfig(
                query_parameters=[
                    bigquery.ScalarQueryParameter("company_name", "STRING", company_name),
                    bigquery.ScalarQueryParameter("start_date", "DATE", start_date),
                    bigquery.ScalarQueryParameter("end_date", "DATE", end_date),
                ]
            ),
        ).result()
    )
    
    return len(rows) > 0


def query_monthly_13m_generic(client, table_fq, date_col, company_name, end_report_month_ym, select_exprs, where_extra=""):
    """
    13ê°œì›” ì›”ë³„ ì§‘ê³„ ê³µí†µ í•¨ìˆ˜ (daily í…Œì´ë¸”ìš©)
    ë°˜í™˜: dict[ym] = metrics
    """
    start_ym = shift_month(end_report_month_ym, -12)
    start_date, _ = month_range_exclusive(start_ym)
    _, end_exclusive_date = month_range_exclusive(shift_month(end_report_month_ym, 1))
    
    # ë””ë²„ê·¸: ì¿¼ë¦¬ ê¸°ê°„ í™•ì¸ (í™˜ê²½ ë³€ìˆ˜ë¡œ ì œì–´)
    if ENABLE_DEBUG_LOGS:
        print(f"[DEBUG] query_monthly_13m_generic: {table_fq} - start_date={start_date}, end_exclusive_date={end_exclusive_date}", file=sys.stderr)
    
    query = f"""
    SELECT 
        FORMAT_DATE('%Y-%m', {date_col}) AS ym,
        {select_exprs}
    FROM `{table_fq}`
    WHERE company_name = @company_name
      AND {date_col} >= @start_date
      AND {date_col} < @end_exclusive_date
      {where_extra}
    GROUP BY ym
    ORDER BY ym
    """
    
    rows = list(
        client.query(
            query,
            job_config=bigquery.QueryJobConfig(
                query_parameters=[
                    bigquery.ScalarQueryParameter("company_name", "STRING", company_name),
                    bigquery.ScalarQueryParameter("start_date", "DATE", start_date),
                    bigquery.ScalarQueryParameter("end_exclusive_date", "DATE", end_exclusive_date),
                ]
            ),
        ).result()
    )
    
    result = {}
    for row in rows:
        ym = row.ym
        metrics = {}
        for field in row.keys():
            if field != "ym":
                value = getattr(row, field)
                if isinstance(value, (int, float)):
                    metrics[field] = float(value) if isinstance(value, float) else int(value)
                else:
                    metrics[field] = value
        result[ym] = metrics
    
    return result


def query_monthly_13m_from_monthly_table(client, table_fq, company_name, end_report_month_ym, select_exprs):
    """
    13ê°œì›” ì›”ë³„ ì§‘ê³„ í•¨ìˆ˜ (ì›”ê°„ ì§‘ê³„ í…Œì´ë¸”ìš©)
    ë°˜í™˜: dict[ym] = metrics
    ì¤‘ë³µí–‰ì—ë„ ì•ˆì „í•˜ë„ë¡ GROUP BY ymìœ¼ë¡œ ì§‘ê³„
    """
    start_ym = shift_month(end_report_month_ym, -12)
    start_date, _ = month_range_exclusive(start_ym)
    _, end_exclusive_date = month_range_exclusive(shift_month(end_report_month_ym, 1))
    
    # ë””ë²„ê·¸: ì¿¼ë¦¬ ê¸°ê°„ í™•ì¸ (í™˜ê²½ ë³€ìˆ˜ë¡œ ì œì–´)
    if ENABLE_DEBUG_LOGS:
        print(f"[DEBUG] query_monthly_13m_from_monthly_table: {table_fq} - start_date={start_date}, end_exclusive_date={end_exclusive_date}", file=sys.stderr)
    
    query = f"""
    SELECT 
        FORMAT_DATE('%Y-%m', month_date) AS ym,
        {select_exprs}
    FROM `{table_fq}`
    WHERE company_name = @company_name
      AND month_date >= @start_date
      AND month_date < @end_exclusive_date
    GROUP BY ym
    ORDER BY ym
    """
    
    rows = list(
        client.query(
            query,
            job_config=bigquery.QueryJobConfig(
                query_parameters=[
                    bigquery.ScalarQueryParameter("company_name", "STRING", company_name),
                    bigquery.ScalarQueryParameter("start_date", "DATE", start_date),
                    bigquery.ScalarQueryParameter("end_exclusive_date", "DATE", end_exclusive_date),
                ]
            ),
        ).result()
    )
    
    result = {}
    for row in rows:
        ym = row.ym
        metrics = {}
        for field in row.keys():
            if field != "ym":
                value = getattr(row, field)
                if isinstance(value, (int, float)):
                    metrics[field] = float(value) if isinstance(value, float) else int(value)
                else:
                    metrics[field] = value
        result[ym] = metrics
    
    return result


def remove_reviews_for_log(data):
    """ë¦¬ë·° ë°ì´í„°ë¥¼ ì œê±°í•œ ìš”ì•½ ë²„ì „ ìƒì„± (ë¡œê·¸ ì¶œë ¥ìš©)"""
    import copy
    summary = copy.deepcopy(data)
    
    # 29cm_best ì„¹ì…˜ì˜ ë¦¬ë·° ì œê±°
    if "facts" in summary and "29cm_best" in summary["facts"]:
        cm_best = summary["facts"]["29cm_best"]
        if cm_best and "items" in cm_best:
            for item in cm_best["items"]:
                if "reviews" in item:
                    # ë¦¬ë·° ê°œìˆ˜ë§Œ í‘œì‹œ
                    review_count = len(item["reviews"]) if item["reviews"] else 0
                    item["reviews"] = f"[{review_count}ê°œ ë¦¬ë·° - ìƒì„¸ ë‚´ìš©ì€ JSON íŒŒì¼ ì°¸ì¡°]"
    
    return summary


def load_snapshot_from_gcs(company_name: str, year: int, month: int):
    """GCS ë²„í‚·ì—ì„œ ìŠ¤ëƒ…ìƒ· JSON íŒŒì¼ ì½ê¸° (Gzip ì••ì¶• í•´ì œ ì§€ì›)"""
    try:
        bucket = storage_client.bucket(GCS_BUCKET)
        
        # ê²½ë¡œ ì‹œë„: ë¨¼ì € .gz íŒŒì¼, ì—†ìœ¼ë©´ .json íŒŒì¼
        blob_paths = [
            f"ai-reports/monthly/{company_name}/{year}-{month:02d}/snapshot.json.gz",  # ì••ì¶• íŒŒì¼ ìš°ì„ 
            f"ai-reports/monthly/{company_name.lower()}/{year}-{month:02d}/snapshot.json.gz",  # ì†Œë¬¸ì ë³€í™˜
            f"ai-reports/monthly/{company_name}/{year}-{month:02d}/snapshot.json",  # ì••ì¶• ì—†ëŠ” íŒŒì¼ (í•˜ìœ„ í˜¸í™˜)
            f"ai-reports/monthly/{company_name.lower()}/{year}-{month:02d}/snapshot.json",  # ì†Œë¬¸ì ë³€í™˜
        ]
        
        blob = None
        found_path = None
        is_gzip = False
        
        for blob_path in blob_paths:
            test_blob = bucket.blob(blob_path)
            if test_blob.exists():
                blob = test_blob
                found_path = blob_path
                is_gzip = blob_path.endswith('.gz')
                break
        
        if not blob:
            if ENABLE_DEBUG_LOGS:
                print(f"âš ï¸ [WARN] GCSì— ìŠ¤ëƒ…ìƒ· íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ì‹œë„í•œ ê²½ë¡œ: {', '.join(blob_paths)}", file=sys.stderr)
            return None
        
        # íŒŒì¼ ì½ê¸° (Gzip ì••ì¶• ì—¬ë¶€ì— ë”°ë¼ ì²˜ë¦¬)
        if is_gzip:
            # Gzip ì••ì¶•ëœ íŒŒì¼ ì½ê¸°
            snapshot_gzip_bytes = blob.download_as_bytes()
            snapshot_json_str = gzip.decompress(snapshot_gzip_bytes).decode('utf-8')
        else:
            # ì••ì¶• ì—†ëŠ” íŒŒì¼ ì½ê¸° (í•˜ìœ„ í˜¸í™˜)
            snapshot_json_str = blob.download_as_text(encoding='utf-8')
        
        snapshot_data = json.loads(snapshot_json_str)
        
        gcs_url = f"gs://{GCS_BUCKET}/{found_path}"
        print(f"âœ… [SUCCESS] GCSì—ì„œ ìŠ¤ëƒ…ìƒ·ì„ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤: {gcs_url} ({'Gzip ì••ì¶•' if is_gzip else 'ì••ì¶• ì—†ìŒ'})", file=sys.stderr)
        return snapshot_data
    except Exception as e:
        print("=" * 80, file=sys.stderr)
        print(f"âŒ [ERROR] GCSì—ì„œ ìŠ¤ëƒ…ìƒ· ì½ê¸° ì‹¤íŒ¨", file=sys.stderr)
        print(f"   ì˜¤ë¥˜ ë©”ì‹œì§€: {e}", file=sys.stderr)
        print("=" * 80, file=sys.stderr)
        import traceback
        traceback.print_exc(file=sys.stderr)
        return None


def run(company_name: str, year: int, month: int, upsert_flag: bool = False, save_to_gcs_flag: bool = False, load_from_gcs_flag: bool = True):
    """
    Args:
        company_name: íšŒì‚¬ëª…
        year: ì—°ë„
        month: ì›”
        upsert_flag: BigQueryì— upsertí• ì§€ ì—¬ë¶€
        save_to_gcs_flag: GCSì— ì €ì¥í• ì§€ ì—¬ë¶€
        load_from_gcs_flag: GCSì—ì„œ ë¨¼ì € ì½ì„ì§€ ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
    """
    # -----------------------
    # GCSì—ì„œ ìŠ¤ëƒ…ìƒ· ì½ê¸° (ìš°ì„ )
    # -----------------------
    if load_from_gcs_flag:
        snapshot_from_gcs = load_snapshot_from_gcs(company_name, year, month)
        if snapshot_from_gcs:
            print(f"âœ… [SUCCESS] GCSì—ì„œ ìŠ¤ëƒ…ìƒ·ì„ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤. (BigQuery ì¡°íšŒ ìŠ¤í‚µ)", file=sys.stderr)
            # ìˆ˜ì§‘ ë°ì´í„°ëŠ” ì½˜ì†”ì— ì¶œë ¥í•˜ì§€ ì•ŠìŒ (JSON íŒŒì¼ì—ë§Œ ì €ì¥)
            # ì „ì²´ JSONì´ í•„ìš”í•˜ë©´ GCSì—ì„œ ì§ì ‘ ë‹¤ìš´ë¡œë“œ: gs://{GCS_BUCKET}/ai-reports/monthly/{company_name}/{year}-{month:02d}/snapshot.json.gz
            return
    
    # -----------------------
    # BigQueryì—ì„œ ë°ì´í„° ì¡°íšŒ (GCSì— ì—†ì„ ë•Œë§Œ)
    # -----------------------
    # ì „ì—­ bq_client ì‚¬ìš© (ì¬ì‚¬ìš©)
    client = bq_client
    
    report_month = month_to_ym(year, month)
    this_start, this_end = month_range(year, month)
    
    if month == 1:
        prev_y, prev_m = year - 1, 12
    else:
        prev_y, prev_m = year, month - 1
    prev_start, prev_end = month_range(prev_y, prev_m)
    prev_month = month_to_ym(prev_y, prev_m)
    
    yoy_y, yoy_m = year - 1, month
    yoy_start, yoy_end = month_range(yoy_y, yoy_m)
    yoy_month = month_to_ym(yoy_y, yoy_m)
    
    # -----------------------
    # Mall sales
    # -----------------------
    q_sales = f"""
    SELECT
        SUM(net_sales) AS net_sales,
        SUM(total_orders) AS total_orders,
        SUM(total_first_order) AS total_first_order,
        SUM(total_canceled) AS total_canceled
    FROM `{PROJECT_ID}.{DATASET}.daily_cafe24_sales`
    WHERE company_name = @company_name
      AND payment_date BETWEEN @start_date AND @end_date
    """
    
    def get_sales(s, e):
        rows = list(
            client.query(
                q_sales,
                job_config=bigquery.QueryJobConfig(
                    query_parameters=[
                        bigquery.ScalarQueryParameter("company_name", "STRING", company_name),
                        bigquery.ScalarQueryParameter("start_date", "DATE", s),
                        bigquery.ScalarQueryParameter("end_date", "DATE", e),
                    ]
                ),
            ).result()
        )
        
        if not rows:
            return {
                "net_sales": 0.0,
                "total_orders": 0,
                "total_first_order": 0,
                "total_canceled": 0,
            }
        
        row = rows[0]
        return {
            "net_sales": float(row.net_sales or 0),
            "total_orders": int(row.total_orders or 0),
            "total_first_order": int(row.total_first_order or 0),
            "total_canceled": int(row.total_canceled or 0),
        }
    
    # âœ… ìµœì í™” 1ë‹¨ê³„: ì›”ê°„ ì§‘ê³„ í…Œì´ë¸”ì—ì„œ this/prev/yoy ì¶”ì¶œ (raw í…Œì´ë¸” ì¡°íšŒ ì œê±°)
    # ì›”ê°„ ì§‘ê³„ í…Œì´ë¸” ì‚¬ìš© (ì„±ëŠ¥ ìµœì í™”) - ë¨¼ì € ì¡°íšŒ
    monthly_13m_raw = query_monthly_13m_from_monthly_table(
        client,
        f"{PROJECT_ID}.{DATASET}.mall_sales_monthly",
        company_name,
        report_month,
        """
        SUM(net_sales) AS net_sales,
        SUM(total_orders) AS total_orders,
        SUM(total_first_order) AS total_first_order,
        SUM(total_canceled) AS total_canceled
        """
    )
    
    monthly_13m = [
        {"ym": ym, **metrics}
        for ym, metrics in sorted(monthly_13m_raw.items())
    ]
    
    # monthly_13mì—ì„œ this/prev/yoy ì¶”ì¶œ
    def get_monthly_data_from_13m(monthly_list, target_ym):
        """monthly_13m ë¦¬ìŠ¤íŠ¸ì—ì„œ íŠ¹ì • ì›” ë°ì´í„° ì¶”ì¶œ. ì—†ìœ¼ë©´ None ë°˜í™˜"""
        for item in monthly_list:
            if item.get("ym") == target_ym:
                return item
        # ë°ì´í„°ê°€ ì—†ìœ¼ë©´ None ë°˜í™˜ (ì‹¤ì œ ìˆ˜ì§‘ë˜ì§€ ì•Šì€ ê²½ìš°)
        return None
    
    sales_this_data = get_monthly_data_from_13m(monthly_13m, report_month)
    sales_prev_data = get_monthly_data_from_13m(monthly_13m, prev_month)
    sales_yoy_data = get_monthly_data_from_13m(monthly_13m, yoy_month)
    
    # ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ None (ì‹¤ì œ ìˆ˜ì§‘ë˜ì§€ ì•Šì€ ê²½ìš°)
    sales_this = {
        "net_sales": float(sales_this_data.get("net_sales", 0)) if sales_this_data else None,
        "total_orders": int(sales_this_data.get("total_orders", 0)) if sales_this_data else None,
        "total_first_order": int(sales_this_data.get("total_first_order", 0)) if sales_this_data else None,
        "total_canceled": int(sales_this_data.get("total_canceled", 0)) if sales_this_data else None,
    } if sales_this_data else None
    
    sales_prev = {
        "net_sales": float(sales_prev_data.get("net_sales", 0)) if sales_prev_data else None,
        "total_orders": int(sales_prev_data.get("total_orders", 0)) if sales_prev_data else None,
        "total_first_order": int(sales_prev_data.get("total_first_order", 0)) if sales_prev_data else None,
        "total_canceled": int(sales_prev_data.get("total_canceled", 0)) if sales_prev_data else None,
    } if sales_prev_data else None
    
    sales_yoy = {
        "net_sales": float(sales_yoy_data.get("net_sales", 0)) if sales_yoy_data else None,
        "total_orders": int(sales_yoy_data.get("total_orders", 0)) if sales_yoy_data else None,
        "total_first_order": int(sales_yoy_data.get("total_first_order", 0)) if sales_yoy_data else None,
        "total_canceled": int(sales_yoy_data.get("total_canceled", 0)) if sales_yoy_data else None,
    } if sales_yoy_data else None
    
    # âœ… ìµœì í™”: ì¼ìë³„ ì„±ê³¼ ë°ì´í„°ë¥¼ í•œ ë²ˆì— ì¡°íšŒ í›„ Pythonì—ì„œ ë¶„í•´
    def get_sales_daily_multi(ranges):
        """this/prev/yoyë¥¼ í•œ ë²ˆì— ì¡°íšŒ í›„ Pythonì—ì„œ ë¶„í•´"""
        # ì „ì²´ ê¸°ê°„(this/prev/yoy) ìµœì†Œ~ìµœëŒ€ ë‚ ì§œ ê³„ì‚°
        all_dates = []
        for key, (s, e) in ranges.items():
            if s and e:
                all_dates.extend([s, e])
        
        if not all_dates:
            return {"this": [], "prev": [], "yoy": []}
        
        min_date = min(all_dates)
        max_date = max(all_dates)
        
        # ì „ì²´ ê¸°ê°„ì„ í•œ ë²ˆì— ì¡°íšŒ
        q_sales_daily_multi = f"""
        SELECT
            payment_date AS date,
            SUM(net_sales) AS net_sales,
            SUM(total_orders) AS total_orders,
            SUM(total_first_order) AS total_first_order,
            SUM(total_canceled) AS total_canceled
        FROM `{PROJECT_ID}.{DATASET}.daily_cafe24_sales`
        WHERE company_name = @company_name
          AND payment_date >= @min_date
          AND payment_date <= @max_date
        GROUP BY payment_date
        ORDER BY payment_date
        """
        
        rows = list(
            client.query(
                q_sales_daily_multi,
                job_config=bigquery.QueryJobConfig(
                    query_parameters=[
                        bigquery.ScalarQueryParameter("company_name", "STRING", company_name),
                        bigquery.ScalarQueryParameter("min_date", "DATE", min_date),
                        bigquery.ScalarQueryParameter("max_date", "DATE", max_date),
                    ]
                ),
            ).result()
        )
        
        # ê° ê¸°ê°„ë³„ë¡œ ë¶„ë¥˜
        result = {"this": [], "prev": [], "yoy": []}
        for row in rows:
            row_date = row.date
            if not row_date:
                continue
            
            row_data = {
                "date": row_date.isoformat(),
                "net_sales": float(row.net_sales or 0),
                "total_orders": int(row.total_orders or 0),
                "total_first_order": int(row.total_first_order or 0),
                "total_canceled": int(row.total_canceled or 0),
            }
            
            # ê° ê¸°ê°„ì— ì†í•˜ëŠ”ì§€ í™•ì¸
            for period_key, (period_start, period_end) in ranges.items():
                if period_start and period_end:
                    period_start_date = date.fromisoformat(period_start)
                    period_end_date = date.fromisoformat(period_end)
                    if period_start_date <= row_date <= period_end_date:
                        result[period_key].append(row_data)
                        break
        
        return result
    
    daily_ranges = {
        "this": (this_start, this_end),
        "prev": (prev_start, prev_end),
        "yoy": (yoy_start, yoy_end),
    }
    
    # âœ… ìµœì í™”: BigQuery ë³‘ë ¬ ì‹¤í–‰ (í•µì‹¬ ìµœì í™”)
    # daily_multiëŠ” ì—¬ê¸°ì„œ ì‹¤í–‰í•˜ì§€ ì•Šê³  ë³‘ë ¬ ë¸”ë¡ì—ì„œ ì‹¤í–‰
    
    # -----------------------
    # Meta ads
    # -----------------------
    q_meta_ads = f"""
    SELECT
        SUM(spend) AS spend,
        SUM(impressions) AS impressions,
        SUM(clicks) AS clicks,
        SUM(purchases) AS purchases,
        SUM(purchase_value) AS purchase_value
    FROM `{PROJECT_ID}.{DATASET}.meta_ads_account_summary`
    WHERE company_name = @company_name
      AND date BETWEEN @start_date AND @end_date
    """
    
    def get_meta_ads(s, e):
        rows = list(
            client.query(
                q_meta_ads,
                job_config=bigquery.QueryJobConfig(
                    query_parameters=[
                        bigquery.ScalarQueryParameter("company_name", "STRING", company_name),
                        bigquery.ScalarQueryParameter("start_date", "DATE", s),
                        bigquery.ScalarQueryParameter("end_date", "DATE", e),
                    ]
                ),
            ).result()
        )
        
        if not rows:
            return {
                "spend": 0.0,
                "impressions": 0,
                "clicks": 0,
                "purchases": 0,
                "purchase_value": 0.0,
                "roas": None,
                "cpc": None,
                "ctr": None,
                "cvr": None,
            }
        
        row = rows[0]
        spend = float(row.spend or 0)
        impressions = int(row.impressions or 0)
        clicks = int(row.clicks or 0)
        purchases = int(row.purchases or 0)
        purchase_value = float(row.purchase_value or 0)
        
        return {
            "spend": spend,
            "impressions": impressions,
            "clicks": clicks,
            "purchases": purchases,
            "purchase_value": purchase_value,
            "roas": (purchase_value / spend * 100) if spend > 0 else None,
            "cpc": (spend / clicks) if clicks > 0 else None,
            "ctr": (clicks / impressions * 100) if impressions > 0 else None,
            "cvr": (purchases / clicks * 100) if clicks > 0 else None,
        }
    
    # âœ… ìµœì í™” 1ë‹¨ê³„: ì›”ê°„ ì§‘ê³„ í…Œì´ë¸”ì—ì„œ this/prev/yoy ì¶”ì¶œ (raw í…Œì´ë¸” ì¡°íšŒ ì œê±°)
    # ì›”ê°„ ì§‘ê³„ í…Œì´ë¸” ì‚¬ìš© (ì„±ëŠ¥ ìµœì í™”) - ë¨¼ì € ì¡°íšŒ
    monthly_13m_meta_raw = query_monthly_13m_from_monthly_table(
        client,
        f"{PROJECT_ID}.{DATASET}.meta_ads_monthly",
        company_name,
        report_month,
        """
        SUM(spend) AS spend,
        SUM(impressions) AS impressions,
        SUM(clicks) AS clicks,
        SUM(purchases) AS purchases,
        SUM(purchase_value) AS purchase_value
        """
    )
    
    monthly_13m_meta = []
    for ym, metrics in sorted(monthly_13m_meta_raw.items()):
        spend = metrics.get("spend", 0)
        impressions = metrics.get("impressions", 0)
        clicks = metrics.get("clicks", 0)
        purchases = metrics.get("purchases", 0)
        purchase_value = metrics.get("purchase_value", 0)
        
        monthly_13m_meta.append({
            "ym": ym,
            "spend": spend,
            "impressions": impressions,
            "clicks": clicks,
            "purchases": purchases,
            "purchase_value": purchase_value,
            "roas": (purchase_value / spend * 100) if spend > 0 else None,
            "cpc": (spend / clicks) if clicks > 0 else None,
            "ctr": (clicks / impressions * 100) if impressions > 0 else None,
            "cvr": (purchases / clicks * 100) if clicks > 0 else None,
        })
    
    # monthly_13m_metaì—ì„œ this/prev/yoy ì¶”ì¶œ
    def get_monthly_meta_from_13m(monthly_list, target_ym):
        """monthly_13m_meta ë¦¬ìŠ¤íŠ¸ì—ì„œ íŠ¹ì • ì›” ë°ì´í„° ì¶”ì¶œ. ì—†ìœ¼ë©´ None ë°˜í™˜"""
        for item in monthly_list:
            if item.get("ym") == target_ym:
                return item
        # ë°ì´í„°ê°€ ì—†ìœ¼ë©´ None ë°˜í™˜ (ì‹¤ì œ ìˆ˜ì§‘ë˜ì§€ ì•Šì€ ê²½ìš°)
        return None
    
    meta_ads_this_data = get_monthly_meta_from_13m(monthly_13m_meta, report_month)
    meta_ads_prev_data = get_monthly_meta_from_13m(monthly_13m_meta, prev_month)
    meta_ads_yoy_data = get_monthly_meta_from_13m(monthly_13m_meta, yoy_month)
    
    # ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ None (ì‹¤ì œ ìˆ˜ì§‘ë˜ì§€ ì•Šì€ ê²½ìš°)
    meta_ads_this = {
        "spend": float(meta_ads_this_data.get("spend", 0)) if meta_ads_this_data else None,
        "impressions": int(meta_ads_this_data.get("impressions", 0)) if meta_ads_this_data else None,
        "clicks": int(meta_ads_this_data.get("clicks", 0)) if meta_ads_this_data else None,
        "purchases": int(meta_ads_this_data.get("purchases", 0)) if meta_ads_this_data else None,
        "purchase_value": float(meta_ads_this_data.get("purchase_value", 0)) if meta_ads_this_data else None,
        "roas": meta_ads_this_data.get("roas") if meta_ads_this_data else None,
        "cpc": meta_ads_this_data.get("cpc") if meta_ads_this_data else None,
        "ctr": meta_ads_this_data.get("ctr") if meta_ads_this_data else None,
        "cvr": meta_ads_this_data.get("cvr") if meta_ads_this_data else None,
    } if meta_ads_this_data else None
    
    meta_ads_prev = {
        "spend": float(meta_ads_prev_data.get("spend", 0)) if meta_ads_prev_data else None,
        "impressions": int(meta_ads_prev_data.get("impressions", 0)) if meta_ads_prev_data else None,
        "clicks": int(meta_ads_prev_data.get("clicks", 0)) if meta_ads_prev_data else None,
        "purchases": int(meta_ads_prev_data.get("purchases", 0)) if meta_ads_prev_data else None,
        "purchase_value": float(meta_ads_prev_data.get("purchase_value", 0)) if meta_ads_prev_data else None,
        "roas": meta_ads_prev_data.get("roas") if meta_ads_prev_data else None,
        "cpc": meta_ads_prev_data.get("cpc") if meta_ads_prev_data else None,
        "ctr": meta_ads_prev_data.get("ctr") if meta_ads_prev_data else None,
        "cvr": meta_ads_prev_data.get("cvr") if meta_ads_prev_data else None,
    } if meta_ads_prev_data else None
    
    meta_ads_yoy = {
        "spend": float(meta_ads_yoy_data.get("spend", 0)) if meta_ads_yoy_data else None,
        "impressions": int(meta_ads_yoy_data.get("impressions", 0)) if meta_ads_yoy_data else None,
        "clicks": int(meta_ads_yoy_data.get("clicks", 0)) if meta_ads_yoy_data else None,
        "purchases": int(meta_ads_yoy_data.get("purchases", 0)) if meta_ads_yoy_data else None,
        "purchase_value": float(meta_ads_yoy_data.get("purchase_value", 0)) if meta_ads_yoy_data else None,
        "roas": meta_ads_yoy_data.get("roas") if meta_ads_yoy_data else None,
        "cpc": meta_ads_yoy_data.get("cpc") if meta_ads_yoy_data else None,
        "ctr": meta_ads_yoy_data.get("ctr") if meta_ads_yoy_data else None,
        "cvr": meta_ads_yoy_data.get("cvr") if meta_ads_yoy_data else None,
    } if meta_ads_yoy_data else None
    
    # -----------------------
    # Meta Ads Goals (ëª©í‘œë³„ ë¶„í•´ ë° Top Ad)
    # -----------------------
    def get_meta_ads_goals(s, e):
        """ëª©í‘œë³„ ë¶„í•´ ë° Top Ad ì¡°íšŒ (ë‹¨ì¼ ê¸°ê°„)"""
        if SKIP_META_ADS_GOALS:
            return {
                "by_goal": {
                    "conversion": {"spend": 0.0, "impressions": 0, "clicks": 0, "purchases": 0, "purchase_value": 0.0, "roas": None, "cpc": None, "ctr": None, "cvr": None, "spend_share_pct": None},
                    "traffic": {"spend": 0.0, "impressions": 0, "clicks": 0, "purchases": 0, "purchase_value": 0.0, "roas": None, "cpc": None, "ctr": None, "cvr": None, "spend_share_pct": None},
                    "awareness": {"spend": 0.0, "impressions": 0, "clicks": 0, "purchases": 0, "purchase_value": 0.0, "roas": None, "cpc": None, "ctr": None, "cvr": None, "spend_share_pct": None},
                    "unknown": {"spend": 0.0, "impressions": 0, "clicks": 0, "purchases": 0, "purchase_value": 0.0, "roas": None, "cpc": None, "ctr": None, "cvr": None, "spend_share_pct": None},
                },
                "top_ads": {
                    "conversion_top_by_purchases": [],
                    "traffic_top_by_ctr": [],
                    "awareness_top_by_spend": [],
                }
            }
        
        q_meta_ads_goals = f"""
        SELECT
            ad_id,
            ad_name,
            campaign_name,
            SUM(spend) AS spend,
            SUM(impressions) AS impressions,
            SUM(clicks) AS clicks,
            SUM(purchases) AS purchases,
            SUM(purchase_value) AS purchase_value
        FROM `{PROJECT_ID}.{DATASET}.meta_ads_ad_summary`
        WHERE company_name = @company_name
          AND date BETWEEN @start_date AND @end_date
        GROUP BY ad_id, ad_name, campaign_name
        """
        
        rows = list(
            client.query(
                q_meta_ads_goals,
                job_config=bigquery.QueryJobConfig(
                    query_parameters=[
                        bigquery.ScalarQueryParameter("company_name", "STRING", company_name),
                        bigquery.ScalarQueryParameter("start_date", "DATE", s),
                        bigquery.ScalarQueryParameter("end_date", "DATE", e),
                    ]
                ),
            ).result()
        )
        
        # ëª©í‘œë³„ ì§‘ê³„
        by_goal = defaultdict(lambda: {
            "spend": 0.0,
            "impressions": 0,
            "clicks": 0,
            "purchases": 0,
            "purchase_value": 0.0,
        })
        
        # Top Ad í›„ë³´
        conversion_ads = []
        traffic_ads = []
        awareness_ads = []
        
        total_spend = 0.0
        
        for row in rows:
            goal = _goal_from_campaign_name(row.campaign_name or "")
            spend = float(row.spend or 0)
            impressions = int(row.impressions or 0)
            clicks = int(row.clicks or 0)
            purchases = int(row.purchases or 0)
            purchase_value = float(row.purchase_value or 0)
            
            by_goal[goal]["spend"] += spend
            by_goal[goal]["impressions"] += impressions
            by_goal[goal]["clicks"] += clicks
            by_goal[goal]["purchases"] += purchases
            by_goal[goal]["purchase_value"] += purchase_value
            total_spend += spend
            
            # Top Ad í›„ë³´ ì¶”ê°€
            ad_data = {
                "ad_id": str(row.ad_id) if row.ad_id else None,
                "ad_name": row.ad_name or "",
                "campaign_name": row.campaign_name or "",
                "spend": spend,
                "impressions": impressions,
                "clicks": clicks,
                "purchases": purchases,
                "purchase_value": purchase_value,
            }
            
            if goal == "conversion":
                conversion_ads.append(ad_data)
            elif goal == "traffic":
                traffic_ads.append(ad_data)
            elif goal == "awareness":
                awareness_ads.append(ad_data)
        
        # ëª©í‘œë³„ ì§€í‘œ ê³„ì‚°
        result_by_goal = {}
        for goal in ["conversion", "traffic", "awareness", "unknown"]:
            data = by_goal[goal]
            spend = data["spend"]
            impressions = data["impressions"]
            clicks = data["clicks"]
            purchases = data["purchases"]
            purchase_value = data["purchase_value"]
            
            result_by_goal[goal] = {
                "spend": spend,
                "impressions": impressions,
                "clicks": clicks,
                "purchases": purchases,
                "purchase_value": purchase_value,
                "roas": (purchase_value / spend * 100) if spend > 0 else None,
                "cpc": (spend / clicks) if clicks > 0 else None,
                "ctr": (clicks / impressions * 100) if impressions > 0 else None,
                "cvr": (purchases / clicks * 100) if clicks > 0 else None,
                "spend_share_pct": (spend / total_spend * 100) if total_spend > 0 else None,
            }
        
        # Top Ad ì •ë ¬ ë° ì„ íƒ
        # ì „í™˜: purchases DESC (ë™ë¥ ì´ë©´ purchase_value DESC, spend DESC)
        conversion_ads.sort(key=lambda x: (-x["purchases"], -x["purchase_value"], -x["spend"]))
        conversion_top = []
        for ad in conversion_ads[:TOP_LIMIT]:
            ad_spend = ad["spend"]
            ad_clicks = ad["clicks"]
            ad_purchases = ad["purchases"]
            ad_purchase_value = ad["purchase_value"]
            conversion_top.append({
                "ad_id": ad["ad_id"],
                "ad_name": ad["ad_name"],
                "campaign_name": ad["campaign_name"],
                "spend": ad_spend,
                "purchases": ad_purchases,
                "purchase_value": ad_purchase_value,
                "roas": (ad_purchase_value / ad_spend * 100) if ad_spend > 0 else None,
                "cpa": (ad_spend / ad_purchases) if ad_purchases > 0 else None,
                "cvr": (ad_purchases / ad_clicks * 100) if ad_clicks > 0 else None,
                "clicks": ad["clicks"],
                "impressions": ad["impressions"],
            })
        
        # ìœ ì…: CTR DESC (ë‹¨ spend >= TRAFFIC_TOP_MIN_SPEND, ë™ë¥ ì´ë©´ clicks DESC)
        traffic_ads_filtered = [ad for ad in traffic_ads if ad["spend"] >= TRAFFIC_TOP_MIN_SPEND]
        for ad in traffic_ads_filtered:
            ad["ctr"] = (ad["clicks"] / ad["impressions"] * 100) if ad["impressions"] > 0 else 0
            ad["cpc"] = (ad["spend"] / ad["clicks"]) if ad["clicks"] > 0 else None
        traffic_ads_filtered.sort(key=lambda x: (-x["ctr"], -x["clicks"]))
        traffic_top = []
        for ad in traffic_ads_filtered[:TOP_LIMIT]:
            traffic_top.append({
                "ad_id": ad["ad_id"],
                "ad_name": ad["ad_name"],
                "campaign_name": ad["campaign_name"],
                "spend": ad["spend"],
                "ctr": round(ad["ctr"], 2),
                "cpc": round(ad["cpc"], 2) if ad["cpc"] is not None else None,
                "clicks": ad["clicks"],
                "impressions": ad["impressions"],
            })
        
        # ë„ë‹¬: spend DESC
        awareness_ads.sort(key=lambda x: -x["spend"])
        awareness_top = []
        for ad in awareness_ads[:TOP_LIMIT]:
            ad_spend = ad["spend"]
            ad_impressions = ad["impressions"]
            awareness_top.append({
                "ad_id": ad["ad_id"],
                "ad_name": ad["ad_name"],
                "campaign_name": ad["campaign_name"],
                "spend": ad_spend,
                "impressions": ad_impressions,
                "cpm": (ad_spend / ad_impressions * 1000) if ad_impressions > 0 else None,
            })
        
        return {
            "by_goal": result_by_goal,
            "top_ads": {
                "conversion_top_by_purchases": conversion_top,
                "traffic_top_by_ctr": traffic_top,
                "awareness_top_by_spend": awareness_top,
            }
        }
    
    def get_meta_ads_goals_multi(ranges):
        """âœ… ìµœì í™”: this/prev/yoyë¥¼ í•œ ë²ˆì— ì¡°íšŒ í›„ Pythonì—ì„œ ë¶„í•´
        âš ï¸ ì›”ê°„ ë¦¬í¬íŠ¸ ì „ìš©: period ë¶„ë¦¬ëŠ” ym(YYYY-MM) ê¸°ì¤€ìœ¼ë¡œë§Œ ìˆ˜í–‰.
        ranges: {"this": (start, end), "prev": (start, end), "yoy": (start, end)} í˜•íƒœ
        """
        if SKIP_META_ADS_GOALS:
            empty_result = {
                "by_goal": {
                    "conversion": {"spend": 0.0, "impressions": 0, "clicks": 0, "purchases": 0, "purchase_value": 0.0, "roas": None, "cpc": None, "ctr": None, "cvr": None, "spend_share_pct": None},
                    "traffic": {"spend": 0.0, "impressions": 0, "clicks": 0, "purchases": 0, "purchase_value": 0.0, "roas": None, "cpc": None, "ctr": None, "cvr": None, "spend_share_pct": None},
                    "awareness": {"spend": 0.0, "impressions": 0, "clicks": 0, "purchases": 0, "purchase_value": 0.0, "roas": None, "cpc": None, "ctr": None, "cvr": None, "spend_share_pct": None},
                    "unknown": {"spend": 0.0, "impressions": 0, "clicks": 0, "purchases": 0, "purchase_value": 0.0, "roas": None, "cpc": None, "ctr": None, "cvr": None, "spend_share_pct": None},
                },
                "top_ads": {
                    "conversion_top_by_purchases": [],
                    "traffic_top_by_ctr": [],
                    "awareness_top_by_spend": [],
                }
            }
            return {
                "this": empty_result,
                "prev": empty_result,
                "yoy": empty_result if "yoy" in ranges else None
            }
        
        # ì „ì²´ ê¸°ê°„(this/prev/yoy) ìµœì†Œ~ìµœëŒ€ ë‚ ì§œ ê³„ì‚°
        all_dates = []
        for key, (s, e) in ranges.items():
            if s and e:
                all_dates.extend([s, e])
        
        if not all_dates:
            return {"this": None, "prev": None, "yoy": None}
        
        min_date = min(all_dates)
        max_date = max(all_dates)
        
        # ì „ì²´ ê¸°ê°„ì„ í•œ ë²ˆì— ì¡°íšŒ
        q_meta_ads_goals_multi = f"""
        SELECT
            FORMAT_DATE('%Y-%m', date) AS ym,
            ad_id,
            ad_name,
            campaign_name,
            SUM(spend) AS spend,
            SUM(impressions) AS impressions,
            SUM(clicks) AS clicks,
            SUM(purchases) AS purchases,
            SUM(purchase_value) AS purchase_value
        FROM `{PROJECT_ID}.{DATASET}.meta_ads_ad_summary`
        WHERE company_name = @company_name
          AND date >= @min_date
          AND date <= @max_date
        GROUP BY ym, ad_id, ad_name, campaign_name
        """
        
        rows = list(
            client.query(
                q_meta_ads_goals_multi,
                job_config=bigquery.QueryJobConfig(
                    query_parameters=[
                        bigquery.ScalarQueryParameter("company_name", "STRING", company_name),
                        bigquery.ScalarQueryParameter("min_date", "DATE", min_date),
                        bigquery.ScalarQueryParameter("max_date", "DATE", max_date),
                    ]
                ),
            ).result()
        )
        
        # ê° ê¸°ê°„ë³„ë¡œ ë¶„ë¥˜ (ì›”(ym) ê¸°ì¤€)
        period_ym_map = {}
        for period_key, (period_start, _period_end) in ranges.items():
            if period_start and isinstance(period_start, str) and len(period_start) >= 7:
                period_ym_map[period_key] = period_start[:7]  # "YYYY-MM"
        
        rows_by_period = defaultdict(list)
        for row in rows:
            row_ym = row.ym  # "YYYY-MM"
            for period_key, target_ym in period_ym_map.items():
                if row_ym == target_ym:
                    rows_by_period[period_key].append(row)
                    break
        
        # ê° ê¸°ê°„ë³„ë¡œ get_meta_ads_goalsì™€ ë™ì¼í•œ ë¡œì§ ì ìš©
        result = {}
        for period_key in ["this", "prev", "yoy"]:
            if period_key not in ranges or not ranges[period_key][0]:
                result[period_key] = None
                continue
            
            period_rows = rows_by_period.get(period_key, [])
            if not period_rows:
                result[period_key] = None
                continue
            
            # ëª©í‘œë³„ ì§‘ê³„
            by_goal = defaultdict(lambda: {
                "spend": 0.0,
                "impressions": 0,
                "clicks": 0,
                "purchases": 0,
                "purchase_value": 0.0,
            })
            
            # Top Ad í›„ë³´
            conversion_ads = []
            traffic_ads = []
            awareness_ads = []
            
            total_spend = 0.0
            
            for row in period_rows:
                goal = _goal_from_campaign_name(row.campaign_name or "")
                spend = float(row.spend or 0)
                impressions = int(row.impressions or 0)
                clicks = int(row.clicks or 0)
                purchases = int(row.purchases or 0)
                purchase_value = float(row.purchase_value or 0)
                
                by_goal[goal]["spend"] += spend
                by_goal[goal]["impressions"] += impressions
                by_goal[goal]["clicks"] += clicks
                by_goal[goal]["purchases"] += purchases
                by_goal[goal]["purchase_value"] += purchase_value
                total_spend += spend
                
                # Top Ad í›„ë³´ ì¶”ê°€
                ad_data = {
                    "ad_id": str(row.ad_id) if row.ad_id else None,
                    "ad_name": row.ad_name or "",
                    "campaign_name": row.campaign_name or "",
                    "spend": spend,
                    "impressions": impressions,
                    "clicks": clicks,
                    "purchases": purchases,
                    "purchase_value": purchase_value,
                }
                
                if goal == "conversion":
                    conversion_ads.append(ad_data)
                elif goal == "traffic":
                    traffic_ads.append(ad_data)
                elif goal == "awareness":
                    awareness_ads.append(ad_data)
            
            # ëª©í‘œë³„ ì§€í‘œ ê³„ì‚°
            result_by_goal = {}
            for goal in ["conversion", "traffic", "awareness", "unknown"]:
                data = by_goal[goal]
                spend = data["spend"]
                impressions = data["impressions"]
                clicks = data["clicks"]
                purchases = data["purchases"]
                purchase_value = data["purchase_value"]
                
                result_by_goal[goal] = {
                    "spend": spend,
                    "impressions": impressions,
                    "clicks": clicks,
                    "purchases": purchases,
                    "purchase_value": purchase_value,
                    "roas": (purchase_value / spend * 100) if spend > 0 else None,
                    "cpc": (spend / clicks) if clicks > 0 else None,
                    "ctr": (clicks / impressions * 100) if impressions > 0 else None,
                    "cvr": (purchases / clicks * 100) if clicks > 0 else None,
                    "spend_share_pct": (spend / total_spend * 100) if total_spend > 0 else None,
                }
            
            # Top Ad ì •ë ¬ ë° ì„ íƒ
            conversion_ads.sort(key=lambda x: (-x["purchases"], -x["purchase_value"], -x["spend"]))
            conversion_top = []
            for ad in conversion_ads[:TOP_LIMIT]:
                ad_spend = ad["spend"]
                ad_clicks = ad["clicks"]
                ad_purchases = ad["purchases"]
                ad_purchase_value = ad["purchase_value"]
                conversion_top.append({
                    "ad_id": ad["ad_id"],
                    "ad_name": ad["ad_name"],
                    "campaign_name": ad["campaign_name"],
                    "spend": ad_spend,
                    "purchases": ad_purchases,
                    "purchase_value": ad_purchase_value,
                    "roas": (ad_purchase_value / ad_spend * 100) if ad_spend > 0 else None,
                    "cpa": (ad_spend / ad_purchases) if ad_purchases > 0 else None,
                    "cvr": (ad_purchases / ad_clicks * 100) if ad_clicks > 0 else None,
                    "clicks": ad["clicks"],
                    "impressions": ad["impressions"],
                })
            
            traffic_ads_filtered = [ad for ad in traffic_ads if ad["spend"] >= TRAFFIC_TOP_MIN_SPEND]
            for ad in traffic_ads_filtered:
                ad["ctr"] = (ad["clicks"] / ad["impressions"] * 100) if ad["impressions"] > 0 else 0
                ad["cpc"] = (ad["spend"] / ad["clicks"]) if ad["clicks"] > 0 else None
            traffic_ads_filtered.sort(key=lambda x: (-x["ctr"], -x["clicks"]))
            traffic_top = []
            for ad in traffic_ads_filtered[:TOP_LIMIT]:
                traffic_top.append({
                    "ad_id": ad["ad_id"],
                    "ad_name": ad["ad_name"],
                    "campaign_name": ad["campaign_name"],
                    "spend": ad["spend"],
                    "ctr": round(ad["ctr"], 2),
                    "cpc": round(ad["cpc"], 2) if ad["cpc"] is not None else None,
                    "clicks": ad["clicks"],
                    "impressions": ad["impressions"],
                })
            
            awareness_ads.sort(key=lambda x: -x["spend"])
            awareness_top = []
            for ad in awareness_ads[:TOP_LIMIT]:
                ad_spend = ad["spend"]
                ad_impressions = ad["impressions"]
                awareness_top.append({
                    "ad_id": ad["ad_id"],
                    "ad_name": ad["ad_name"],
                    "campaign_name": ad["campaign_name"],
                    "spend": ad_spend,
                    "impressions": ad_impressions,
                    "cpm": (ad_spend / ad_impressions * 1000) if ad_impressions > 0 else None,
                })
            
            result[period_key] = {
                "by_goal": result_by_goal,
                "top_ads": {
                    "conversion_top_by_purchases": conversion_top,
                    "traffic_top_by_ctr": traffic_top,
                    "awareness_top_by_spend": awareness_top,
                }
            }
        
        return result
    
    # -----------------------
    # Meta Ads Goals (ëª©í‘œë³„ ë¶„í•´ ë° Top Ad) - SKIP_META_ADS_GOALS ì²´í¬
    # -----------------------
    # meta_ads_yoy_availableì€ comparisonsì—ì„œë„ ì‚¬ìš©ë˜ë¯€ë¡œ ë¨¼ì € ì´ˆê¸°í™”
    meta_ads_yoy_available = False
    # rangesë¥¼ ìƒìœ„ ìŠ¤ì½”í”„ì—ì„œ ì´ˆê¸°í™” (ë³‘ë ¬ ì‹¤í–‰ ë¸”ë¡ì—ì„œ ì ‘ê·¼í•˜ê¸° ìœ„í•´)
    ranges = None
    
    if SKIP_META_ADS_GOALS:
        meta_ads_goals_this = None
        meta_ads_goals_prev = None
        meta_ads_goals_yoy = None
        meta_ads_benchmarks = None
    else:
        # (B) YoY rows ì¡´ì¬ ì²´í¬
        q_meta_ads_exists = f"""
        SELECT COUNT(1) AS cnt
        FROM `{PROJECT_ID}.{DATASET}.meta_ads_account_summary`
        WHERE company_name = @company_name
          AND date BETWEEN @start_date AND @end_date
        """
        
        def has_meta_ads_rows(s, e):
            rows = list(
                client.query(
                    q_meta_ads_exists,
                    job_config=bigquery.QueryJobConfig(
                        query_parameters=[
                            bigquery.ScalarQueryParameter("company_name", "STRING", company_name),
                            bigquery.ScalarQueryParameter("start_date", "DATE", s),
                            bigquery.ScalarQueryParameter("end_date", "DATE", e),
                        ]
                    ),
                ).result()
            )
            if not rows:
                return False
            return int(rows[0].cnt or 0) > 0
        
        # ì›”ê°„ ì§‘ê³„(meta_ads_yoy_data)ê°€ ìˆìœ¼ë©´ ìš°ì„  true
        meta_ads_yoy_available = (meta_ads_yoy_data is not None)
        if not meta_ads_yoy_available:
            # ì›”ê°„ ì§‘ê³„ê°€ ë¹„ì–´ìˆì„ ë•Œë§Œ raw fallback
            meta_ads_yoy_available = has_meta_ads_rows(yoy_start, yoy_end)
        
        # âœ… ìµœì í™”: this/prev/yoyë¥¼ í•œ ë²ˆì— ì¡°íšŒ
        ranges = {
            "this": (this_start, this_end),
            "prev": (prev_start, prev_end),
            "yoy": (yoy_start, yoy_end) if meta_ads_yoy_available else None
        }
        if ranges["yoy"] is None:
            del ranges["yoy"]
        
        # goals_multiëŠ” ë³‘ë ¬ ì‹¤í–‰ ë¸”ë¡ì—ì„œ ì‹¤í–‰ (ga4_top_sources_ranges ì •ì˜ í›„)
        
        # -----------------------
        # Meta Ads Benchmarks (ìµœê·¼ 6ê°œì›” ê¸°ì¤€ì¹˜)
        # -----------------------
        def build_meta_ads_benchmarks_from_monthly_13m(monthly_13m_data):
            """ìµœê·¼ 6ê°œì›” ê¸°ì¤€ì¹˜ ê³„ì‚° (monthly_13m_meta ê¸°ë°˜, goalë³„ ë¶„í•´ëŠ” ad_summaryì—ì„œ)"""
            # âœ… ìµœì í™”: 6ê°œì›” ì „ì²´ë¥¼ í•œ ë²ˆì— ì¡°íšŒ í›„ Pythonì—ì„œ ì›”ë³„ ë¶„í•´
            # ìµœê·¼ 6ê°œì›” YM ëª©ë¡
            end_ym = report_month
            month_yms = [shift_month(end_ym, -i) for i in range(6)]
            
            # 6ê°œì›” ì „ì²´ ê¸°ê°„ ê³„ì‚°
            start_ym = shift_month(end_ym, -5)
            start_date_iso, _ = month_range_exclusive(start_ym)
            end_excl_iso, _ = month_range_exclusive(shift_month(end_ym, 1))
            
            # 6ê°œì›” ì „ì²´ë¥¼ í•œ ë²ˆì— ì¡°íšŒ
            q_6m_goals = f"""
            SELECT
                FORMAT_DATE('%Y-%m', date) AS ym,
                campaign_name,
                SUM(spend) AS spend,
                SUM(impressions) AS impressions,
                SUM(clicks) AS clicks,
                SUM(purchases) AS purchases,
                SUM(purchase_value) AS purchase_value
            FROM `{PROJECT_ID}.{DATASET}.meta_ads_ad_summary`
            WHERE company_name = @company_name
              AND date >= @start_date
              AND date < @end_exclusive_date
            GROUP BY ym, campaign_name
            """
            
            rows = list(
                client.query(
                    q_6m_goals,
                    job_config=bigquery.QueryJobConfig(
                        query_parameters=[
                            bigquery.ScalarQueryParameter("company_name", "STRING", company_name),
                            bigquery.ScalarQueryParameter("start_date", "DATE", start_date_iso),
                            bigquery.ScalarQueryParameter("end_exclusive_date", "DATE", end_excl_iso),
                        ]
                    ),
                ).result()
            )
            
            # ì›”ë³„ë¡œ ê·¸ë£¹í™”
            by_month = defaultdict(list)
            for r in rows:
                by_month[r.ym].append(r)
            
            # ê° ì›”ë³„ goal ì§‘ê³„
            traffic_cpcs = []
            traffic_ctrs = []
            conversion_cvrs = []
            conversion_cpas = []
            count_months = 0
            
            for ym in month_yms:
                month_rows = by_month.get(ym, [])
                if not month_rows:
                    continue
                
                count_months += 1
                
                # ëª©í‘œë³„ ì§‘ê³„
                traffic_data = {"spend": 0.0, "clicks": 0, "impressions": 0}
                conversion_data = {"spend": 0.0, "clicks": 0, "purchases": 0}
                
                for row in month_rows:
                    goal = _goal_from_campaign_name(row.campaign_name or "")
                    spend = float(row.spend or 0)
                    clicks = int(row.clicks or 0)
                    impressions = int(row.impressions or 0)
                    purchases = int(row.purchases or 0)
                    
                    if goal == "traffic":
                        traffic_data["spend"] += spend
                        traffic_data["clicks"] += clicks
                        traffic_data["impressions"] += impressions
                    elif goal == "conversion":
                        conversion_data["spend"] += spend
                        conversion_data["clicks"] += clicks
                        conversion_data["purchases"] += purchases
                
                # Traffic: CPC, CTR
                if traffic_data["clicks"] > 0:
                    cpc = traffic_data["spend"] / traffic_data["clicks"]
                    traffic_cpcs.append(cpc)
                if traffic_data["impressions"] > 0:
                    ctr = (traffic_data["clicks"] / traffic_data["impressions"]) * 100
                    traffic_ctrs.append(ctr)
                
                # Conversion: CVR, CPA
                if conversion_data["clicks"] > 0:
                    cvr = (conversion_data["purchases"] / conversion_data["clicks"]) * 100
                    conversion_cvrs.append(cvr)
                if conversion_data["purchases"] > 0:
                    cpa = conversion_data["spend"] / conversion_data["purchases"]
                    conversion_cpas.append(cpa)
            
            # í‰ê· /ì¤‘ì•™ê°’ ê³„ì‚°
            traffic_avg_cpc = statistics.mean(traffic_cpcs) if traffic_cpcs else None
            traffic_median_cpc = statistics.median(traffic_cpcs) if traffic_cpcs else None
            traffic_avg_ctr = statistics.mean(traffic_ctrs) if traffic_ctrs else None
            
            conversion_avg_cvr = statistics.mean(conversion_cvrs) if conversion_cvrs else None
            conversion_median_cvr = statistics.median(conversion_cvrs) if conversion_cvrs else None
            conversion_avg_cpa = statistics.mean(conversion_cpas) if conversion_cpas else None
            conversion_median_cpa = statistics.median(conversion_cpas) if conversion_cpas else None
            
            return {
                "last_6m": {
                    "traffic": {
                        "avg_cpc": round(traffic_avg_cpc, 2) if traffic_avg_cpc is not None else None,
                        "median_cpc": round(traffic_median_cpc, 2) if traffic_median_cpc is not None else None,
                        "avg_ctr": round(traffic_avg_ctr, 2) if traffic_avg_ctr is not None else None,
                        "count_months": count_months,
                    },
                    "conversion": {
                        "avg_cvr": round(conversion_avg_cvr, 2) if conversion_avg_cvr is not None else None,
                        "median_cvr": round(conversion_median_cvr, 2) if conversion_median_cvr is not None else None,
                        "avg_cpa": round(conversion_avg_cpa, 2) if conversion_avg_cpa is not None else None,
                        "median_cpa": round(conversion_median_cpa, 2) if conversion_median_cpa is not None else None,
                        "count_months": count_months,
                    }
                }
            }
        
        # (D) 6ê°œì›” ë²¤ì¹˜ë§ˆí¬ëŠ” monthly_13m_meta ê¸°ë°˜ìœ¼ë¡œ ê³„ì‚°
        meta_ads_benchmarks = build_meta_ads_benchmarks_from_monthly_13m(monthly_13m_meta)
    
    # -----------------------
    # GA4 traffic
    # -----------------------
    q_ga4_traffic = f"""
    WITH ga4_totals AS (
        SELECT
            SUM(total_users) AS total_users,
            SUM(screen_page_views) AS screen_page_views,
            SUM(event_count) AS event_count
        FROM `{PROJECT_ID}.{DATASET}.ga4_traffic_ngn`
        WHERE company_name = @company_name
          AND event_date BETWEEN @start_date AND @end_date
    ),
    cart_signup_totals AS (
        SELECT
            COALESCE(SUM(cart_users), 0) AS add_to_cart_users,
            COALESCE(SUM(signup_count), 0) AS sign_up_users
        FROM `{PROJECT_ID}.{DATASET}.performance_summary_ngn`
        WHERE company_name = @company_name
          AND DATE(date) BETWEEN @start_date AND @end_date
    )
    SELECT
        COALESCE(g.total_users, 0) AS total_users,
        COALESCE(g.screen_page_views, 0) AS screen_page_views,
        COALESCE(g.event_count, 0) AS event_count,
        COALESCE(c.add_to_cart_users, 0) AS add_to_cart_users,
        COALESCE(c.sign_up_users, 0) AS sign_up_users
    FROM (SELECT 1 AS dummy) dummy
    LEFT JOIN ga4_totals g ON TRUE
    LEFT JOIN cart_signup_totals c ON TRUE
    """
    
    def get_ga4_traffic_totals(s, e):
        rows = list(
            client.query(
                q_ga4_traffic,
                job_config=bigquery.QueryJobConfig(
                    query_parameters=[
                        bigquery.ScalarQueryParameter("company_name", "STRING", company_name),
                        bigquery.ScalarQueryParameter("start_date", "DATE", s),
                        bigquery.ScalarQueryParameter("end_date", "DATE", e),
                    ]
                ),
            ).result()
        )
        
        if not rows:
            return {
                "total_users": 0,
                "screen_page_views": 0,
                "event_count": 0,
                "add_to_cart_users": 0,
                "sign_up_users": 0,
            }
        
        row = rows[0]
        return {
            "total_users": int(row.total_users or 0),
            "screen_page_views": int(row.screen_page_views or 0),
            "event_count": int(row.event_count or 0),
            "add_to_cart_users": int(row.add_to_cart_users or 0),
            "sign_up_users": int(row.sign_up_users or 0),
        }
    
    # âœ… ìµœì í™”: this/prev/yoyë¥¼ í•œ ë²ˆì— ì¡°íšŒ í›„ Pythonì—ì„œ ë¶„í•´
    def get_ga4_top_sources_multi(ranges, top_n=10):
        """this/prev/yoyë¥¼ í•œ ë²ˆì— ì¡°íšŒ í›„ Pythonì—ì„œ ë¶„í•´"""
        # ì „ì²´ ê¸°ê°„(this/prev/yoy) ìµœì†Œ~ìµœëŒ€ ë‚ ì§œ ê³„ì‚°
        all_dates = []
        for key, (s, e) in ranges.items():
            if s and e:
                all_dates.extend([s, e])
        
        if not all_dates:
            return {"this": [], "prev": [], "yoy": []}
        
        min_date = min(all_dates)
        max_date = max(all_dates)
        
        # ì „ì²´ ê¸°ê°„ì„ í•œ ë²ˆì— ì¡°íšŒ (ë‚ ì§œë³„ë¡œ ì§‘ê³„ í›„ Pythonì—ì„œ ê¸°ê°„ë³„ ë¶„ë¥˜)
        q_ga4_top_sources_multi = f"""
        SELECT
            event_date,
            first_user_source AS source,
            SUM(total_users) AS total_users,
            SUM(screen_page_views) AS screen_page_views,
            -- ì´íƒˆìœ¨ ê°€ì¤‘í‰ê·  ê³„ì‚° (ë‚ ì§œë³„)
            SAFE_DIVIDE(
                SUM(IFNULL(bounce_rate, 0) * total_users),
                SUM(total_users)
            ) AS bounce_rate
        FROM `{PROJECT_ID}.{DATASET}.ga4_traffic_ngn`
        WHERE company_name = @company_name
          AND event_date >= @min_date
          AND event_date <= @max_date
          AND first_user_source IS NOT NULL
          AND first_user_source != '(not set)'
        GROUP BY event_date, source
        """
        
        rows = list(
            client.query(
                q_ga4_top_sources_multi,
                job_config=bigquery.QueryJobConfig(
                    query_parameters=[
                        bigquery.ScalarQueryParameter("company_name", "STRING", company_name),
                        bigquery.ScalarQueryParameter("min_date", "DATE", min_date),
                        bigquery.ScalarQueryParameter("max_date", "DATE", max_date),
                    ]
                ),
            ).result()
        )
        
        # ê° ê¸°ê°„ë³„ë¡œ ë¶„ë¥˜ ë° ì§‘ê³„
        by_period = defaultdict(lambda: defaultdict(lambda: {
            "total_users": 0,
            "screen_page_views": 0,
            "bounce_rate_sum": 0.0,
            "bounce_rate_weight": 0,
        }))
        
        for row in rows:
            row_date = row.event_date
            if not row_date:
                continue
            
            # ê° ê¸°ê°„ì— ì†í•˜ëŠ”ì§€ í™•ì¸
            for period_key, (period_start, period_end) in ranges.items():
                if period_start and period_end:
                    period_start_date = date.fromisoformat(period_start)
                    period_end_date = date.fromisoformat(period_end)
                    if period_start_date <= row_date <= period_end_date:
                        source_data = by_period[period_key][row.source]
                        users = int(row.total_users or 0)
                        source_data["total_users"] += users
                        source_data["screen_page_views"] += int(row.screen_page_views or 0)
                        if row.bounce_rate is not None:
                            source_data["bounce_rate_sum"] += float(row.bounce_rate) * users
                            source_data["bounce_rate_weight"] += users
                        break
        
        # ê° ê¸°ê°„ë³„ë¡œ Top N ì„ íƒ
        result = {}
        for period_key in ["this", "prev", "yoy"]:
            if period_key not in by_period:
                result[period_key] = []
                continue
            
            period_sources = []
            for source, data in by_period[period_key].items():
                bounce_rate = (data["bounce_rate_sum"] / data["bounce_rate_weight"]) if data["bounce_rate_weight"] > 0 else None
                period_sources.append({
                    "source": source,
                    "total_users": data["total_users"],
                    "screen_page_views": data["screen_page_views"],
                    "bounce_rate": round(bounce_rate, 2) if bounce_rate is not None else None,
                })
            
            # total_users DESCë¡œ ì •ë ¬ í›„ Top N
            period_sources.sort(key=lambda x: x["total_users"], reverse=True)
            result[period_key] = period_sources[:top_n]
        
        return result
    
    def get_ga4_top_sources(s, e, top_n=10):
        """ë‹¨ì¼ ê¸°ê°„ìš© (í•˜ìœ„ í˜¸í™˜ì„± ìœ ì§€)"""
        ranges = {"single": (s, e)}
        result = get_ga4_top_sources_multi(ranges, top_n)
        return result.get("single", [])
    
    # âœ… ìµœì í™” 1ë‹¨ê³„: ì›”ê°„ ì§‘ê³„ í…Œì´ë¸”ì—ì„œ this/prev/yoy ì¶”ì¶œ (raw í…Œì´ë¸” ì¡°íšŒ ì œê±°)
    # ì›”ê°„ ì§‘ê³„ í…Œì´ë¸” ì‚¬ìš© (ì„±ëŠ¥ ìµœì í™”) - ë¨¼ì € ì¡°íšŒ
    monthly_13m_ga4_raw = query_monthly_13m_from_monthly_table(
        client,
        f"{PROJECT_ID}.{DATASET}.ga4_traffic_monthly",
        company_name,
        report_month,
        """
        SUM(total_users) AS total_users,
        SUM(screen_page_views) AS screen_page_views,
        SUM(event_count) AS event_count,
        SUM(add_to_cart_users) AS add_to_cart_users,
        SUM(sign_up_users) AS sign_up_users
        """
    )
    
    monthly_13m_ga4 = [
        {"ym": ym, **metrics}
        for ym, metrics in sorted(monthly_13m_ga4_raw.items())
    ]
    
    # monthly_13m_ga4ì—ì„œ this/prev/yoy totals ì¶”ì¶œ
    def get_monthly_ga4_from_13m(monthly_list, target_ym):
        """monthly_13m_ga4 ë¦¬ìŠ¤íŠ¸ì—ì„œ íŠ¹ì • ì›” ë°ì´í„° ì¶”ì¶œ. ì—†ìœ¼ë©´ None ë°˜í™˜"""
        for item in monthly_list:
            if item.get("ym") == target_ym:
                return item
        # ë°ì´í„°ê°€ ì—†ìœ¼ë©´ None ë°˜í™˜ (ì‹¤ì œ ìˆ˜ì§‘ë˜ì§€ ì•Šì€ ê²½ìš°)
        return None
    
    ga4_this_data = get_monthly_ga4_from_13m(monthly_13m_ga4, report_month)
    ga4_prev_data = get_monthly_ga4_from_13m(monthly_13m_ga4, prev_month)
    ga4_yoy_data = get_monthly_ga4_from_13m(monthly_13m_ga4, yoy_month)
    
    # âœ… ìµœì í™”: ëª¨ë“  totals ë°ì´í„°ë¥¼ ì›”ê°„ ì§‘ê³„ í…Œì´ë¸”ì—ì„œ ê°€ì ¸ì˜´ (raw í…Œì´ë¸” ì¡°íšŒ ì œê±°)
    # ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ None (ì‹¤ì œ ìˆ˜ì§‘ë˜ì§€ ì•Šì€ ê²½ìš°)
    ga4_this_totals = {
        "total_users": int(ga4_this_data.get("total_users", 0)) if ga4_this_data else None,
        "screen_page_views": int(ga4_this_data.get("screen_page_views", 0)) if ga4_this_data else None,
        "event_count": int(ga4_this_data.get("event_count", 0)) if ga4_this_data else None,
        "add_to_cart_users": int(ga4_this_data.get("add_to_cart_users", 0)) if ga4_this_data else None,
        "sign_up_users": int(ga4_this_data.get("sign_up_users", 0)) if ga4_this_data else None,
    } if ga4_this_data else None
    
    ga4_prev_totals = {
        "total_users": int(ga4_prev_data.get("total_users", 0)) if ga4_prev_data else None,
        "screen_page_views": int(ga4_prev_data.get("screen_page_views", 0)) if ga4_prev_data else None,
        "event_count": int(ga4_prev_data.get("event_count", 0)) if ga4_prev_data else None,
        "add_to_cart_users": int(ga4_prev_data.get("add_to_cart_users", 0)) if ga4_prev_data else None,
        "sign_up_users": int(ga4_prev_data.get("sign_up_users", 0)) if ga4_prev_data else None,
    } if ga4_prev_data else None
    
    # YoY ë°ì´í„° ì¡´ì¬ ì—¬ë¶€ í™•ì¸ (ì›”ê°„ ì§‘ê³„ ìš°ì„ , ì—†ìœ¼ë©´ raw fallback)
    # ì›”ê°„ ì§‘ê³„(ga4_yoy_data)ê°€ ìˆìœ¼ë©´ ìš°ì„  true
    ga4_yoy_available = (ga4_yoy_data is not None)
    if not ga4_yoy_available:
        # ì›”ê°„ ì§‘ê³„ê°€ ë¹„ì–´ìˆì„ ë•Œë§Œ raw fallback (top_sourcesëŠ” ì—¬ì „íˆ raw í…Œì´ë¸” í•„ìš”)
        ga4_yoy_available = has_rows(
            client,
            f"{PROJECT_ID}.{DATASET}.ga4_traffic_ngn",
            "event_date",
            company_name,
            yoy_start,
            yoy_end
        )
    
    # âœ… ìµœì í™”: this/prev/yoyë¥¼ í•œ ë²ˆì— ì¡°íšŒ
    ga4_top_sources_ranges = {
        "this": (this_start, this_end),
        "prev": (prev_start, prev_end),
        "yoy": (yoy_start, yoy_end) if ga4_yoy_available else None,
    }
    if ga4_top_sources_ranges["yoy"] is None:
        del ga4_top_sources_ranges["yoy"]
    
    # âœ… ìµœì í™”: BigQuery ë³‘ë ¬ ì‹¤í–‰ (í•µì‹¬ ìµœì í™”)
    # ì„¸ ì¿¼ë¦¬ë¥¼ ë™ì‹œì— ì‹¤í–‰í•˜ì—¬ ì „ì²´ ì‹¤í–‰ ì‹œê°„ ë‹¨ì¶•
    with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
        # ê° ì¿¼ë¦¬ í•¨ìˆ˜ë¥¼ ë™ì‹œì— ì‹¤í–‰ ì˜ˆì•½
        future_daily = executor.submit(get_sales_daily_multi, daily_ranges)
        future_ga4 = executor.submit(get_ga4_top_sources_multi, ga4_top_sources_ranges, GA4_TRAFFIC_TOP_LIMIT)
        
        # goals_multiëŠ” SKIP_META_ADS_GOALSê°€ Falseì´ê³  rangesê°€ ì •ì˜ë˜ì–´ ìˆì„ ë•Œë§Œ ì‹¤í–‰
        if not SKIP_META_ADS_GOALS and ranges is not None:
            future_goals = executor.submit(get_meta_ads_goals_multi, ranges)
        else:
            future_goals = None
        
        # ê²°ê³¼ í•œêº¼ë²ˆì— ë°›ê¸° (ê°€ì¥ ëŠë¦° ì¿¼ë¦¬ ì‹œê°„ë§Œí¼ë§Œ ì†Œìš”ë¨)
        daily_multi = future_daily.result()
        ga4_top_sources_multi = future_ga4.result()
        goals_multi = future_goals.result() if future_goals else None
    
    # ê²°ê³¼ ë¶„í•´
    daily_this = daily_multi.get("this", [])
    daily_prev = daily_multi.get("prev", [])
    daily_yoy = daily_multi.get("yoy", [])
    
    # goals_multi ê²°ê³¼ëŠ” if ë¸”ë¡ ì•ˆì—ì„œ ì²˜ë¦¬
    if not SKIP_META_ADS_GOALS:
        meta_ads_goals_this = goals_multi.get("this")
        meta_ads_goals_prev = goals_multi.get("prev")
        meta_ads_goals_yoy = goals_multi.get("yoy") if meta_ads_yoy_available else None
    
    if ga4_yoy_available and ga4_yoy_data:
        ga4_yoy_totals = {
            "total_users": int(ga4_yoy_data.get("total_users", 0)),
            "screen_page_views": int(ga4_yoy_data.get("screen_page_views", 0)),
            "event_count": int(ga4_yoy_data.get("event_count", 0)),
            "add_to_cart_users": int(ga4_yoy_data.get("add_to_cart_users", 0)),
            "sign_up_users": int(ga4_yoy_data.get("sign_up_users", 0)),
        }
        ga4_yoy = {
            "totals": ga4_yoy_totals,
            "top_sources": ga4_top_sources_multi.get("yoy", []),
        }
    else:
        ga4_yoy = {
            "totals": None,
            "top_sources": [],
        }
    
    ga4_this = {
        "totals": ga4_this_totals,
        "top_sources": ga4_top_sources_multi.get("this", []),
    }
    ga4_prev = {
        "totals": ga4_prev_totals,
        "top_sources": ga4_top_sources_multi.get("prev", []),
    }
    
    # -----------------------
    # Products (30d / 90d)
    # -----------------------
    q_products = f"""
    SELECT
      product_no,
      product_name,
      ANY_VALUE(product_url) AS product_url,
      SUM(item_quantity) AS quantity,
      SUM(item_product_sales) AS sales
    FROM `{PROJECT_ID}.{DATASET}.daily_cafe24_items`
    WHERE company_name = @company_name
      AND payment_date BETWEEN @start_date AND @end_date
    GROUP BY product_no, product_name
    HAVING SUM(item_product_sales) > 0
    ORDER BY sales DESC
    LIMIT @limit
    """
    
    def get_products_block(end_date_iso):
        block = {"rolling": {}}
        rolling_top = {}
        
        for days in PRODUCT_ROLLING_WINDOWS:
            s, e = rolling_range(end_date_iso, days)
            
            rows = list(
                client.query(
                    q_products,
                    job_config=bigquery.QueryJobConfig(
                        query_parameters=[
                            bigquery.ScalarQueryParameter("company_name", "STRING", company_name),
                            bigquery.ScalarQueryParameter("start_date", "DATE", s),
                            bigquery.ScalarQueryParameter("end_date", "DATE", e),
                            bigquery.ScalarQueryParameter("limit", "INT64", PRODUCT_TOP_LIMIT),
                        ]
                    ),
                ).result()
            )
            
            rolling_top[days] = [
                {
                    "product_no": int(r.product_no),
                    "product_name": r.product_name,
                    "product_url": r.product_url,
                    "quantity": int(r.quantity),
                    "sales": float(r.sales),
                }
                for r in rows
            ]
        
        s90, e90 = rolling_range(end_date_iso, 90)
        net90 = get_sales(s90, e90)["net_sales"]
        
        products_30d_map = {}
        for p in rolling_top.get(30, []):
            products_30d_map[p["product_no"]] = {
                "quantity": p["quantity"],
                "sales": p["sales"],
            }
        
        for p in rolling_top.get(90, []):
            share = (p["sales"] / net90 * 100) if net90 else None
            p["share_of_net_sales_pct_90d"] = share
            if share is None:
                p["role_90d"] = "unknown"
            elif share >= 20:
                p["role_90d"] = "core"
            elif share >= 10:
                p["role_90d"] = "hit"
            else:
                p["role_90d"] = "normal"
            
            if p["role_90d"] in ["core", "hit"]:
                p30d = products_30d_map.get(p["product_no"])
                if p30d:
                    p["quantity_30d"] = p30d["quantity"]
                    p["sales_30d"] = p30d["sales"]
                    avg_90d_sales = p["sales"] / 90
                    avg_30d_sales = p30d["sales"] / 30
                    p["is_declining"] = avg_30d_sales < avg_90d_sales
                else:
                    p["quantity_30d"] = None
                    p["sales_30d"] = None
                    p["is_declining"] = None
        
        block["rolling"]["d30"] = {"top_products_by_sales": rolling_top.get(30, [])}
        block["rolling"]["d90"] = {"top_products_by_sales_with_role": rolling_top.get(90, [])}
        
        return block
    
    products_this = get_products_block(this_end)
    
    # -----------------------
    # GA4 view_item (ì›”ê°„ ì§‘ê³„ í…Œì´ë¸” ì‚¬ìš©)
    # -----------------------
    q_viewitem_monthly = f"""
    SELECT
      item_name,
      view_item
    FROM `{PROJECT_ID}.{DATASET}.ga4_viewitem_monthly_raw`
    WHERE company_name = @company_name
      AND ym = @ym
    ORDER BY view_item DESC
    LIMIT @limit
    """
    
    def get_viewitem_block(ym, products_30d):
        sales_map = {}
        if products_30d:
            for p in products_30d:
                if isinstance(p, dict):
                    product_name = p.get("product_name")
                    if product_name:
                        key = normalize_item_name(product_name)
                        if key:
                            if key not in sales_map:
                                sales_map[key] = p
        
        rows = list(
            client.query(
                q_viewitem_monthly,
                job_config=bigquery.QueryJobConfig(
                    query_parameters=[
                        bigquery.ScalarQueryParameter("company_name", "STRING", company_name),
                        bigquery.ScalarQueryParameter("ym", "STRING", ym),
                        bigquery.ScalarQueryParameter("limit", "INT64", VIEWITEM_TOP_LIMIT * 3),
                    ]
                ),
            ).result()
        )
        
        aggregated = defaultdict(lambda: {"total_view_item": 0, "matched": None})
        
        for r in rows:
            raw = r.item_name or ""
            view_item_count = int(r.view_item or 0)
            
            if view_item_count == 0:
                continue
            
            key = normalize_item_name(raw)
            
            if not key:
                continue
            
            aggregated[key]["total_view_item"] += view_item_count
            
            if aggregated[key]["matched"] is None:
                matched = sales_map.get(key)
                if matched:
                    aggregated[key]["matched"] = matched
        
        items = []
        for key, data in aggregated.items():
            matched = data["matched"]
            total_view_item = data["total_view_item"]
            
            if total_view_item == 0:
                continue
            
            matched_product_no = matched.get("product_no") if matched else None
            matched_quantity_30d = matched.get("quantity") if matched else None
            matched_sales_30d = matched.get("sales") if matched else None
            
            qty_per_view = (matched_quantity_30d / total_view_item) if (matched_quantity_30d and total_view_item > 0) else None
            sales_per_view = (matched_sales_30d / total_view_item) if (matched_sales_30d and total_view_item > 0) else None
            
            attention_without_conversion = (
                total_view_item >= VIEWITEM_ATTENTION_MIN_VIEW and
                (matched_quantity_30d is None or matched_quantity_30d == 0)
            )
            
            # íš¨ìœ¨ì„± í”Œë˜ê·¸
            efficient_conversion = (
                total_view_item >= VIEWITEM_EFFICIENT_MIN_VIEW and
                qty_per_view is not None and
                qty_per_view >= VIEWITEM_EFFICIENT_MIN_QTY_PER_VIEW
            )
            
            high_attention_and_high_conversion = (
                total_view_item >= VIEWITEM_ATTENTION_MIN_VIEW and
                qty_per_view is not None and
                qty_per_view >= VIEWITEM_EFFICIENT_MIN_QTY_PER_VIEW
            )
            
            items.append({
                "item_name_normalized": key,
                "total_view_item": total_view_item,
                "matched_product_no": matched_product_no,
                "matched_quantity_30d": matched_quantity_30d,
                "matched_sales_30d": matched_sales_30d,
                "qty_per_view": round(qty_per_view, 4) if qty_per_view is not None else None,
                "sales_per_view": round(sales_per_view, 2) if sales_per_view is not None else None,
                "attention_without_conversion": attention_without_conversion,
                "efficient_conversion": efficient_conversion,
                "high_attention_and_high_conversion": high_attention_and_high_conversion,
            })
        
        items.sort(key=lambda x: x["total_view_item"], reverse=True)
        
        return {"top_items_by_view_item": items}
    
    products_30d = products_this.get("rolling", {}).get("d30", {}).get("top_products_by_sales", [])
    if SKIP_VIEWITEM:
        viewitem_this = {"top_items_by_view_item": []}
    else:
        viewitem_this = get_viewitem_block(report_month, products_30d)
    
    # -----------------------
    # YoY ë°ì´í„° ì¡´ì¬ ì—¬ë¶€ í™•ì¸ (ì›”ê°„ ì§‘ê³„ ìš°ì„ , ì—†ìœ¼ë©´ raw fallback)
    # -----------------------
    # ì›”ê°„ ì§‘ê³„(sales_yoy_data)ê°€ ìˆìœ¼ë©´ ìš°ì„  true
    mall_sales_yoy_available = (sales_yoy_data is not None)
    if not mall_sales_yoy_available:
        # ì›”ê°„ ì§‘ê³„ê°€ ë¹„ì–´ìˆì„ ë•Œë§Œ raw fallback
        mall_sales_yoy_available = has_rows(
            client,
            f"{PROJECT_ID}.{DATASET}.daily_cafe24_sales",
            "payment_date",
            company_name,
            yoy_start,
            yoy_end
        )
    
    # meta_ads_yoy_availableì€ goals ë¸”ë¡ì—ì„œ ì²´í¬ë¨
    # SKIP_META_ADS_GOALS=1ì¼ ë•ŒëŠ” Falseë¡œ ìœ ì§€ë¨
    # comparisonsì—ì„œ ì‚¬ìš©í•˜ê¸° ìœ„í•´ goals ë¸”ë¡ ë°–ì—ì„œë„ ì²´í¬ í•„ìš”
    if SKIP_META_ADS_GOALS:
        # goals ë¸”ë¡ì´ ìŠ¤í‚µë˜ë©´ ì—¬ê¸°ì„œë§Œ ë³´ì™„ í•„ìš”
        meta_ads_yoy_available = (meta_ads_yoy_data is not None)
        if not meta_ads_yoy_available:
            # ì›”ê°„ ì§‘ê³„ê°€ ë¹„ì–´ìˆì„ ë•Œë§Œ raw fallback
            meta_ads_yoy_available = has_rows(
                client,
                f"{PROJECT_ID}.{DATASET}.meta_ads_account_summary",
                "date",
                company_name,
                yoy_start,
                yoy_end
            )
    
    # -----------------------
    # Comparisons
    # -----------------------
    def build_meta_ads_goals_comparisons(meta_ads_goals_this, meta_ads_goals_prev, meta_ads_goals_yoy):
        """Meta Ads Goalsë³„ ë¹„êµ ìƒì„±"""
        if meta_ads_goals_this is None or meta_ads_goals_prev is None:
            return None
        
        by_goal_this = meta_ads_goals_this.get("by_goal", {})
        by_goal_prev = meta_ads_goals_prev.get("by_goal", {})
        by_goal_yoy = meta_ads_goals_yoy.get("by_goal", {}) if meta_ads_goals_yoy else {}
        
        # ëª¨ë“  goal í‚¤ ìˆ˜ì§‘ (conversion, traffic, awareness, unknown)
        all_goals = set(["conversion", "traffic", "awareness", "unknown"])
        all_goals.update(by_goal_this.keys())
        all_goals.update(by_goal_prev.keys())
        if meta_ads_goals_yoy:
            all_goals.update(by_goal_yoy.keys())
        
        result_mom = {}
        result_yoy = {} if meta_ads_goals_yoy else None
        
        for goal in sorted(all_goals):
            goal_this = by_goal_this.get(goal, {})
            goal_prev = by_goal_prev.get(goal, {})
            goal_yoy = by_goal_yoy.get(goal, {}) if meta_ads_goals_yoy else {}
            
            # ê¸°ë³¸ê°’ ì„¤ì •
            def get_value(data, key, default=0):
                return data.get(key, default) if data else default
            
            def get_rate(data, key):
                return data.get(key) if data else None
            
            # MoM ë¹„êµ
            goal_mom = {}
            
            # spend
            spend_this = get_value(goal_this, "spend", 0.0)
            spend_prev = get_value(goal_prev, "spend", 0.0)
            goal_mom["spend"] = delta(spend_this, spend_prev)
            
            # purchases
            purchases_this = get_value(goal_this, "purchases", 0)
            purchases_prev = get_value(goal_prev, "purchases", 0)
            goal_mom["purchases"] = delta(purchases_this, purchases_prev)
            
            # purchase_value
            purchase_value_this = get_value(goal_this, "purchase_value", 0.0)
            purchase_value_prev = get_value(goal_prev, "purchase_value", 0.0)
            goal_mom["purchase_value"] = delta(purchase_value_this, purchase_value_prev)
            
            # clicks
            clicks_this = get_value(goal_this, "clicks", 0)
            clicks_prev = get_value(goal_prev, "clicks", 0)
            goal_mom["clicks"] = delta(clicks_this, clicks_prev)
            
            # impressions
            impressions_this = get_value(goal_this, "impressions", 0)
            impressions_prev = get_value(goal_prev, "impressions", 0)
            goal_mom["impressions"] = delta(impressions_this, impressions_prev)
            
            # rateë¥˜: baseê°€ Noneì´ë©´ deltaë„ None
            # ctr
            ctr_this = get_rate(goal_this, "ctr")
            ctr_prev = get_rate(goal_prev, "ctr")
            goal_mom["ctr"] = delta(ctr_this, ctr_prev) if (ctr_this is not None and ctr_prev is not None) else None
            
            # cpc
            cpc_this = get_rate(goal_this, "cpc")
            cpc_prev = get_rate(goal_prev, "cpc")
            goal_mom["cpc"] = delta(cpc_this, cpc_prev) if (cpc_this is not None and cpc_prev is not None) else None
            
            # cvr
            cvr_this = get_rate(goal_this, "cvr")
            cvr_prev = get_rate(goal_prev, "cvr")
            goal_mom["cvr"] = delta(cvr_this, cvr_prev) if (cvr_this is not None and cvr_prev is not None) else None
            
            # cpa (purchasesê°€ ìˆìœ¼ë©´ ê³„ì‚°)
            cpa_this = (spend_this / purchases_this) if purchases_this > 0 else None
            cpa_prev = (spend_prev / purchases_prev) if purchases_prev > 0 else None
            goal_mom["cpa"] = delta(cpa_this, cpa_prev) if (cpa_this is not None and cpa_prev is not None) else None
            
            # roas
            roas_this = get_rate(goal_this, "roas")
            roas_prev = get_rate(goal_prev, "roas")
            goal_mom["roas"] = delta(roas_this, roas_prev) if (roas_this is not None and roas_prev is not None) else None
            
            # base_small í”Œë˜ê·¸
            goal_mom["note_if_base_small_spend"] = note_if_base_small(spend_prev, META_ADS_BASE_SMALL_THRESHOLD)
            
            result_mom[goal] = goal_mom
            
            # YoY ë¹„êµ (meta_ads_goals_yoyê°€ ìˆìœ¼ë©´)
            if meta_ads_goals_yoy:
                goal_yoy_dict = {}
                
                # spend
                spend_yoy_val = get_value(goal_yoy, "spend", 0.0)
                goal_yoy_dict["spend"] = delta(spend_this, spend_yoy_val)
                
                # purchases
                purchases_yoy = get_value(goal_yoy, "purchases", 0)
                goal_yoy_dict["purchases"] = delta(purchases_this, purchases_yoy)
                
                # purchase_value
                purchase_value_yoy = get_value(goal_yoy, "purchase_value", 0.0)
                goal_yoy_dict["purchase_value"] = delta(purchase_value_this, purchase_value_yoy)
                
                # clicks
                clicks_yoy = get_value(goal_yoy, "clicks", 0)
                goal_yoy_dict["clicks"] = delta(clicks_this, clicks_yoy)
                
                # impressions
                impressions_yoy = get_value(goal_yoy, "impressions", 0)
                goal_yoy_dict["impressions"] = delta(impressions_this, impressions_yoy)
                
                # rateë¥˜
                ctr_yoy = get_rate(goal_yoy, "ctr")
                goal_yoy_dict["ctr"] = delta(ctr_this, ctr_yoy) if (ctr_this is not None and ctr_yoy is not None) else None
                
                cpc_yoy = get_rate(goal_yoy, "cpc")
                goal_yoy_dict["cpc"] = delta(cpc_this, cpc_yoy) if (cpc_this is not None and cpc_yoy is not None) else None
                
                cvr_yoy = get_rate(goal_yoy, "cvr")
                goal_yoy_dict["cvr"] = delta(cvr_this, cvr_yoy) if (cvr_this is not None and cvr_yoy is not None) else None
                
                cpa_yoy = (spend_yoy_val / purchases_yoy) if purchases_yoy > 0 else None
                goal_yoy_dict["cpa"] = delta(cpa_this, cpa_yoy) if (cpa_this is not None and cpa_yoy is not None) else None
                
                roas_yoy = get_rate(goal_yoy, "roas")
                goal_yoy_dict["roas"] = delta(roas_this, roas_yoy) if (roas_this is not None and roas_yoy is not None) else None
                
                # base_small í”Œë˜ê·¸
                goal_yoy_dict["note_if_base_small_spend"] = note_if_base_small(spend_yoy_val, META_ADS_BASE_SMALL_THRESHOLD)
                
                result_yoy[goal] = goal_yoy_dict
        
        return {
            "mom": result_mom,
            "yoy": result_yoy,
        }
    
    def build_comparisons():
        comparisons = {}
        
        # mall_sales
        net_sales_mom = delta(sales_this.get("net_sales"), sales_prev.get("net_sales")) if (sales_this and sales_prev) else None
        net_sales_yoy = delta(sales_this.get("net_sales"), sales_yoy.get("net_sales")) if (mall_sales_yoy_available and sales_yoy and sales_this) else None
        comparisons["mall_sales"] = {
            "net_sales_mom": net_sales_mom,
            "net_sales_yoy": net_sales_yoy,
            "note_if_base_small_mom": note_if_base_small(sales_prev.get("net_sales"), MALL_SALES_BASE_SMALL_THRESHOLD) if sales_prev else None,
        }
        
        # meta_ads
        spend_mom = delta(meta_ads_this.get("spend"), meta_ads_prev.get("spend")) if (meta_ads_this and meta_ads_prev) else None
        spend_yoy = delta(meta_ads_this.get("spend"), meta_ads_yoy.get("spend")) if (meta_ads_yoy_available and meta_ads_yoy and meta_ads_this) else None
        roas_mom = (
            delta(meta_ads_this.get("roas"), meta_ads_prev.get("roas"))
            if (meta_ads_this and meta_ads_prev and meta_ads_this.get("roas") is not None and meta_ads_prev.get("roas") is not None)
            else None
        )
        cvr_mom = (
            delta(meta_ads_this.get("cvr"), meta_ads_prev.get("cvr"))
            if (meta_ads_this and meta_ads_prev and meta_ads_this.get("cvr") is not None and meta_ads_prev.get("cvr") is not None)
            else None
        )
        comparisons["meta_ads"] = {
            "spend_mom": spend_mom,
            "spend_yoy": spend_yoy,
            "roas_mom": roas_mom,
            "cvr_mom": cvr_mom,
            "note_if_base_small_mom": note_if_base_small(meta_ads_prev.get("spend"), META_ADS_BASE_SMALL_THRESHOLD) if meta_ads_prev else None,
        }
        
        # meta_ads_goals
        meta_ads_goals_comparisons = build_meta_ads_goals_comparisons(
            meta_ads_goals_this,
            meta_ads_goals_prev,
            meta_ads_goals_yoy
        )
        if meta_ads_goals_comparisons:
            comparisons["meta_ads_goals"] = meta_ads_goals_comparisons
        
        # ga4_traffic
        total_users_mom = delta(ga4_this_totals.get("total_users"), ga4_prev_totals.get("total_users")) if (ga4_this_totals and ga4_prev_totals) else None
        total_users_yoy = delta(ga4_this_totals.get("total_users"), ga4_yoy_totals.get("total_users")) if (ga4_yoy_available and ga4_yoy_totals and ga4_this_totals) else None
        comparisons["ga4_traffic"] = {
            "total_users_mom": total_users_mom,
            "total_users_yoy": total_users_yoy,
            "note_if_base_small_mom": note_if_base_small(ga4_prev_totals.get("total_users"), GA4_TRAFFIC_BASE_SMALL_THRESHOLD) if ga4_prev_totals else None,
        }
        
        return comparisons
    
    comparisons = build_comparisons()
    
    # -----------------------
    # Forecast next month
    # -----------------------
    def build_forecast_next_month():
        next_report_month = shift_month(report_month, 1)
        next_month_num = int(next_report_month.split("-")[1])
        
        # ì‘ë…„ ìµì›” ê³„ì‚° (ë‹¤ìŒ ë‹¬ì˜ ì‘ë…„ ë™ì›”)
        next_month_next = shift_month(next_report_month, 1)
        next_month_next_num = int(next_month_next.split("-")[1])
        
        forecast = {
            "month": next_report_month,
            "mall_sales": {},
            "meta_ads": {},
            "ga4_traffic": {},
        }
        
        # ê°™ì€ ì›”(month-of-year) í‘œë³¸ ìˆ˜ì§‘ (ì‘ë…„ ë™ì›”)
        mall_sales_same_month = []
        meta_ads_same_month = []
        ga4_traffic_same_month = []
        
        # ì‘ë…„ ìµì›” í‘œë³¸ ìˆ˜ì§‘
        mall_sales_next_month = []
        
        for item in monthly_13m:
            ym = item.get("ym", "")
            ym_parts = ym.split("-")
            if len(ym_parts) >= 2:
                try:
                    item_month = int(ym_parts[1])
                    if item_month == next_month_num:
                        v = item.get("net_sales")
                        if v is not None:
                            mall_sales_same_month.append(v)
                    elif item_month == next_month_next_num:
                        # ì‘ë…„ ìµì›” ë§¤ì¶œ
                        v = item.get("net_sales")
                        if v is not None:
                            mall_sales_next_month.append(v)
                except (ValueError, IndexError):
                    continue
        
        for item in monthly_13m_meta:
            ym = item.get("ym", "")
            ym_parts = ym.split("-")
            if len(ym_parts) >= 2:
                try:
                    item_month = int(ym_parts[1])
                    if item_month == next_month_num:
                        v = item.get("spend")
                        if v is not None:
                            meta_ads_same_month.append(v)
                except (ValueError, IndexError):
                    continue
        
        for item in monthly_13m_ga4:
            ym = item.get("ym", "")
            ym_parts = ym.split("-")
            if len(ym_parts) >= 2:
                try:
                    item_month = int(ym_parts[1])
                    if item_month == next_month_num:
                        v = item.get("total_users")
                        if v is not None:
                            ga4_traffic_same_month.append(v)
                except (ValueError, IndexError):
                    continue
        
        def calc_stats(values):
            if not values:
                return {"count": 0, "min": None, "max": None, "median": None}
            return {
                "count": len(values),
                "min": min(values),
                "max": max(values),
                "median": statistics.median(values) if len(values) > 0 else None,
            }
        
        # ì‘ë…„ ë™ì›” ë§¤ì¶œ í†µê³„
        forecast["mall_sales"]["net_sales_same_month_stats"] = calc_stats(mall_sales_same_month)
        
        # ì‘ë…„ ìµì›” ë§¤ì¶œ í†µê³„
        forecast["mall_sales"]["net_sales_next_month_stats"] = calc_stats(mall_sales_next_month)
        
        # ì‘ë…„ ë§¤ì¶œ ì¦ê°ë¥  ê³„ì‚°
        same_month_median = forecast["mall_sales"]["net_sales_same_month_stats"].get("median")
        next_month_median = forecast["mall_sales"]["net_sales_next_month_stats"].get("median")
        
        if same_month_median is not None and next_month_median is not None and same_month_median > 0:
            growth_pct = ((next_month_median - same_month_median) / same_month_median) * 100
            forecast["mall_sales"]["yoy_growth_pct"] = round(growth_pct, 2)
        else:
            forecast["mall_sales"]["yoy_growth_pct"] = None
        
        forecast["meta_ads"]["spend_same_month_stats"] = calc_stats(meta_ads_same_month)
        forecast["ga4_traffic"]["total_users_same_month_stats"] = calc_stats(ga4_traffic_same_month)
        
        return forecast
    
    forecast_next_month = build_forecast_next_month()
    
    # -----------------------
    # Signals (bool/ìˆ˜ì¹˜ë§Œ, íŒë‹¨ ë‹¨ì–´ ê¸ˆì§€)
    # -----------------------
    def calculate_signals():
        signals = {}
        
        # attention_without_conversion_exists
        viewitem_items = viewitem_this.get("top_items_by_view_item", [])
        signals["attention_without_conversion_exists"] = any(
            item.get("attention_without_conversion", False) for item in viewitem_items
        )
        
        # efficient_conversion_exists
        signals["efficient_conversion_exists"] = any(
            item.get("efficient_conversion", False) for item in viewitem_items
        )
        
        # high_attention_and_high_conversion_exists
        signals["high_attention_and_high_conversion_exists"] = any(
            item.get("high_attention_and_high_conversion", False) for item in viewitem_items
        )
        
        # meta_ads_interpretable_monthly
        if sales_this and meta_ads_this and (sales_this.get("net_sales") or 0) > 0:
            signals["meta_ads_interpretable_monthly"] = (
                (meta_ads_this.get("spend") or 0) >= (sales_this.get("net_sales") or 0) * 0.1
            )
        else:
            signals["meta_ads_interpretable_monthly"] = False
        
        # core_product_risk
        products_90d = products_this.get("rolling", {}).get("d90", {}).get("top_products_by_sales_with_role", [])
        core_products = [p for p in products_90d if p.get("role_90d") == "core"]
        signals["core_product_risk"] = any(
            p.get("is_declining") is True for p in core_products
        )
        
        # new_product_dependency
        # âš ï¸ 90d top ë¦¬ìŠ¤íŠ¸ ê¸°ì¤€ì´ë¯€ë¡œ "ì‹ ìƒí’ˆ" í™•ì •ì´ ì•„ë‹ˆë¼
        # "ìµœê·¼ 30d ìƒìœ„ê¶Œì—ë§Œ ë“±ì¥" ì •ë„ë¡œ í•´ì„í•˜ëŠ” ê²Œ ì•ˆì „
        products_30d = products_this.get("rolling", {}).get("d30", {}).get("top_products_by_sales", [])
        first_order_products = []
        total_30d_sales = sum(p.get("sales", 0) for p in products_30d)
        
        products_90d_map = {p.get("product_no"): p for p in products_90d}
        for p in products_30d:
            product_no = p.get("product_no")
            if product_no not in products_90d_map:
                first_order_products.append(p)
        
        first_order_sales = sum(p.get("sales", 0) for p in first_order_products)
        signals["new_product_dependency"] = (
            (first_order_sales / total_30d_sales * 100) >= 30
        ) if total_30d_sales > 0 else False
        
        # mall_sales_mom_pct (ìˆ˜ì¹˜ë§Œ)
        net_this = (sales_this or {}).get("net_sales", 0)
        net_prev = (sales_prev or {}).get("net_sales", 0)
        signals["mall_sales_mom_pct"] = ((net_this - net_prev) / net_prev * 100) if net_prev else None
        
        # note_if_base_small_mom
        signals["note_if_base_small_mom"] = note_if_base_small(net_prev, MALL_SALES_BASE_SMALL_THRESHOLD)
        
        return signals
    
    signals = calculate_signals()
    
    # -----------------------
    # 29CM í¬ë¡¤ë§ ì‹¤í–‰
    # -----------------------
    crawl_29cm_result = crawl_29cm_best()
    
    # -----------------------
    # Event ë°ì´í„° ì¡°íšŒ (ì§€ë‚œë‹¬ ì´ë²¤íŠ¸)
    # -----------------------
    def get_prev_month_events():
        """ì§€ë‚œë‹¬ ì´ë²¤íŠ¸ ì •ë³´ ì¡°íšŒ"""
        try:
            query = f"""
            SELECT 
                mall,
                date,
                event,
                event_first,
                event_end,
                memo
            FROM `{PROJECT_ID}.{DATASET}.sheets_event_data`
            WHERE mall = @company_name
              AND FORMAT_DATE('%Y-%m', date) = @prev_month
            ORDER BY event_first ASC, event ASC
            """
            
            rows = list(
                client.query(
                    query,
                    job_config=bigquery.QueryJobConfig(
                        query_parameters=[
                            bigquery.ScalarQueryParameter("company_name", "STRING", company_name),
                            bigquery.ScalarQueryParameter("prev_month", "STRING", prev_month),
                        ]
                    ),
                ).result()
            )
            
            events = []
            for row in rows:
                events.append({
                    "event": row.event,
                    "event_first": row.event_first.isoformat() if row.event_first else None,
                    "event_end": row.event_end.isoformat() if row.event_end else None,
                    "memo": row.memo if row.memo else None,
                })
            
            return {
                "month": prev_month,
                "events": events,
            } if events else None
        except Exception as e:
            print(f"âš ï¸ [WARN] Event ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}", file=sys.stderr)
            return None
    
    prev_month_events = get_prev_month_events()
    
    out = {
        "report_meta": {
            "company_name": company_name,
            "report_month": report_month,
            "period_this": {"from": this_start, "to": this_end},
            "period_prev": {"from": prev_start, "to": prev_end},
            "period_yoy": {"from": yoy_start, "to": yoy_end},
            "yoy_available": {
                "mall_sales": mall_sales_yoy_available,
                "meta_ads": meta_ads_yoy_available,
                "ga4_traffic": ga4_yoy_available,
            },
        },
        "facts": {
            "mall_sales": {
                "this": sales_this,
                "prev": sales_prev,
                "yoy": sales_yoy,
                "monthly_13m": monthly_13m,
                "daily_this": daily_this,
                "daily_prev": daily_prev,
                "daily_yoy": daily_yoy,
            },
            "meta_ads": {
                "this": meta_ads_this,
                "prev": meta_ads_prev,
                "yoy": meta_ads_yoy,
                "monthly_13m": monthly_13m_meta,
            },
            "meta_ads_goals": {
                "this": meta_ads_goals_this,
                "prev": meta_ads_goals_prev,
                "yoy": meta_ads_goals_yoy,
            },
            "meta_ads_benchmarks": meta_ads_benchmarks,
            "ga4_traffic": {
                "this": ga4_this,
                "prev": ga4_prev,
                "yoy": ga4_yoy,
                "monthly_13m": monthly_13m_ga4,
            },
            "products": {
                "this": products_this,
            },
            "viewitem": {
                "this": viewitem_this,
            },
            "comparisons": comparisons,
            "forecast_next_month": forecast_next_month,
            "29cm_best": crawl_29cm_result,
            "events": prev_month_events,
        },
        "signals": signals,
    }
    
    # -----------------------
    # Save to GCS (optional)
    # -----------------------
    def save_snapshot_to_gcs(company_name, year, month, snapshot_data):
        """ìŠ¤ëƒ…ìƒ·ì„ GCS ë²„í‚·ì— ì €ì¥ (Gzip ì••ì¶• ì ìš©)"""
        try:
            print(f"ğŸ” [DEBUG] GCS í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” í™•ì¸", file=sys.stderr)
            print(f"   í”„ë¡œì íŠ¸ ID: {PROJECT_ID}", file=sys.stderr)
            print(f"   ë²„í‚· ì´ë¦„: {GCS_BUCKET}", file=sys.stderr)
            
            # ë²„í‚· ì¡´ì¬ ì—¬ë¶€ í™•ì¸
            try:
                bucket = storage_client.bucket(GCS_BUCKET)
                # ë²„í‚· ì¡´ì¬ ì—¬ë¶€ í™•ì¸ (reloadë¡œ ì‹¤ì œ ì ‘ê·¼ ì‹œë„)
                bucket.reload()
                print(f"âœ… [DEBUG] ë²„í‚· ì¡´ì¬ í™•ì¸: {GCS_BUCKET}", file=sys.stderr)
            except Exception as bucket_error:
                print(f"âŒ [DEBUG] ë²„í‚· ì ‘ê·¼ ì‹¤íŒ¨: {type(bucket_error).__name__}: {bucket_error}", file=sys.stderr)
                raise
            
            # ê²½ë¡œ: ai-reports/monthly/{company}/{year}-{month:02d}/snapshot.json.gz
            blob_path = f"ai-reports/monthly/{company_name}/{year}-{month:02d}/snapshot.json.gz"
            
            # ê¸°ì¡´ íŒŒì¼ë“¤ ì‚­ì œ (snapshot.json, snapshot.json.gz ëª¨ë‘)
            old_paths = [
                f"ai-reports/monthly/{company_name}/{year}-{month:02d}/snapshot.json",
                f"ai-reports/monthly/{company_name}/{year}-{month:02d}/snapshot.json.gz",
            ]
            for old_path in old_paths:
                old_blob = bucket.blob(old_path)
                if old_blob.exists():
                    old_blob.delete()
                    print(f"ğŸ—‘ï¸  [INFO] ê¸°ì¡´ íŒŒì¼ ì‚­ì œ: {old_path}", file=sys.stderr)
            
            blob = bucket.blob(blob_path)
            
            print(f"ğŸ“¤ [INFO] GCS ì €ì¥ ì‹œì‘: {blob_path}", file=sys.stderr)
            
            # JSON ë¬¸ìì—´ ìƒì„±
            snapshot_json_str = json.dumps(snapshot_data, ensure_ascii=False, indent=2, sort_keys=True)
            
            # Gzip ì••ì¶•
            snapshot_gzip_bytes = gzip.compress(
                snapshot_json_str.encode('utf-8'),
                compresslevel=6  # ì••ì¶• ë ˆë²¨ (1-9, 6ì´ ì†ë„/ì••ì¶•ë¥  ê· í˜•)
            )
            
            # ì••ì¶• ì „í›„ í¬ê¸° ë¹„êµ (ë””ë²„ê·¸ìš©)
            original_size = len(snapshot_json_str.encode('utf-8'))
            compressed_size = len(snapshot_gzip_bytes)
            compression_ratio = (1 - compressed_size / original_size) * 100 if original_size > 0 else 0
            
            # Gzip ì••ì¶•ëœ ë°ì´í„° ì—…ë¡œë“œ
            # upload_from_string()ì— content_typeì„ ì¸ìë¡œ ì „ë‹¬í•´ì•¼ í•¨
            blob.content_encoding = 'gzip'
            blob.upload_from_string(
                snapshot_gzip_bytes,
                content_type='application/json'
            )
            
            gcs_url = f"gs://{GCS_BUCKET}/{blob_path}"
            print("=" * 80, file=sys.stderr)
            print(f"âœ… [SUCCESS] ìŠ¤ëƒ…ìƒ·ì´ GCSì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤", file=sys.stderr)
            print(f"   ğŸ“ ì €ì¥ ìœ„ì¹˜: {gcs_url}", file=sys.stderr)
            print(f"   ğŸ“¦ ë²„í‚·: {GCS_BUCKET}", file=sys.stderr)
            print(f"   ğŸ“ ê²½ë¡œ: {blob_path}", file=sys.stderr)
            if ENABLE_DEBUG_LOGS:
                print(f"   ì••ì¶• ì „: {original_size:,} bytes, ì••ì¶• í›„: {compressed_size:,} bytes ({compression_ratio:.1f}% ê°ì†Œ)", file=sys.stderr)
            print("=" * 80, file=sys.stderr)
            return gcs_url
        except Exception as e:
            print("=" * 80, file=sys.stderr)
            print(f"âŒ [ERROR] GCS ì €ì¥ ì‹¤íŒ¨", file=sys.stderr)
            print(f"   ğŸ“ ì‹œë„í•œ ì €ì¥ ìœ„ì¹˜: gs://{GCS_BUCKET}/ai-reports/monthly/{company_name}/{year}-{month:02d}/snapshot.json.gz", file=sys.stderr)
            print(f"   ğŸ“¦ ë²„í‚· ì´ë¦„: {GCS_BUCKET}", file=sys.stderr)
            print(f"   ğŸ” í”„ë¡œì íŠ¸ ID: {PROJECT_ID}", file=sys.stderr)
            print(f"   ì˜¤ë¥˜ íƒ€ì…: {type(e).__name__}", file=sys.stderr)
            print(f"   ì˜¤ë¥˜ ë©”ì‹œì§€: {str(e)}", file=sys.stderr)
            print("=" * 80, file=sys.stderr)
            import traceback
            print("ìƒì„¸ ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤:", file=sys.stderr)
            traceback.print_exc(file=sys.stderr)
            print("=" * 80, file=sys.stderr)
            return None
    
    # -----------------------
    # Upsert to BigQuery (optional)
    # -----------------------
    def upsert_snapshot(client, company_name, month_date_iso, snapshot_data):
        """ìŠ¤ëƒ…ìƒ·ì„ BigQueryì— upsert"""
        snapshot_data_safe = json_safe(snapshot_data)
        snapshot_json_str = json.dumps(snapshot_data_safe, ensure_ascii=False, sort_keys=True)
        snapshot_hash = hashlib.sha256(snapshot_json_str.encode('utf-8')).hexdigest()
        
        query = f"""
        MERGE `{PROJECT_ID}.{DATASET}.report_monthly_snapshot` T
        USING (
            SELECT
                @company_name AS company_name,
                DATE(@month_date) AS month,
                PARSE_JSON(@snapshot_json) AS snapshot_json,
                @snapshot_hash AS snapshot_hash,
                CURRENT_TIMESTAMP() AS updated_at
        ) S
        ON T.company_name = S.company_name AND T.month = S.month
        WHEN MATCHED THEN UPDATE SET
            snapshot_json = S.snapshot_json,
            snapshot_hash = S.snapshot_hash,
            updated_at = S.updated_at
        WHEN NOT MATCHED THEN
            INSERT (company_name, month, snapshot_json, snapshot_hash, updated_at)
            VALUES (S.company_name, S.month, S.snapshot_json, S.snapshot_hash, S.updated_at)
        """
        
        client.query(
            query,
            job_config=bigquery.QueryJobConfig(
                query_parameters=[
                    bigquery.ScalarQueryParameter("company_name", "STRING", company_name),
                    bigquery.ScalarQueryParameter("month_date", "STRING", month_date_iso),
                    bigquery.ScalarQueryParameter("snapshot_json", "STRING", snapshot_json_str),
                    bigquery.ScalarQueryParameter("snapshot_hash", "STRING", snapshot_hash),
                ]
            ),
        ).result()
    
    # JSON ì•ˆì „í™” ì ìš©
    out_safe = json_safe(out)
    
    if upsert_flag:
        month_date_iso = date(year, month, 1).isoformat()
        upsert_snapshot(client, company_name, month_date_iso, out)
    
    if save_to_gcs_flag:
        save_snapshot_to_gcs(company_name, year, month, out_safe)
    
    print("=" * 80, file=sys.stderr)
    print(f"âœ… [SUCCESS] ìŠ¤ëƒ…ìƒ· ìƒì„± ì™„ë£Œ: {company_name} {year}-{month:02d}", file=sys.stderr)
    print("=" * 80, file=sys.stderr)
    
    # ìˆ˜ì§‘ ë°ì´í„°ëŠ” ì½˜ì†”ì— ì¶œë ¥í•˜ì§€ ì•ŠìŒ (JSON íŒŒì¼ì—ë§Œ ì €ì¥)
    # ì „ì²´ JSONì´ í•„ìš”í•˜ë©´ GCSì—ì„œ ì§ì ‘ ë‹¤ìš´ë¡œë“œ: gs://{GCS_BUCKET}/ai-reports/monthly/{company_name}/{year}-{month:02d}/snapshot.json.gz


if __name__ == "__main__":
    if len(sys.argv) < 4:
        print("Usage: python3 bq_monthly_snapshot.py <company_name> <year> <month> [--upsert] [--save-to-gcs] [--force]")
        print("  --force: GCSì— ê¸°ì¡´ ìŠ¤ëƒ…ìƒ·ì´ ìˆì–´ë„ ì¬ìƒì„± (ê¸°ë³¸ê°’: GCSì—ì„œ ë¨¼ì € ì½ê¸°)")
        sys.exit(1)
    
    company_name = sys.argv[1]
    year = int(sys.argv[2])
    month = int(sys.argv[3])
    upsert_flag = "--upsert" in sys.argv
    save_to_gcs_flag = "--save-to-gcs" in sys.argv
    force_flag = "--force" in sys.argv  # ì¬ìƒì„± í”Œë˜ê·¸
    
    # --force í”Œë˜ê·¸ê°€ ìˆìœ¼ë©´ GCSì—ì„œ ì½ì§€ ì•Šê³  ì¬ìƒì„±
    load_from_gcs_flag = not force_flag
    
    run(company_name, year, month, upsert_flag, save_to_gcs_flag, load_from_gcs_flag)
