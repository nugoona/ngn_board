import sys
import os
import json
import requests
from google.cloud import bigquery, storage
from datetime import datetime, timedelta, timezone
import logging

# âœ… í•œêµ­ ì‹œê°„ëŒ€ ì„¤ì •
KST = timezone(timedelta(hours=9))
current_time = datetime.now(timezone.utc).astimezone(KST)

# âœ… ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")

# âœ… ë¡œê·¸ íŒŒì¼ ê²½ë¡œ
LOG_FILE = "/home/oscar/ngn_board/ngn_wep/logs/product_data_handler.log"
if not os.path.exists(os.path.dirname(LOG_FILE)):
    os.makedirs(os.path.dirname(LOG_FILE))

# âœ… GCP ì¸ì¦ ì •ë³´
GOOGLE_APPLICATION_CREDENTIALS = os.getenv("GOOGLE_APPLICATION_CREDENTIALS", "/home/oscar/ngn_board/service-account.json")
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = GOOGLE_APPLICATION_CREDENTIALS

# âœ… GCP ì„¤ì •
BUCKET_NAME = "winged-precept-443218-v8.appspot.com"
TOKEN_FILE_NAME = "tokens.json"

# âœ… BigQuery í´ë¼ì´ì–¸íŠ¸
client = bigquery.Client.from_service_account_json(GOOGLE_APPLICATION_CREDENTIALS)

# âœ… Cloud Storageì—ì„œ tokens.json ë‹¤ìš´ë¡œë“œ
def download_tokens():
    storage_client = storage.Client()
    bucket = storage_client.bucket(BUCKET_NAME)
    blob = bucket.blob(TOKEN_FILE_NAME)

    try:
        token_data = blob.download_as_text()
        logging.info(f"{TOKEN_FILE_NAME} íŒŒì¼ì´ GCP ë²„í‚·ì—ì„œ ë‹¤ìš´ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
        tokens = json.loads(token_data)
        if isinstance(tokens, list):
            return tokens
        else:
            raise ValueError("âŒ í† í° íŒŒì¼ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    except Exception as e:
        logging.error(f"âŒ í† í° íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        return []

# âœ… tokens.json ê²½ë¡œ ì„¤ì •
tokens_path = download_tokens()
TOKENS_JSON_PATH = tokens_path if tokens_path else TOKEN_FILE_NAME

# âœ… BigQuery ì„¤ì •
PROJECT_ID = "winged-precept-443218-v8"
DATASET_ID = "ngn_dataset"
ITEMS_TABLE_ID = "cafe24_order_items_table"
TEMP_TABLE_ID = "temp_order_items_table"

# âœ… tokens.json ë¡œë“œ
def load_tokens():
    storage_client = storage.Client()
    bucket = storage_client.bucket(BUCKET_NAME)
    blob = bucket.blob(TOKEN_FILE_NAME)

    try:
        token_data = blob.download_as_text()
        tokens = json.loads(token_data)
        if isinstance(tokens, list):
            return {token["mall_id"]: token for token in tokens if "mall_id" in token}
        else:
            raise ValueError("âŒ í† í° íŒŒì¼ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    except json.JSONDecodeError as e:
        logging.error(f"âŒ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
    except Exception as e:
        logging.error(f"âŒ í† í° ë¡œë”© ì˜¤ë¥˜: {e}")
    return {}

# âœ… íŠ¹ì • mall_id í† í° ì •ë³´ ê°€ì ¸ì˜¤ê¸°
def get_token_info(mall_id):
    tokens = load_tokens()
    return tokens.get(mall_id)

# âœ… ë‚ ì§œ íŒŒì‹± í•¨ìˆ˜
def parse_date(date_value):
    if not date_value:
        return None
    try:
        dt_kst = datetime.strptime(date_value, "%Y-%m-%dT%H:%M:%S%z")
        dt_utc = dt_kst.astimezone(timezone.utc)
        return dt_utc.strftime("%Y-%m-%dT%H:%M:%S.%fZ")
    except Exception as e:
        logging.error(f"âŒ ë‚ ì§œ ë³€í™˜ ì˜¤ë¥˜: {e}, ìž…ë ¥ê°’: {date_value}")
        return None

# âœ… ì£¼ë¬¸ ID ê°€ì ¸ì˜¤ê¸°
def fetch_order_ids(mall_id, start_date, end_date):
    token_info = get_token_info(mall_id)
    if not token_info:
        logging.error(f"âŒ {mall_id} - í† í° ì •ë³´ ëˆ„ë½")
        return []

    access_token = token_info["access_token"]
    headers = {"Authorization": f"Bearer {access_token}", "Content-Type": "application/json"}
    url = f"https://{mall_id}.cafe24api.com/api/v2/admin/orders"
    params = {
        "start_date": f"{start_date}T00:00:00+09:00",
        "end_date": f"{end_date}T23:59:59+09:00",
        "limit": 100,
        "include_fields": "order_id"
    }

    order_ids = []
    offset = 0

    while True:
        params["offset"] = offset
        response = requests.get(url, headers=headers, params=params)

        if response.status_code != 200:
            logging.error(f"âŒ {mall_id} - ì£¼ë¬¸ ID ì¡°íšŒ ì‹¤íŒ¨: {response.status_code}, {response.text}")
            break

        orders = response.json().get("orders", [])
        if not orders:
            break

        order_ids.extend([order["order_id"] for order in orders])
        offset += len(orders)

    logging.info(f"âœ… {mall_id} - {len(order_ids)}ê°œì˜ ì£¼ë¬¸ ID ìˆ˜ì§‘ ì™„ë£Œ")
    return order_ids

# âœ… ì£¼ë¬¸ ìƒí’ˆ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
def fetch_order_items(mall_id, order_id, retries=3):
    token_info = get_token_info(mall_id)
    if not token_info:
        logging.error(f"âŒ {mall_id} - í† í° ì •ë³´ ëˆ„ë½")
        return []

    access_token = token_info["access_token"]
    headers = {"Authorization": f"Bearer {access_token}", "Content-Type": "application/json"}
    url = f"https://{mall_id}.cafe24api.com/api/v2/admin/orders/{order_id}/items"

    for attempt in range(retries):
        response = requests.get(url, headers=headers)
        if response.status_code == 200:
            items = response.json().get("items", [])
            for item in items:
                item["mall_id"] = mall_id
                item["order_id"] = order_id
            return items
        else:
            logging.warning(f"âš ï¸ {mall_id} - ì£¼ë¬¸ ìƒí’ˆ ì¡°íšŒ ì‹¤íŒ¨ (ì‹œë„ {attempt+1}/{retries}): {response.status_code}")

    logging.error(f"âŒ {mall_id} - ì£¼ë¬¸ ìƒí’ˆ ì¡°íšŒ ì‹¤íŒ¨ (order_id: {order_id})")
    return []

# âœ… BigQuery ìž„ì‹œ í…Œì´ë¸” ì—…ë¡œë“œ
def upload_to_temp_table(mall_id, items_data):
    if not items_data:
        logging.warning(f"âš ï¸ {mall_id} - ì „ì†¡í•  ë°ì´í„° ì—†ìŒ")
        return

    transformed_data = []
    for item in items_data:
        try:
            transformed_data.append({
                "mall_id": mall_id,
                "order_id": item.get("order_id"),
                "order_item_code": item.get("order_item_code"),
                "product_no": item.get("product_no"),
                "product_name": item.get("product_name"),
                "product_price": float(item.get("product_price") or 0),
                "additional_discount_price": float(item.get("additional_discount_price") or 0),
                "coupon_discount_price": float(item.get("coupon_discount_price") or 0),
                "app_item_discount_amount": float(item.get("app_item_discount_amount") or 0),
                "individual_shipping_fee": float(item.get("individual_shipping_fee") or 0),
                "quantity": int(item.get("quantity") or 0),
                "ordered_date": parse_date(item.get("ordered_date")),
                "payment_amount": float(item.get("payment_amount") or 0),
                "claim_code": item.get("claim_code"),
                "status_code": item.get("status_code")
            })
        except Exception as e:
            logging.error(f"âŒ {mall_id} - ë°ì´í„° ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    if not transformed_data:
        logging.warning(f"âš ï¸ {mall_id} - ë³€í™˜ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    table_ref = f"{PROJECT_ID}.{DATASET_ID}.{TEMP_TABLE_ID}"
    errors = client.insert_rows_json(table_ref, transformed_data)

    if errors:
        logging.error(f"âŒ {mall_id} - BigQuery ì—…ë¡œë“œ ì‹¤íŒ¨: {errors}")
    else:
        logging.info(f"âœ… {mall_id} - BigQuery ìž„ì‹œ í…Œì´ë¸” ì—…ë¡œë“œ ì„±ê³µ!")

# âœ… BigQuery ë³‘í•©
def merge_temp_to_main_table():
    query = f"""
    MERGE `{PROJECT_ID}.{DATASET_ID}.{ITEMS_TABLE_ID}` AS target
    USING (
        SELECT * EXCEPT(row_num)
        FROM (
            SELECT *, ROW_NUMBER() OVER (PARTITION BY mall_id, order_item_code ORDER BY ordered_date DESC) AS row_num
            FROM `{PROJECT_ID}.{DATASET_ID}.{TEMP_TABLE_ID}`
        )
        WHERE row_num = 1
    ) AS source
    ON target.mall_id = source.mall_id 
       AND target.order_item_code = source.order_item_code
       AND (target.ordered_date IS NULL OR DATE(target.ordered_date) >= DATE_SUB(CURRENT_DATE(), INTERVAL 2 DAY))

    WHEN MATCHED THEN
    UPDATE SET
        target.order_id = source.order_id,
        target.product_no = source.product_no,
        target.product_name = source.product_name,
        target.product_price = source.product_price,
        target.additional_discount_price = source.additional_discount_price,
        target.coupon_discount_price = source.coupon_discount_price,
        target.app_item_discount_amount = source.app_item_discount_amount,
        target.individual_shipping_fee = source.individual_shipping_fee,
        target.quantity = source.quantity,
        target.ordered_date = source.ordered_date,
        target.payment_amount = source.payment_amount,
        target.claim_code = COALESCE(source.claim_code, target.claim_code),
        target.status_code = COALESCE(source.status_code, target.status_code)

    WHEN NOT MATCHED THEN
    INSERT (
        mall_id, order_id, order_item_code, product_no, product_name,
        product_price, additional_discount_price, coupon_discount_price,
        app_item_discount_amount, individual_shipping_fee, quantity,
        ordered_date, payment_amount, claim_code, status_code
    )
    VALUES (
        source.mall_id, source.order_id, source.order_item_code, source.product_no, source.product_name,
        source.product_price, source.additional_discount_price, source.coupon_discount_price,
        source.app_item_discount_amount, source.individual_shipping_fee, source.quantity,
        source.ordered_date, source.payment_amount, source.claim_code, source.status_code
    );
    """
    try:
        client.query(query).result()
        logging.info("âœ… ìž„ì‹œ í…Œì´ë¸” ë°ì´í„°ë¥¼ ë©”ì¸ í…Œì´ë¸”ë¡œ ë³‘í•© ì™„ë£Œ!")
    except Exception as e:
        logging.error(f"âŒ ë³‘í•© ì‹¤íŒ¨: {e}")

# âœ… ì‹¤í–‰ í•¨ìˆ˜
def main(process_type="today"):
    today = datetime.now(KST).strftime("%Y-%m-%d")
    yesterday = (datetime.now(KST) - timedelta(days=1)).strftime("%Y-%m-%d")
    start_date_7 = (datetime.now(KST) - timedelta(days=6)).strftime("%Y-%m-%d")

    tokens = load_tokens()
    if not tokens:
        logging.error("âŒ í† í° ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return

    for mall_id in tokens:
        logging.info(f"ðŸš€ {mall_id} - ì œí’ˆ ë°ì´í„° ì²˜ë¦¬ ì‹œìž‘...")

        if process_type == "today":
            logging.info(f"ðŸ“… {mall_id} - ì˜¤ëŠ˜({today}) ì£¼ë¬¸ ID ê°€ì ¸ì˜¤ëŠ” ì¤‘...")
            order_ids = fetch_order_ids(mall_id, today, today)

        elif process_type == "yesterday":
            logging.info(f"ðŸ“… {mall_id} - ì–´ì œ({yesterday}) ì£¼ë¬¸ ID ê°€ì ¸ì˜¤ëŠ” ì¤‘...")
            order_ids = fetch_order_ids(mall_id, yesterday, yesterday)

        elif process_type == "last_7_days":
            logging.info(f"ðŸ“… {mall_id} - ìµœê·¼ 7ì¼({start_date_7} ~ {today}) ì£¼ë¬¸ ID ê°€ì ¸ì˜¤ëŠ” ì¤‘...")
            order_ids = fetch_order_ids(mall_id, start_date_7, today)

        all_items = []
        for order_id in order_ids:
            all_items.extend(fetch_order_items(mall_id, order_id))

        upload_to_temp_table(mall_id, all_items)

    merge_temp_to_main_table()
    logging.info("ðŸŽ‰ ëª¨ë“  ìž‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

if __name__ == "__main__":
    process_type = sys.argv[1] if len(sys.argv) > 1 else "today"
    main(process_type)
