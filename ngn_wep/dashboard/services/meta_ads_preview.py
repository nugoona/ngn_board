import os
import logging
import requests
from requests.exceptions import RequestException, Timeout, ConnectionError as RequestsConnectionError
from google.cloud import bigquery
from concurrent.futures import ThreadPoolExecutor, as_completed
import time
from urllib.parse import quote
from collections import defaultdict
import threading

# âœ… ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)

# âœ… Cloud Runì—ì„œëŠ” í‚¤ íŒŒì¼ ëŒ€ì‹  ëŸ°íƒ€ì„ ì„œë¹„ìŠ¤ê³„ì •(ADC)ì„ ì‚¬ìš©
# GOOGLE_APPLICATION_CREDENTIALS í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì–´ ìˆìœ¼ë©´ ì œê±°í•˜ì—¬ ADC ì‚¬ìš©
creds_path = os.environ.get("GOOGLE_APPLICATION_CREDENTIALS")
if creds_path and not os.path.exists(creds_path):
    os.environ.pop("GOOGLE_APPLICATION_CREDENTIALS", None)

# âš ï¸ ì „ì—­ ìºì‹± ì œê±° - í˜¸ì¶œ ì‹œì ì— í† í°ì„ ì½ë„ë¡ ë³€ê²½
# META_ACCESS_TOKEN = os.getenv("META_SYSTEM_USER_TOKEN")  # DEPRECATED

# âœ… í† í° ë¡œê·¸ ì¶œë ¥ ì—¬ë¶€ (1íšŒë§Œ ì¶œë ¥)
_token_logged = False


def _get_meta_access_token():
    """
    Meta API ì•¡ì„¸ìŠ¤ í† í°ì„ í™˜ê²½ë³€ìˆ˜ì—ì„œ ì½ì–´ ë°˜í™˜í•©ë‹ˆë‹¤.
    í† í°ì´ ì—†ìœ¼ë©´ RuntimeErrorë¥¼ ë°œìƒì‹œí‚µë‹ˆë‹¤.
    """
    global _token_logged
    token = os.getenv("META_SYSTEM_USER_TOKEN")
    if not token:
        logger.error("[META_API] META_SYSTEM_USER_TOKEN í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
        raise RuntimeError("META_SYSTEM_USER_TOKEN í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Cloud Run í™˜ê²½ë³€ìˆ˜ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    
    # âœ… í† í° ì• 8ìë§Œ 1íšŒ ì¶œë ¥ (ë³´ì•ˆìƒ ì „ì²´ ì¶œë ¥ ê¸ˆì§€)
    if not _token_logged:
        token_head = token[:8] if len(token) >= 8 else token
        logger.warning(f"[META_API][TOKEN] í† í° ë¡œë“œ ì™„ë£Œ: token_head={token_head}..., length={len(token)}")
        _token_logged = True
    
    return token


def _safe_meta_api_get(url, timeout=3, context=""):
    """
    Meta Graph API GET ìš”ì²­ì„ ìˆ˜í–‰í•˜ê³ , ì—ëŸ¬ ë°œìƒ ì‹œ ìƒì„¸ ë¡œê·¸ë¥¼ ë‚¨ê¹ë‹ˆë‹¤.
    
    Returns:
        tuple: (data, error_reason) - ì„±ê³µ ì‹œ (dict, None), ì‹¤íŒ¨ ì‹œ (None, "reason_string")
    """
    try:
        resp = requests.get(url, timeout=timeout)
        
        # âœ… HTTP ìƒíƒœ ì½”ë“œ ì²´í¬
        if resp.status_code != 200:
            reason = f"http_{resp.status_code}"
            logger.error(
                f"[META_API][HTTP_ERROR] ({context}): "
                f"status_code={resp.status_code}, url={url[:100]}..., "
                f"body={resp.text[:500]}"
            )
            return None, reason
        
        data = resp.json()
        
        # âœ… API ì—ëŸ¬ ì²´í¬
        if "error" in data:
            error_info = data.get("error", {})
            reason = f"api_error_{error_info.get('code', 'unknown')}"
            logger.error(
                f"[META_API][API_ERROR] ({context}): "
                f"code={error_info.get('code')}, type={error_info.get('type')}, "
                f"message={error_info.get('message')}, "
                f"error_subcode={error_info.get('error_subcode')}"
            )
            return None, reason
        
        return data, None
    
    except Timeout as e:
        logger.exception(f"[META_API][TIMEOUT] ({context}): url={url[:100]}...")
        return None, "timeout"
    except RequestsConnectionError as e:
        logger.exception(f"[META_API][CONN_ERROR] ({context}): url={url[:100]}...")
        return None, "connection_error"
    except RequestException as e:
        logger.exception(f"[META_API][REQ_ERROR] ({context}): url={url[:100]}...")
        return None, "request_exception"
    except ValueError as e:
        # JSON íŒŒì‹± ì—ëŸ¬
        logger.exception(f"[META_API][JSON_ERROR] ({context}): url={url[:100]}...")
        return None, "json_parse_error"
    except Exception as e:
        logger.exception(f"[META_API][EXCEPTION] ({context}): {type(e).__name__}")
        return None, f"exception_{type(e).__name__}"


def get_proxy_image_url(image_url):
    """
    ì´ë¯¸ì§€ URLì„ í”„ë¡ì‹œ URLë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    ë°°í¬ í™˜ê²½ì—ì„œ CORS ë° Mixed Content ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    if not image_url or image_url.strip() == "":
        return ""
    
    # ë¡œì»¬ íŒŒì¼ ê²½ë¡œì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ë°˜í™˜
    if image_url.startswith("/static/"):
        return image_url
    
    # ì™¸ë¶€ URLì¸ ê²½ìš° í”„ë¡ì‹œ URLë¡œ ë³€í™˜
    # URL ì¸ì½”ë”©í•˜ì—¬ í”„ë¡ì‹œ ì—”ë“œí¬ì¸íŠ¸ì— ì „ë‹¬
    encoded_url = quote(image_url, safe='')
    return f"/dashboard/proxy_image?url={encoded_url}"


def get_meta_ads_preview_list(account_id):
    """
    ì£¼ì–´ì§„ account_idì— ëŒ€í•´ ì˜¤ëŠ˜ í™œì„±í™”ëœ 'ë‹¨ì¼', 'ì˜ìƒ' ê´‘ê³ ë¥¼ ì¡°íšŒí•˜ê³ ,
    ê´‘ê³  ì¸ë„¤ì¼, ë¬¸êµ¬, ë§í¬ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. (ìµœì í™”ëœ ë²„ì „)
    """
    start_time = time.time()
    logger.warning(f"[META_API][START] LIVE ê´‘ê³  ë¯¸ë¦¬ë³´ê¸° ìš”ì²­ ì‹œì‘: account_id={account_id}")
    
    client = bigquery.Client()

    # âœ… ë¨¼ì € í•´ë‹¹ account_idì˜ company_nameì´ demoì¸ì§€ í™•ì¸ (ê³„ì • ë§¤ì¹­ ê²€ì¦ ê°•í™”)
    company_check_query = """
        SELECT company_name, meta_acc_id
        FROM `winged-precept-443218-v8.ngn_dataset.metaAds_acc`
        WHERE meta_acc_id = @account_id
        LIMIT 1
    """
    company_check_params = [
        bigquery.ScalarQueryParameter("account_id", "STRING", account_id)
    ]
    company_result = client.query(
        company_check_query,
        job_config=bigquery.QueryJobConfig(query_parameters=company_check_params)
    ).result()
    company_data = next(iter(company_result), {})
    company_name = company_data.get("company_name", None)
    verified_account_id = company_data.get("meta_acc_id", None)
    
    # âœ… ê³„ì • ë§¤ì¹­ ê²€ì¦
    if not verified_account_id or verified_account_id != account_id:
        logger.error(f"[META_API][ERROR] ê³„ì • ë§¤ì¹­ ì‹¤íŒ¨: ìš”ì²­ëœ account_id={account_id}, ê²€ì¦ëœ account_id={verified_account_id}")
        return []
    
    logger.warning(f"[META_API][VERIFIED] ê³„ì • ê²€ì¦ ì™„ë£Œ: {account_id} -> {company_name}")

    # âœ… ë°ëª¨ ê³„ì •ì´ë©´ ê³ ì • ê´‘ê³  8ê°œ ë°˜í™˜
    if company_name == "demo":
        logger.warning("[META_API][DEMO] ë°ëª¨ ê³„ì • - ê³ ì • ê´‘ê³  ë°˜í™˜")
        ad_names = [f"[ë‹¨ì¼] NGN ì¸ìŠ¤íƒ€ ê´‘ê³  {chr(65+i)}" for i in range(8)]  # A ~ H
        image_urls = [f"/static/demo_ads/demo_{i+1}.jpg" for i in range(8)]
        message = "â˜…ì¸ìŠ¤íƒ€ê´‘ê³ ëŠ” ëˆ„êµ¬ë‚˜ì»´í¼ë‹ˆâ˜…"
        link = "https://www.nugoona.co.kr/"

        dummy_ads = []
        for i in range(8):
            dummy_ads.append({
                "ad_id": f"demo_ad_{i+1}",
                "ad_name": ad_names[i],
                "instagram_acc_name": "NGN_COMPANY",
                "message": message,
                "link": link,
                "image_url": image_urls[i],
                "is_video": False
            })
        return dummy_ads

    # âœ… ì¼ë°˜ ê³„ì •ì¼ ê²½ìš° ì‹¤ì œ ê´‘ê³  ê°€ì ¸ì˜¤ê¸° (ìµœì í™”ëœ ì¿¼ë¦¬)
    query = """
        WITH today_ads AS (
          SELECT
            A.date,
            C.company_name,
            CI.instagram_acc_name,
            A.account_id,
            A.ad_name,
            A.ad_id,
            A.ad_status,
            A.spend
          FROM `winged-precept-443218-v8.ngn_dataset.meta_ads_ad_level` A
          LEFT JOIN `winged-precept-443218-v8.ngn_dataset.metaAds_acc` C
            ON A.account_id = C.meta_acc_id
          LEFT JOIN `winged-precept-443218-v8.ngn_dataset.company_info` CI
            ON C.company_name = CI.company_name
          WHERE
            A.date = CURRENT_DATE('Asia/Seoul')
            AND A.ad_status = 'ACTIVE'
            AND A.spend > 0
            AND A.account_id = @account_id
            AND (LOWER(A.ad_name) LIKE '%ë‹¨ì¼%' OR LOWER(A.ad_name) LIKE '%ì˜ìƒ%')
        )
        SELECT
          FORMAT_DATE('%Y-%m-%d', ANY_VALUE(date)) AS date,
          ANY_VALUE(company_name) AS company_name,
          ANY_VALUE(instagram_acc_name) AS instagram_acc_name,
          ANY_VALUE(account_id) AS account_id,
          ad_name,
          ANY_VALUE(ad_id) AS ad_id,
          ANY_VALUE(ad_status) AS ad_status,
          SUM(spend) AS total_spend
        FROM today_ads
        GROUP BY ad_name
        ORDER BY total_spend DESC
        LIMIT 10
    """
    ads_query_params = [
        bigquery.ScalarQueryParameter("account_id", "STRING", account_id)
    ]

    logger.warning("[META_API][BIGQUERY] ê´‘ê³  ëª©ë¡ ì¡°íšŒ ì‹œì‘")
    query_start = time.time()
    ads = client.query(
        query,
        job_config=bigquery.QueryJobConfig(query_parameters=ads_query_params)
    ).result()
    
    # âœ… BigQuery ê²°ê³¼ë¥¼ ad_listë¡œ ë³€í™˜í•˜ë©´ì„œ ìƒì„¸ ë¡œê¹…
    ad_list = []
    raw_row_count = 0
    filtered_count = 0
    
    for row in ads:
        raw_row_count += 1
        try:
            ad_dict = dict(row)
            ad_id = ad_dict.get("ad_id")
            
            # ad_idê°€ ì—†ìœ¼ë©´ í•„í„°ë§ ë¡œê·¸
            if not ad_id:
                filtered_count += 1
                logger.warning(
                    f"[META_API][FILTERED_BEFORE_PARALLEL] "
                    f"idx={raw_row_count-1}, reason=missing_ad_id, "
                    f"keys={list(ad_dict.keys())}, "
                    f"ad_name={ad_dict.get('ad_name', 'N/A')[:40]}"
                )
                continue  # ad_id ì—†ìœ¼ë©´ ìŠ¤í‚µ
            
            ad_list.append(ad_dict)
            
        except Exception as e:
            filtered_count += 1
            logger.warning(
                f"[META_API][FILTERED_BEFORE_PARALLEL] "
                f"idx={raw_row_count-1}, reason=dict_conversion_error, "
                f"error={type(e).__name__}: {e}"
            )
            continue
    
    query_time = time.time() - query_start
    logger.warning(
        f"[META_API][BIGQUERY] ê´‘ê³  ëª©ë¡ ì¡°íšŒ ì™„ë£Œ: "
        f"raw_rows={raw_row_count}, valid_ads={len(ad_list)}, filtered={filtered_count}, "
        f"query_time={query_time:.2f}ì´ˆ"
    )
    
    # ë””ë²„ê¹…: ì¡°íšŒëœ ê´‘ê³  ëª©ë¡ ì¶œë ¥
    if ad_list:
        logger.warning(f"[META_API][BIGQUERY] ì¡°íšŒëœ ê´‘ê³  ëª©ë¡ (ìµœëŒ€ 5ê°œ):")
        for idx, ad in enumerate(ad_list[:5], 1):
            logger.warning(
                f"[META_API][BIGQUERY]   {idx}. "
                f"ad_id={ad.get('ad_id')}, "
                f"ad_name={ad.get('ad_name', '')[:50]}, "
                f"account_id={ad.get('account_id')}"
            )
    else:
        logger.warning(f"[META_API][BIGQUERY] âš ï¸ ê´‘ê³  ëª©ë¡ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. account_id={account_id}, raw_rows={raw_row_count}, ì¿¼ë¦¬ ì¡°ê±´ í™•ì¸ í•„ìš”")

    if not ad_list:
        logger.warning("[META_API][RESULT] í™œì„± ê´‘ê³  ì—†ìŒ")
        return []

    # âœ… [PRE_FILTER] ë³‘ë ¬ ì²˜ë¦¬ ì§ì „ ad_list ìƒíƒœ ê°•ì œ ë¡œê¹…
    logger.warning(f"[META_API][PRE_FILTER] ========== ë³‘ë ¬ ì²˜ë¦¬ ì§ì „ ad_list ê²€ì‚¬ ì‹œì‘ ==========")
    logger.warning(f"[META_API][PRE_FILTER] total_ads={len(ad_list)}, ad_list_type={type(ad_list).__name__}")
    
    for idx, ad in enumerate(ad_list[:3]):
        ad_id_val = ad.get("ad_id") if isinstance(ad, dict) else None
        ad_name_val = ad.get("ad_name", "N/A")[:40] if isinstance(ad, dict) else "N/A"
        account_id_val = ad.get("account_id") if isinstance(ad, dict) else None
        has_creative_id = "creative_id" in ad if isinstance(ad, dict) else False
        has_creative = "creative" in ad if isinstance(ad, dict) else False
        has_object_story_spec = "object_story_spec" in ad if isinstance(ad, dict) else False
        ad_keys = list(ad.keys()) if isinstance(ad, dict) else []
        
        logger.warning(
            f"[META_API][PRE_FILTER] idx={idx}, "
            f"ad_id={ad_id_val}, "
            f"account_id={account_id_val}, "
            f"ad_name={ad_name_val}, "
            f"has_creative_id={has_creative_id}, "
            f"has_creative={has_creative}, "
            f"has_object_story_spec={has_object_story_spec}, "
            f"ad_type={type(ad).__name__}, "
            f"keys={ad_keys}"
        )
    
    # ad_list ìš”ì†Œ ì¤‘ ad_idê°€ ì—†ëŠ” ê²ƒì´ ìˆëŠ”ì§€ ì‚¬ì „ ê²€ì‚¬
    ads_without_id = [i for i, ad in enumerate(ad_list) if not (isinstance(ad, dict) and ad.get("ad_id"))]
    if ads_without_id:
        logger.warning(f"[META_API][PRE_FILTER] âš ï¸ ad_id ëˆ„ë½ëœ ì¸ë±ìŠ¤: {ads_without_id[:10]}... (ì´ {len(ads_without_id)}ê°œ)")
    else:
        logger.warning(f"[META_API][PRE_FILTER] âœ… ëª¨ë“  ê´‘ê³ ì— ad_id ì¡´ì¬í•¨")
    
    logger.warning(f"[META_API][PRE_FILTER] ========== ë³‘ë ¬ ì²˜ë¦¬ ì§ì „ ad_list ê²€ì‚¬ ì™„ë£Œ ==========")

    # âœ… ë³‘ë ¬ ì²˜ë¦¬ë¡œ Meta API í˜¸ì¶œ ìµœì í™”
    logger.warning("[META_API][PARALLEL] ë³‘ë ¬ ì²˜ë¦¬ë¡œ ê´‘ê³  ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ ì‹œì‘")
    api_start = time.time()
    results = get_ads_details_parallel(ad_list)
    api_time = time.time() - api_start
    logger.warning(f"[META_API][PARALLEL] ê´‘ê³  ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ: {len(results)}ê°œ, {api_time:.2f}ì´ˆ")
    
    total_time = time.time() - start_time
    logger.warning(f"[META_API][DONE] ì „ì²´ ì²˜ë¦¬ ì™„ë£Œ: {total_time:.2f}ì´ˆ")
    
    return results


def get_ads_details_parallel(ad_list):
    """
    ë³‘ë ¬ ì²˜ë¦¬ë¡œ ê´‘ê³  ìƒì„¸ ì •ë³´ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
    """
    total_count = len(ad_list)
    start_time = time.time()
    logger.warning(f"[META_API][PARALLEL_START] get_ads_details_parallel ì‹œì‘: {total_count}ê°œ ê´‘ê³  ì²˜ë¦¬")
    
    if not ad_list:
        logger.warning("[META_API][PARALLEL_EMPTY] âš ï¸ ad_listê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤!")
        return []
    
    # âœ… [INPUT] ì²« 3ê°œ ê´‘ê³  ìƒ˜í”Œ ë””ë²„ê·¸ ë¡œê·¸
    for idx, ad in enumerate(ad_list[:3]):
        ad_id_val = ad.get("ad_id") if isinstance(ad, dict) else None
        has_creative_id = "creative_id" in ad if isinstance(ad, dict) else False
        has_creative = "creative" in ad if isinstance(ad, dict) else False
        ad_keys = list(ad.keys()) if isinstance(ad, dict) else []
        logger.warning(
            f"[META_API][INPUT] idx={idx}, "
            f"ad_id={ad_id_val}, "
            f"has_creative_id={has_creative_id}, "
            f"has_creative={has_creative}, "
            f"ad_type={type(ad).__name__}, "
            f"keys={ad_keys}"
        )
    
    results = []
    success_count = 0
    fail_count = 0
    
    # âœ… ìŠ¤í‚µ ì‚¬ìœ ë³„ ì¹´ìš´íŠ¸ (thread-safe)
    skip_reasons = defaultdict(int)
    skip_reasons_lock = threading.Lock()
    
    # ThreadPoolExecutorë¥¼ ì‚¬ìš©í•œ ë³‘ë ¬ ì²˜ë¦¬
    logger.warning(f"[META_API][EXECUTOR] ThreadPoolExecutor ì‹œì‘ (max_workers=5)")
    with ThreadPoolExecutor(max_workers=5) as executor:
        # ê° ê´‘ê³ ì— ëŒ€í•´ ë³‘ë ¬ë¡œ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘
        future_to_ad = {
            executor.submit(get_single_ad_details, ad): ad 
            for ad in ad_list
        }
        logger.warning(f"[META_API][EXECUTOR] {len(future_to_ad)}ê°œ future ìƒì„± ì™„ë£Œ")
        
        # ì™„ë£Œëœ ì‘ì—…ë“¤ì„ ìˆœì„œëŒ€ë¡œ ì²˜ë¦¬
        processed_count = 0
        for future in as_completed(future_to_ad):
            ad = future_to_ad[future]
            ad_id_for_log = ad.get("ad_id", "UNKNOWN") if isinstance(ad, dict) else "INVALID"
            processed_count += 1
            
            try:
                result, skip_reason = future.result()
                if result:  # ìœ íš¨í•œ ê²°ê³¼ë§Œ ì¶”ê°€
                    results.append(result)
                    success_count += 1
                    logger.warning(f"[META_API][SUCCESS] ad_id={ad_id_for_log} (processed={processed_count}/{total_count})")
                else:
                    fail_count += 1
                    # âœ… [NONE] resultê°€ Noneì¸ ê²½ìš° ìƒì„¸ ë¡œê¹…
                    logger.warning(
                        f"[META_API][NONE] ad_id={ad_id_for_log}, "
                        f"skip_reason={skip_reason}, "
                        f"processed={processed_count}/{total_count}"
                    )
                    # âœ… ìŠ¤í‚µ ì‚¬ìœ  ì¹´ìš´íŠ¸
                    with skip_reasons_lock:
                        skip_reasons[skip_reason or "unknown"] += 1
            except RuntimeError as e:
                # í† í° ëˆ„ë½ ì‹œ ì¦‰ì‹œ ì—ëŸ¬ ì „íŒŒ (ì¡°ìš©íˆ 0ê°œ ë°˜í™˜ ê¸ˆì§€)
                logger.error(f"[META_API][RUNTIME_ERROR] í† í° ì—ëŸ¬ë¡œ ì²˜ë¦¬ ì¤‘ë‹¨: ad_id={ad_id_for_log}, error={e}")
                raise
            except Exception as e:
                fail_count += 1
                with skip_reasons_lock:
                    skip_reasons[f"exception_{type(e).__name__}"] += 1
                logger.exception(
                    f"[META_API][FUTURE_EXCEPTION] ad_id={ad_id_for_log}, "
                    f"exception={type(e).__name__}: {e}"
                )
                continue
    
    elapsed_time = time.time() - start_time
    
    # âœ… ìµœì¢… ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½ ë¡œê·¸ (1íšŒ)
    logger.warning(
        f"[META_API][SUMMARY] ğŸ“Š ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½: "
        f"ìš”ì²­={total_count}ê°œ, ì„±ê³µ={success_count}ê°œ, ì‹¤íŒ¨={fail_count}ê°œ, "
        f"ê²½ê³¼ì‹œê°„={elapsed_time:.2f}ì´ˆ"
    )
    
    # âœ… ìŠ¤í‚µ ì‚¬ìœ ë³„ ì¹´ìš´íŠ¸ ìš”ì•½ ë¡œê·¸ (1íšŒ)
    if skip_reasons:
        reasons_str = ", ".join([f"{k}={v}" for k, v in sorted(skip_reasons.items())])
        logger.warning(f"[META_API][SKIP_SUMMARY] ğŸ“‹ ìŠ¤í‚µ ì‚¬ìœ ë³„ ì¹´ìš´íŠ¸: {reasons_str}")
    else:
        logger.warning(f"[META_API][SKIP_SUMMARY] ìŠ¤í‚µ ì‚¬ìœ  ì—†ìŒ (ëª¨ë‘ ì„±ê³µ ë˜ëŠ” ì˜ˆì™¸)")
    
    return results


def get_single_ad_details(ad):
    """
    ë‹¨ì¼ ê´‘ê³ ì˜ ìƒì„¸ ì •ë³´ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
    
    Returns:
        tuple: (result_dict, skip_reason) - ì„±ê³µ ì‹œ (dict, None), ì‹¤íŒ¨ ì‹œ (None, "reason_string")
    """
    # âœ… [ENTER] ë¬´ì¡°ê±´ ì°íˆëŠ” ì§„ì… ë¡œê·¸ (ë§¨ ì²« ì¤„)
    ad_id_raw = ad.get("ad_id") if isinstance(ad, dict) else None
    logger.warning(f"[META_API][ENTER] get_single_ad_details ad_id={ad_id_raw}, ad_type={type(ad).__name__}")
    
    # âœ… ad dict ê²€ì¦ ë° ê¸°ë³¸ê°’ ì¶”ì¶œ
    if not ad or not isinstance(ad, dict):
        logger.warning(f"[META_API][SKIP] reason=invalid_ad_dict, ad_type={type(ad).__name__}, ad_value={str(ad)[:100]}")
        return None, "invalid_ad_dict"
    
    ad_id = ad.get("ad_id")
    ad_name = ad.get("ad_name", "UNKNOWN")
    account_id = ad.get("account_id", "UNKNOWN")
    instagram_acc_name = ad.get("instagram_acc_name", "")
    ad_keys = list(ad.keys())
    
    # âœ… ad_id í•„ìˆ˜ ê²€ì¦
    if not ad_id:
        logger.warning(
            f"[META_API][SKIP] reason=missing_ad_id, "
            f"account_id={account_id}, ad_name={ad_name[:50]}, "
            f"keys={ad_keys}"
        )
        return None, "missing_ad_id"
    
    logger.warning(f"[META_API][DETAIL_START] ad_id={ad_id}, ad_name={ad_name[:50]}, account_id={account_id}")
    
    # âœ… í˜¸ì¶œ ì‹œì ì— í† í° ì½ê¸° (í† í° ì—†ìœ¼ë©´ RuntimeError ë°œìƒ)
    try:
        access_token = _get_meta_access_token()
    except RuntimeError as e:
        logger.error(f"[META_API][SKIP] reason=token_missing, ad_id={ad_id}, error={e}")
        raise  # í† í° ì—ëŸ¬ëŠ” ì „íŒŒ
    
    try:
        # 1ì°¨ ìš”ì²­: í¬ë¦¬ì—ì´í‹°ë¸Œ ID (íƒ€ì„ì•„ì›ƒ ë‹¨ì¶•)
        creative_url = f"https://graph.facebook.com/v24.0/{ad_id}?fields=adcreatives&access_token={access_token}"
        logger.warning(f"[META_API][API_CALL_1] adcreatives ìš”ì²­: ad_id={ad_id}")
        
        creative_data, api_error = _safe_meta_api_get(creative_url, timeout=3, context=f"adcreatives ad_id={ad_id}")
        if creative_data is None:
            skip_reason = f"adcreatives_api_{api_error}"
            logger.warning(
                f"[META_API][SKIP] reason={skip_reason}, "
                f"ad_id={ad_id}, account_id={account_id}, ad_name={ad_name[:50]}"
            )
            return None, skip_reason
        
        logger.warning(f"[META_API][API_RESP_1] adcreatives ì‘ë‹µ ìˆ˜ì‹ : ad_id={ad_id}, keys={list(creative_data.keys())}")
        
        # âœ… adcreatives ì‘ë‹µ êµ¬ì¡° ê²€ì¦
        adcreatives = creative_data.get("adcreatives")
        if not adcreatives:
            logger.warning(
                f"[META_API][SKIP] reason=no_adcreatives_field, "
                f"ad_id={ad_id}, account_id={account_id}, "
                f"response_keys={list(creative_data.keys())}"
            )
            return None, "no_adcreatives_field"
        
        adcreatives_data = adcreatives.get("data", [])
        if not adcreatives_data or len(adcreatives_data) == 0:
            logger.warning(
                f"[META_API][SKIP] reason=empty_adcreatives_data, "
                f"ad_id={ad_id}, account_id={account_id}, "
                f"adcreatives={adcreatives}"
            )
            return None, "empty_adcreatives_data"
        
        creative_id = adcreatives_data[0].get("id")
        if not creative_id:
            logger.warning(
                f"[META_API][SKIP] reason=missing_creative_id, "
                f"ad_id={ad_id}, account_id={account_id}, "
                f"adcreatives_data[0]={adcreatives_data[0]}"
            )
            return None, "missing_creative_id"
        
        logger.warning(f"[META_API][CREATIVE_OK] ad_id={ad_id}, creative_id={creative_id}")

        # 2ì°¨ ìš”ì²­: ìƒì„¸ ì •ë³´ (íƒ€ì„ì•„ì›ƒ ë‹¨ì¶•) - asset_feed_spec í¬í•¨í•˜ì—¬ ìë™ í˜•ì‹ ê´‘ê³  ì§€ì›
        detail_url = (
            f"https://graph.facebook.com/v24.0/{creative_id}"
            f"?fields=body,object_story_spec,image_url,video_id,asset_feed_spec"
            f"&access_token={access_token}"
        )
        logger.warning(f"[META_API][API_CALL_2] creative_detail ìš”ì²­: creative_id={creative_id}")
        
        detail_data, api_error = _safe_meta_api_get(detail_url, timeout=3, context=f"creative_detail creative_id={creative_id}")
        if detail_data is None:
            skip_reason = f"creative_detail_api_{api_error}"
            logger.warning(
                f"[META_API][SKIP] reason={skip_reason}, "
                f"ad_id={ad_id}, creative_id={creative_id}, account_id={account_id}"
            )
            return None, skip_reason
        
        logger.warning(f"[META_API][API_RESP_2] creative_detail ì‘ë‹µ ìˆ˜ì‹ : creative_id={creative_id}, keys={list(detail_data.keys())}")

        # asset_feed_spec ì¶”ì¶œ (NGN ìë™ í˜•ì‹ ê´‘ê³ ìš©)
        asset_feed = detail_data.get("asset_feed_spec", {})
        
        # message ì¶”ì¶œ (ì—¬ëŸ¬ ê²½ë¡œ ì§€ì›)
        message = (
            detail_data.get("body") or  # ì§ì ‘ body
            detail_data.get("object_story_spec", {}).get("message") or  # object_story_spec.message
            detail_data.get("object_story_spec", {}).get("video_data", {}).get("message") or  # object_story_spec.video_data.message
            (asset_feed.get("bodies", [{}])[0].get("text") if asset_feed.get("bodies") and len(asset_feed.get("bodies", [])) > 0 else None) or  # asset_feed_spec.bodies[0].text
            (asset_feed.get("descriptions", [{}])[0].get("text") if asset_feed.get("descriptions") and len(asset_feed.get("descriptions", [])) > 0 else None) or  # asset_feed_spec.descriptions[0].text
            "(ë¬¸êµ¬ ì—†ìŒ)"
        )

        # link ì¶”ì¶œ (ì—¬ëŸ¬ ê²½ë¡œ ì§€ì›)
        # asset_feed_spec.link_urls[0].website_url (NGN ê³„ì • ì‹¤ì œ êµ¬ì¡°)
        asset_link_urls = asset_feed.get("link_urls", [])
        asset_link_value = None
        if asset_link_urls and len(asset_link_urls) > 0:
            asset_link_value = asset_link_urls[0].get("website_url")  # asset_feed_spec.link_urls[0].website_url
        
        # asset_feed_spec.linksëŠ” ë¬¸ìì—´ ë°°ì—´ì¼ ìˆ˜ë„ ìˆê³  ê°ì²´ ë°°ì—´ì¼ ìˆ˜ë„ ìˆìŒ (ë‹¤ë¥¸ êµ¬ì¡° ëŒ€ë¹„)
        asset_links = asset_feed.get("links", [])
        if not asset_link_value and asset_links and len(asset_links) > 0:
            if isinstance(asset_links[0], str):
                asset_link_value = asset_links[0]  # ë¬¸ìì—´ì¸ ê²½ìš°
            elif isinstance(asset_links[0], dict):
                asset_link_value = asset_links[0].get("link")  # ê°ì²´ì¸ ê²½ìš°
        
        link = (
            detail_data.get("object_story_spec", {}).get("video_data", {}).get("call_to_action", {}).get("value", {}).get("link") or  # object_story_spec.video_data.call_to_action.value.link
            detail_data.get("object_story_spec", {}).get("link_data", {}).get("link") or  # object_story_spec.link_data.link
            asset_link_value or  # asset_feed_spec.link_urls[0].website_url (ìµœìš°ì„ )
            (asset_feed.get("call_to_action_links", [{}])[0].get("link") if asset_feed.get("call_to_action_links") and len(asset_feed.get("call_to_action_links", [])) > 0 else None) or  # asset_feed_spec.call_to_action_links[0].link
            "#"
        )
        
        # ë””ë²„ê¹…: asset_feed_specì´ ìˆëŠ” ê²½ìš° ë¡œê·¸ ì¶œë ¥
        if asset_feed:
            logger.debug(f"[META_API] asset_feed_spec ë°œê²¬ (ad_id={ad_id}): message={message[:50] if message else 'None'}..., link={link[:50] if link and link != '#' else 'None'}...")

        # video_id ì¶”ì¶œ (ì—¬ëŸ¬ ê²½ë¡œ ì§€ì›)
        extracted_video_id = None
        
        # 1) root video_id
        if detail_data.get("video_id"):
            extracted_video_id = detail_data["video_id"]
        
        # 2) asset_feed_spec ê¸°ë°˜ (NGN ìë™ í˜•ì‹ ê´‘ê³ )
        asset_feed = detail_data.get("asset_feed_spec", {})
        videos = asset_feed.get("videos", [])
        if not extracted_video_id and isinstance(videos, list) and len(videos) > 0:
            extracted_video_id = videos[0].get("video_id")
        
        # 3) object_story_spec.video_data.video_id
        oss = detail_data.get("object_story_spec", {})
        if not extracted_video_id:
            extracted_video_id = oss.get("video_data", {}).get("video_id")
        
        # ë¹„ë””ì˜¤ URL ì¶”ì¶œ ë° ê³ í™”ì§ˆ ì¸ë„¤ì¼ í´ë°± ì²˜ë¦¬
        video_url = None
        high_quality_thumbnail = None  # ê³ í™”ì§ˆ ì¸ë„¤ì¼ (ë¹„ë””ì˜¤ source ì‹¤íŒ¨ ì‹œ ì‚¬ìš©)
        
        if extracted_video_id:
            # 1ë‹¨ê³„: ë¹„ë””ì˜¤ source URL ì¡°íšŒ ì‹œë„
            video_api = (
                f"https://graph.facebook.com/v24.0/{extracted_video_id}"
                f"?fields=source&access_token={access_token}"
            )
            video_data, video_error = _safe_meta_api_get(video_api, timeout=3, context=f"video_source video_id={extracted_video_id}")
            if video_data:
                video_url = video_data.get("source")
            else:
                logger.warning(f"[META_API][VIDEO_FALLBACK] ë¹„ë””ì˜¤ source ì¡°íšŒ ì‹¤íŒ¨ (ad_id={ad_id}, error={video_error}), ì¸ë„¤ì¼ë¡œ í´ë°±")
            
            # 2ë‹¨ê³„: ë¹„ë””ì˜¤ sourceê°€ ì—†ê±°ë‚˜ ì‹¤íŒ¨í•œ ê²½ìš°, ê³ í™”ì§ˆ ì¸ë„¤ì¼ ì¡°íšŒ
            if not video_url:
                thumb_url = f"https://graph.facebook.com/v24.0/{extracted_video_id}?fields=thumbnails&access_token={access_token}"
                thumb_data, thumb_error = _safe_meta_api_get(thumb_url, timeout=2, context=f"video_thumbnails video_id={extracted_video_id}")
                if thumb_data:
                    thumbnails = thumb_data.get("thumbnails", {}).get("data", [])
                    if thumbnails:
                        # í•´ìƒë„(width * height)ê°€ ê°€ì¥ ë†’ì€ ì¸ë„¤ì¼ ì„ íƒ (ê³ í™”ì§ˆ)
                        high_quality_thumbnail = max(
                            thumbnails, 
                            key=lambda x: x.get("width", 0) * x.get("height", 0)
                        ).get("uri", "")
                        logger.warning(f"[META_API][THUMB_OK] ê³ í™”ì§ˆ ì¸ë„¤ì¼ ì¶”ì¶œ ì„±ê³µ (ad_id={ad_id})")
        
        # ì´ë¯¸ì§€ URL ì¶”ì¶œ (ì¸ë„¤ì¼ìš© ë˜ëŠ” ì´ë¯¸ì§€ ê´‘ê³ ìš©)
        # asset_feed_spec.videos[0].thumbnail_url ì¶”ì¶œ (NGN ìë™ í˜•ì‹ ê´‘ê³ ìš©)
        asset_video_thumbnail = None
        if asset_feed and asset_feed.get("videos") and len(asset_feed.get("videos", [])) > 0:
            asset_video_thumbnail = asset_feed.get("videos", [])[0].get("thumbnail_url")
        
        # ê³ í™”ì§ˆ ì¸ë„¤ì¼ì´ ìˆìœ¼ë©´ ìµœìš°ì„ ìœ¼ë¡œ ì‚¬ìš©, ì—†ìœ¼ë©´ ê¸°ì¡´ ë¡œì§ ì‚¬ìš©
        image_url = (
            high_quality_thumbnail or  # ê³ í™”ì§ˆ ì¸ë„¤ì¼ (ìµœìš°ì„ )
            asset_video_thumbnail or  # asset_feed_spec.videos[0].thumbnail_url
            detail_data.get("thumbnail_url") or  # ë£¨íŠ¸ thumbnail_url (NGN ê³„ì •)
            detail_data.get("image_url") or  # ì§ì ‘ ì´ë¯¸ì§€ URL
            detail_data.get("object_story_spec", {}).get("link_data", {}).get("picture") or  # ë§í¬ ê´‘ê³  ì´ë¯¸ì§€
            detail_data.get("object_story_spec", {}).get("link_data", {}).get("image_url") or
            detail_data.get("object_story_spec", {}).get("video_data", {}).get("image_url") or  # ë¹„ë””ì˜¤ ê´‘ê³  ì´ë¯¸ì§€
            detail_data.get("object_story_spec", {}).get("video_data", {}).get("picture") or
            ""
        )

        # âœ… ì´ë¯¸ì§€ URL ë˜ëŠ” ë¹„ë””ì˜¤ URL ì¤‘ í•˜ë‚˜ëŠ” ìˆì–´ì•¼ í•¨
        if (not image_url or image_url.strip() == "") and (not video_url or video_url.strip() == ""):
            logger.warning(
                f"[META_API][SKIP] reason=no_image_or_video_url, "
                f"ad_id={ad_id}, account_id={account_id}, ad_name={ad_name[:50]}, "
                f"detail_keys={list(detail_data.keys())}"
            )
            return None, "no_image_or_video_url"
        
        # âœ… ì´ë¯¸ì§€ URLì„ í”„ë¡ì‹œ URLë¡œ ë³€í™˜ (ë°°í¬ í™˜ê²½ ëŒ€ì‘)
        proxy_image_url = get_proxy_image_url(image_url) if image_url else ""
        
        logger.warning(f"[META_API][DETAIL_OK] âœ… ê´‘ê³  ìƒì„¸ ìˆ˜ì§‘ ì„±ê³µ: ad_id={ad_id}, has_image={bool(image_url)}, has_video={bool(video_url)}")
        
        return {
            "ad_id": ad_id,
            "ad_name": ad["ad_name"],
            "instagram_acc_name": instagram_acc_name,
            "message": message,
            "link": link,
            "image_url": proxy_image_url,  # í”„ë¡ì‹œ URLë¡œ ë³€í™˜ëœ ì¸ë„¤ì¼ ë˜ëŠ” ì´ë¯¸ì§€ ê´‘ê³ ìš©
            "video_url": video_url,  # ë¹„ë””ì˜¤ ê´‘ê³  ì›ë³¸ URL (ìˆì„ ê²½ìš°)
            "is_video": bool(extracted_video_id)
        }, None  # ì„±ê³µ ì‹œ skip_reason = None

    except Exception as e:
        skip_reason = f"exception_{type(e).__name__}"
        logger.exception(
            f"[META_API][SKIP] reason={skip_reason}, "
            f"ad_id={ad_id}, account_id={account_id}, ad_name={ad_name[:50]}"
        )
        return None, skip_reason
